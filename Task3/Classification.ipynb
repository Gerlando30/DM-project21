{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f855d-9a01-417c-a23f-f5b8a8c42b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import scikitplot as skplt\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c0e5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54535855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/tennis_players.csv\", skipinitialspace=True, sep=',', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-instruction",
   "metadata": {},
   "source": [
    "### Adding player's rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = pd.read_csv('../Task1/dataset/matches_datacleaning.csv', index_col = 0)\n",
    "pd.set_option('display.max_columns', None) # to visualize all the columns\n",
    "df_rank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_rank = df_rank[['winner_name', 'winner_rank']]\n",
    "winner_rank.set_axis(['name', 'rank'], axis=1, inplace=True)\n",
    "\n",
    "loser_rank = df_rank[['loser_name', 'loser_rank']]\n",
    "loser_rank.set_axis(['name', 'rank'], axis=1, inplace=True)\n",
    "\n",
    "player_rank = loser_rank.append(winner_rank)\n",
    "player = df[['name']]\n",
    "player = pd.merge(player, player_rank, how='left', on='name')\n",
    "print(player, '\\n# of nan:', player['rank'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#osserviamo quanti giocatori hanno QUALCHE nan\n",
    "nan_name = player[player['rank'].isna()]\n",
    "nan_name['name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prendiamo la media del rank e vediamo se sono rimasti nan (per quelli che avranno nan come rank vuol dire che nel db originale \n",
    "# non era presente nessun valore di rank per quel giocatore)\n",
    "player = player.groupby('name').mean()\n",
    "player['rank']=player['rank'].round(0)\n",
    "player['rank'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "player.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "player['rank'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "player[player['rank'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "player.reset_index(inplace = True)\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbec8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, player, how='left', on='name')\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013b6f7",
   "metadata": {},
   "source": [
    "## Transform categorical features into numerical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12acc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to discretize the variables\n",
    "#input: the dataset and the list of variables' names to discretize\n",
    "def discretize_data(dataset, variables):\n",
    "    for variable in variables:\n",
    "        #get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        \n",
    "        #generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "\n",
    "        #add a new colum with the number representation of the variable\n",
    "        dataset[variable+'_num'] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretize the categorical variables\n",
    "variables = ['hand', 'gender', 'ioc']\n",
    "df = discretize_data(df, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the categorical variables since we don't need them anymore \n",
    "df.drop(columns=['name','hand', 'gender', 'ioc'], axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d940dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15428b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Labels\n",
    "\n",
    "Abbiamo bisogno di capire qual'è il target associato ad ogni insieme per fare il processo di classificazione, un idea potrebbe essere utilizzando un attributo specifico che tiene tratta delle \"performance\" di ogni giocatore, in modo da poter contraddistingure i giocatori più forti da quelli più deboli.\n",
    "\n",
    "Nota: questa non è una metrica efficate perchè il vero label del giocatore viene calcolato in base al relativo ranking ma nel nostro caso avendo molti null risulta difficile stimarlo quindi se non ci sono altre alternative potrebbe essere la soluzione più efficente \n",
    "\n",
    "Quindi possiamo usare i percentili o i quartili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f658d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label tipo1\n",
    "quantile_a = df['rank'].quantile(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3436b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blindtest=df[df['rank'].isna()]\n",
    "del blindtest['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19326c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['rank'].isna()].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for index, rank in df['rank'].items():\n",
    "    if rank <= quantile_a:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['high-level', 'low-level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.DataFrame()\n",
    "classes['labels'] = labels\n",
    "classes.labels.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97ac76",
   "metadata": {},
   "source": [
    "### Prepare dataset (splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005100a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use stratify because database contain unbalanced label, in this way it's possible to mantain this percentage \n",
    "#of label in train and test set \n",
    "train_set, test_set, train_label, test_label = train_test_split(df, labels, stratify=labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.size(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e13c0e",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b2af6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Classfication with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library for decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "import pydotplus \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a733cb",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62241b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_max_depth = [2,3,5,6,7,10,12,None]\n",
    "dt_min_samples_split = sp_randint(2, 51)\n",
    "min_samples_leaf = sp_randint(1, 51)\n",
    "criterion = [\"entropy\", \"gini\"]\n",
    "splitter = [\"best\", \"random\"]\n",
    "max_features = [None, 2, 3, 4, 5]\n",
    "\n",
    "dt_param_grid = {\n",
    "    \"max_depth\": dt_max_depth,\n",
    "    \"min_samples_split\": dt_min_samples_split.rvs(5),\n",
    "    \"min_samples_leaf\": min_samples_leaf.rvs(5),\n",
    "    \"criterion\": criterion,\n",
    "    \"splitter\": splitter,\n",
    "    \"max_features\": max_features,\n",
    "    }\n",
    "\n",
    "\n",
    "#define the grid search\n",
    "dt_grid = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=dt_param_grid, \n",
    "                            scoring=make_scorer(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = dt_grid.fit(train_set, train_label)\n",
    "print(dt_grid.best_params_)\n",
    "train_pred_dt = dt_grid.predict(train_set)\n",
    "test_pred_dt = dt_grid.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_pred_dt = dt_grid.predict(blindtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(best_model.best_estimator_, out_file=None, \n",
    "            filled=True, rounded=True, class_names=['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "print(graph.to_string())\n",
    "#Image(graph.create_png()) AGGIUSTARE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473325a",
   "metadata": {},
   "source": [
    "### Evaluation of the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate the accuracy on the train set and the test set\n",
    "#metrics also contains precision, recall, f1 and the support\n",
    "### PUò ESSERE UTILE CALCOLARE LA PROBABILITà DI APPARTENZA DI UN RECORD AD UNA CLASSE O ALL'ALTRA (UTILE PER ROC CURVE)\n",
    "print(classification_report(train_label, train_pred_dt, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_label, test_pred_dt, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_label, test_pred_dt)\n",
    "plot_confusion_matrix(dt_grid, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba_dt = dt_grid.predict_proba(test_set)\n",
    "skplt.metrics.plot_roc(test_label, test_pred_proba_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae78959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ace and minutes\n",
    "plt.scatter(test_set['minutes'], test_set['perc_ace'], c=test_label, s=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e3b9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bayesian classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79696835",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set, train_label)\n",
    "train_pred_gnb = gnb.predict(train_set)\n",
    "#predict on the test set\n",
    "test_pred_gnb = gnb.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483bbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the performance of the model\n",
    "print(classification_report(train_label, train_pred_gnb, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b40da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_label, test_pred_gnb, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba_gnb = gnb.predict_proba(test_set)\n",
    "test_pred_proba_gnb\n",
    "skplt.metrics.plot_roc(test_label, test_pred_proba_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-brook",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb06a33",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068cc0f5-1b14-4447-9f4c-701cead0cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_neurons1, activation1, n_neurons2, activation2, activation_out, loss): \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_neurons1, input_dim=19, activation=activation1)) \n",
    "    model.add(Dense(n_neurons2, activation=activation2)) \n",
    "    model.add(Dense(1, activation=activation_out))\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, metrics=[\"accuracy\", \"MeanSquaredError\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    \"n_neurons1\":[3,7,22],\n",
    "    \"activation1\":[\"sigmoid\",\"softmax\"],\n",
    "    \"n_neurons2\":[5,15],\n",
    "    \"activation2\":[\"relu\",\"softmax\"],\n",
    "    \"activation_out\":[\"relu\",\"sigmoid\"],\n",
    "    \"loss\":[\"binary_crossentropy\", \"mean_squared_error\"]\n",
    "}\n",
    "\n",
    "nn = KerasClassifier(build_fn=create_model, epochs=150, batch_size=32)\n",
    "nn_grid = RandomizedSearchCV(nn, param_distributions=grid_param, n_iter=100, n_jobs=-1, cv=5, scoring=make_scorer(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9771803-84c9-412f-a1a7-08d9be7daa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = nn_grid.fit(train_set, train_label)\n",
    "print(nn_grid.best_params_)\n",
    "train_pred_nn = nn_grid.predict(train_set)\n",
    "test_pred_nn = nn_grid.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa75007-22fb-4670-9425-a0b93c9f9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_label, train_pred_nn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447433a4-f77b-4d01-a4f2-f0c7884505ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_label, test_pred_nn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-sterling",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_no_cat = train_set.loc[:,~train_set.columns.str.contains('_num', case=False)] \n",
    "test_set_no_cat = test_set.loc[:,~test_set.columns.str.contains('_num', case=False)] \n",
    "\n",
    "k = math.sqrt(len(train_set))\n",
    "k = round(k, 0)\n",
    "k = int(k)\n",
    "k = k - 2\n",
    "k_range = []\n",
    "for i in range(0,5):\n",
    "    k_range.append(k)\n",
    "    k = k + 1\n",
    "k_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': k_range,\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "            }\n",
    "\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5, scoring=make_scorer(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.fit(train_set_no_cat, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_knn = knn_grid.predict(train_set_no_cat)\n",
    "test_pred_knn = knn_grid.predict(test_set_no_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_label, train_pred_knn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_label, test_pred_knn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-tolerance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-minimum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
