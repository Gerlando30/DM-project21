{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4f855d-9a01-417c-a23f-f5b8a8c42b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import statistics \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import scikitplot as skplt\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "#import graphviz\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c0e5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54535855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2072 entries, 0 to 3885\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   name                   2072 non-null   object \n",
      " 1   ratio                  2072 non-null   float64\n",
      " 2   num_matches_2016-2019  2072 non-null   float64\n",
      " 3   ratio_2016-2019        2072 non-null   float64\n",
      " 4   num_matches_2020-2021  2072 non-null   float64\n",
      " 5   ratio_2020-2021        2072 non-null   float64\n",
      " 6   hand                   2072 non-null   object \n",
      " 7   gender                 2072 non-null   object \n",
      " 8   ioc                    2072 non-null   object \n",
      " 9   birth                  2072 non-null   float64\n",
      " 10  ht                     2072 non-null   float64\n",
      " 11  minutes                2072 non-null   float64\n",
      " 12  perc_ace               2072 non-null   float64\n",
      " 13  serv_won_tot_seve      2072 non-null   float64\n",
      " 14  bpFaced                2072 non-null   float64\n",
      " 15  perc_df                2072 non-null   float64\n",
      " 16  perc_2ndwon            2072 non-null   float64\n",
      " 17  perc_v_ace             2072 non-null   float64\n",
      " 18  perc_v_df              2072 non-null   float64\n",
      " 19  perc_v_1stwon          2072 non-null   float64\n",
      "dtypes: float64(16), object(4)\n",
      "memory usage: 339.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/tennis_players.csv\", skipinitialspace=True, sep=',', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-instruction",
   "metadata": {},
   "source": [
    "### Adding player's rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "creative-hughes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 181501 entries, 0 to 185763\n",
      "Data columns (total 50 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   tourney_id          181501 non-null  object \n",
      " 1   tourney_name        181501 non-null  object \n",
      " 2   surface             181354 non-null  object \n",
      " 3   draw_size           181501 non-null  float64\n",
      " 4   tourney_level       181501 non-null  object \n",
      " 5   tourney_date        181501 non-null  object \n",
      " 6   match_num           181501 non-null  float64\n",
      " 7   winner_id           181501 non-null  float64\n",
      " 8   winner_entry        25298 non-null   object \n",
      " 9   winner_name         181501 non-null  object \n",
      " 10  winner_hand         181501 non-null  object \n",
      " 11  winner_ioc          181501 non-null  object \n",
      " 12  winner_age          178681 non-null  float64\n",
      " 13  loser_id            181501 non-null  float64\n",
      " 14  loser_entry         43307 non-null   object \n",
      " 15  loser_name          181501 non-null  object \n",
      " 16  loser_hand          181501 non-null  object \n",
      " 17  loser_ioc           181501 non-null  object \n",
      " 18  loser_age           175006 non-null  float64\n",
      " 19  score               181334 non-null  object \n",
      " 20  best_of             181501 non-null  float64\n",
      " 21  round               181501 non-null  object \n",
      " 22  minutes             181501 non-null  float64\n",
      " 23  w_ace               126454 non-null  float64\n",
      " 24  w_df                126454 non-null  float64\n",
      " 25  w_svpt              181501 non-null  float64\n",
      " 26  w_1stIn             181501 non-null  float64\n",
      " 27  w_1stWon            126454 non-null  float64\n",
      " 28  w_2ndWon            126454 non-null  float64\n",
      " 29  w_bpSaved           126454 non-null  float64\n",
      " 30  w_bpFaced           126454 non-null  float64\n",
      " 31  l_ace               124716 non-null  float64\n",
      " 32  l_df                124716 non-null  float64\n",
      " 33  l_svpt              181501 non-null  float64\n",
      " 34  l_1stIn             181501 non-null  float64\n",
      " 35  l_1stWon            124716 non-null  float64\n",
      " 36  l_2ndWon            124716 non-null  float64\n",
      " 37  l_bpSaved           124716 non-null  float64\n",
      " 38  l_bpFaced           124716 non-null  float64\n",
      " 39  winner_rank         162188 non-null  float64\n",
      " 40  winner_rank_points  162172 non-null  float64\n",
      " 41  loser_rank          146385 non-null  float64\n",
      " 42  loser_rank_points   146369 non-null  float64\n",
      " 43  tourney_spectators  181501 non-null  float64\n",
      " 44  tourney_revenue     181501 non-null  float64\n",
      " 45  winner_gender       181501 non-null  object \n",
      " 46  loser_gender        181501 non-null  object \n",
      " 47  SvGms               181501 non-null  float64\n",
      " 48  winner_ht           181457 non-null  float64\n",
      " 49  loser_ht            181438 non-null  float64\n",
      "dtypes: float64(33), object(17)\n",
      "memory usage: 70.6+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_rank = pd.read_csv('../Task1/dataset/matches_datacleaning.csv', index_col = 0)\n",
    "pd.set_option('display.max_columns', None) # to visualize all the columns\n",
    "df_rank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broadband-ecology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name    rank\n",
      "0         AARON ADDISON  1037.0\n",
      "1         AARON ADDISON  1254.0\n",
      "2         AARON ADDISON  1255.0\n",
      "3         AARON ADDISON  1047.0\n",
      "4         AARON ADDISON  1055.0\n",
      "...                 ...     ...\n",
      "257926  ZUZANA ZLOCHOVA   343.0\n",
      "257927  ZUZANA ZLOCHOVA   335.0\n",
      "257928  ZUZANA ZLOCHOVA   316.0\n",
      "257929  ZUZANA ZLOCHOVA   318.0\n",
      "257930  ZUZANA ZLOCHOVA   316.0\n",
      "\n",
      "[257931 rows x 2 columns] \n",
      "# of nan: 7622\n"
     ]
    }
   ],
   "source": [
    "winner_rank = df_rank[['winner_name', 'winner_rank']]\n",
    "winner_rank.set_axis(['name', 'rank'], axis=1, inplace=True)\n",
    "\n",
    "loser_rank = df_rank[['loser_name', 'loser_rank']]\n",
    "loser_rank.set_axis(['name', 'rank'], axis=1, inplace=True)\n",
    "\n",
    "player_rank = loser_rank.append(winner_rank)\n",
    "player = df[['name']]\n",
    "player = pd.merge(player, player_rank, how='left', on='name')\n",
    "print(player, '\\n# of nan:', player['rank'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "together-analysis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#osserviamo quanti giocatori hanno QUALCHE nan\n",
    "nan_name = player[player['rank'].isna()]\n",
    "nan_name['name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surprised-killer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2037.000000\n",
       "mean      490.356406\n",
       "std       327.419749\n",
       "min         3.000000\n",
       "25%       243.000000\n",
       "50%       422.000000\n",
       "75%       682.000000\n",
       "max      1908.000000\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prendiamo la media del rank e vediamo se sono rimasti nan (per quelli che avranno nan come rank vuol dire che nel db originale \n",
    "# non era presente nessun valore di rank per quel giocatore)\n",
    "player = player.groupby('name').mean()\n",
    "player['rank']=player['rank'].round(0)\n",
    "player['rank'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1151f5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e6b110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "947"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player['rank'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "banned-philippines",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABIR EL FAHIMI</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALEX LAWSON</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMAL SULTANBEKOV</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMARNI BANKS</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANASTASIA IAMACHKINE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANNA BOWTELL</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARBORA PALICOVA</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BREANA STAMPFLI</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHARLOTTE KEMPENAERS POCZ</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANIELLE ANDREA THOMPSON</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DARYA SHVARTSMANN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAVID O'HARE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DONA ABO HABAGA</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMILY MEYER</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EUNJI LIM</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLORENCIA ROSSI</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNAH VILLER MOLLER</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSIEN YIN PENG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IVETA DAUJOTAITE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JACKSON J WITHROW</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JESSICA FOWLER</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LINA QOSTAL</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LISA ZAAR</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARIAN JADE CAPADOCIA</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARK VERRYTH</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MENG YI CHEN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIA KUPRES</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NASIBA ESPOLOVA</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NATALIA SZABANIN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NETHMI HIMASHI WADUGE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAULINA BAKAITE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAARA ORAV</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYBILLE GAUVAIN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THEIVIYA SELVARAJOO</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERONIKA BOKOR</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           rank\n",
       "name                           \n",
       "ABIR EL FAHIMI              NaN\n",
       "ALEX LAWSON                 NaN\n",
       "AMAL SULTANBEKOV            NaN\n",
       "AMARNI BANKS                NaN\n",
       "ANASTASIA IAMACHKINE        NaN\n",
       "ANNA BOWTELL                NaN\n",
       "BARBORA PALICOVA            NaN\n",
       "BREANA STAMPFLI             NaN\n",
       "CHARLOTTE KEMPENAERS POCZ   NaN\n",
       "DANIELLE ANDREA THOMPSON    NaN\n",
       "DARYA SHVARTSMANN           NaN\n",
       "DAVID O'HARE                NaN\n",
       "DONA ABO HABAGA             NaN\n",
       "EMILY MEYER                 NaN\n",
       "EUNJI LIM                   NaN\n",
       "FLORENCIA ROSSI             NaN\n",
       "HANNAH VILLER MOLLER        NaN\n",
       "HSIEN YIN PENG              NaN\n",
       "IVETA DAUJOTAITE            NaN\n",
       "JACKSON J WITHROW           NaN\n",
       "JESSICA FOWLER              NaN\n",
       "LINA QOSTAL                 NaN\n",
       "LISA ZAAR                   NaN\n",
       "MARIAN JADE CAPADOCIA       NaN\n",
       "MARK VERRYTH                NaN\n",
       "MENG YI CHEN                NaN\n",
       "MIA KUPRES                  NaN\n",
       "NASIBA ESPOLOVA             NaN\n",
       "NATALIA SZABANIN            NaN\n",
       "NETHMI HIMASHI WADUGE       NaN\n",
       "PAULINA BAKAITE             NaN\n",
       "SAARA ORAV                  NaN\n",
       "SYBILLE GAUVAIN             NaN\n",
       "THEIVIYA SELVARAJOO         NaN\n",
       "VERONIKA BOKOR              NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player[player['rank'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5893908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARON ADDISON</td>\n",
       "      <td>1131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBIE MYERS</td>\n",
       "      <td>475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABHINAV SANJEEV SHANMUGAM</td>\n",
       "      <td>1233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABIGAIL TERE APISAH</td>\n",
       "      <td>422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABIR EL FAHIMI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>ZIZOU BERGS</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>ZOE HIVES</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>ZOE KRUGER</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>ZSOMBOR PIROS</td>\n",
       "      <td>454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>ZUZANA ZLOCHOVA</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2072 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name    rank\n",
       "0                 AARON ADDISON  1131.0\n",
       "1                   ABBIE MYERS   475.0\n",
       "2     ABHINAV SANJEEV SHANMUGAM  1233.0\n",
       "3           ABIGAIL TERE APISAH   422.0\n",
       "4                ABIR EL FAHIMI     NaN\n",
       "...                         ...     ...\n",
       "2067                ZIZOU BERGS   371.0\n",
       "2068                  ZOE HIVES   319.0\n",
       "2069                 ZOE KRUGER   750.0\n",
       "2070              ZSOMBOR PIROS   454.0\n",
       "2071            ZUZANA ZLOCHOVA   461.0\n",
       "\n",
       "[2072 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.reset_index(inplace = True)\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbec8ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio</th>\n",
       "      <th>num_matches_2016-2019</th>\n",
       "      <th>ratio_2016-2019</th>\n",
       "      <th>num_matches_2020-2021</th>\n",
       "      <th>ratio_2020-2021</th>\n",
       "      <th>birth</th>\n",
       "      <th>ht</th>\n",
       "      <th>minutes</th>\n",
       "      <th>perc_ace</th>\n",
       "      <th>serv_won_tot_seve</th>\n",
       "      <th>bpFaced</th>\n",
       "      <th>perc_df</th>\n",
       "      <th>perc_2ndwon</th>\n",
       "      <th>perc_v_ace</th>\n",
       "      <th>perc_v_df</th>\n",
       "      <th>perc_v_1stwon</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.000000</td>\n",
       "      <td>2072.00000</td>\n",
       "      <td>2037.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.486609</td>\n",
       "      <td>100.942085</td>\n",
       "      <td>0.478162</td>\n",
       "      <td>23.541988</td>\n",
       "      <td>0.309913</td>\n",
       "      <td>1993.805502</td>\n",
       "      <td>179.104946</td>\n",
       "      <td>80.432832</td>\n",
       "      <td>6.716569</td>\n",
       "      <td>0.523839</td>\n",
       "      <td>871.927124</td>\n",
       "      <td>7.450516</td>\n",
       "      <td>43.113605</td>\n",
       "      <td>6.698571</td>\n",
       "      <td>6.355497</td>\n",
       "      <td>54.31431</td>\n",
       "      <td>490.356406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.115073</td>\n",
       "      <td>78.005562</td>\n",
       "      <td>0.134808</td>\n",
       "      <td>26.280039</td>\n",
       "      <td>0.264866</td>\n",
       "      <td>5.063032</td>\n",
       "      <td>8.008870</td>\n",
       "      <td>16.122646</td>\n",
       "      <td>5.324856</td>\n",
       "      <td>0.146481</td>\n",
       "      <td>720.860044</td>\n",
       "      <td>3.444339</td>\n",
       "      <td>12.302156</td>\n",
       "      <td>4.583606</td>\n",
       "      <td>1.962237</td>\n",
       "      <td>19.24605</td>\n",
       "      <td>327.419749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>55.472222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.91000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.423077</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.415466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>62.607850</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>5.220000</td>\n",
       "      <td>40.770000</td>\n",
       "      <td>2.550000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>39.42750</td>\n",
       "      <td>243.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>82.359127</td>\n",
       "      <td>5.755000</td>\n",
       "      <td>0.580575</td>\n",
       "      <td>638.500000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>47.295000</td>\n",
       "      <td>6.155000</td>\n",
       "      <td>6.615000</td>\n",
       "      <td>64.30500</td>\n",
       "      <td>422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.565673</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>0.566866</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>185.705882</td>\n",
       "      <td>94.008066</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>0.614162</td>\n",
       "      <td>1446.500000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>50.112500</td>\n",
       "      <td>10.312500</td>\n",
       "      <td>7.552500</td>\n",
       "      <td>69.80000</td>\n",
       "      <td>682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.845161</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>145.073643</td>\n",
       "      <td>35.390000</td>\n",
       "      <td>0.949992</td>\n",
       "      <td>3834.000000</td>\n",
       "      <td>29.860000</td>\n",
       "      <td>94.180000</td>\n",
       "      <td>23.310000</td>\n",
       "      <td>17.890000</td>\n",
       "      <td>80.79000</td>\n",
       "      <td>1908.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ratio  num_matches_2016-2019  ratio_2016-2019  \\\n",
       "count  2072.000000            2072.000000      2072.000000   \n",
       "mean      0.486609             100.942085         0.478162   \n",
       "std       0.115073              78.005562         0.134808   \n",
       "min       0.133333               0.000000         0.000000   \n",
       "25%       0.423077              28.000000         0.415466   \n",
       "50%       0.500000              82.000000         0.500000   \n",
       "75%       0.565673             170.000000         0.566866   \n",
       "max       0.845161             309.000000         1.000000   \n",
       "\n",
       "       num_matches_2020-2021  ratio_2020-2021        birth           ht  \\\n",
       "count            2072.000000      2072.000000  2072.000000  2072.000000   \n",
       "mean               23.541988         0.309913  1993.805502   179.104946   \n",
       "std                26.280039         0.264866     5.063032     8.008870   \n",
       "min                 0.000000         0.000000  1977.000000   157.000000   \n",
       "25%                 0.000000         0.000000  1990.000000   173.000000   \n",
       "50%                12.000000         0.375000  1994.000000   178.000000   \n",
       "75%                45.000000         0.533333  1998.000000   185.705882   \n",
       "max               101.000000         1.000000  2006.000000   198.000000   \n",
       "\n",
       "           minutes     perc_ace  serv_won_tot_seve      bpFaced      perc_df  \\\n",
       "count  2072.000000  2072.000000        2072.000000  2072.000000  2072.000000   \n",
       "mean     80.432832     6.716569           0.523839   871.927124     7.450516   \n",
       "std      16.122646     5.324856           0.146481   720.860044     3.444339   \n",
       "min      55.472222     0.000000           0.037581     0.000000     0.000000   \n",
       "25%      62.607850     2.400000           0.505333   230.000000     5.220000   \n",
       "50%      82.359127     5.755000           0.580575   638.500000     6.950000   \n",
       "75%      94.008066     9.840000           0.614162  1446.500000     9.172500   \n",
       "max     145.073643    35.390000           0.949992  3834.000000    29.860000   \n",
       "\n",
       "       perc_2ndwon   perc_v_ace    perc_v_df  perc_v_1stwon         rank  \n",
       "count  2072.000000  2072.000000  2072.000000     2072.00000  2037.000000  \n",
       "mean     43.113605     6.698571     6.355497       54.31431   490.356406  \n",
       "std      12.302156     4.583606     1.962237       19.24605   327.419749  \n",
       "min       0.000000     0.070000     0.000000        0.91000     3.000000  \n",
       "25%      40.770000     2.550000     5.390000       39.42750   243.000000  \n",
       "50%      47.295000     6.155000     6.615000       64.30500   422.000000  \n",
       "75%      50.112500    10.312500     7.552500       69.80000   682.000000  \n",
       "max      94.180000    23.310000    17.890000       80.79000  1908.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, player, how='left', on='name')\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013b6f7",
   "metadata": {},
   "source": [
    "## Transform categorical features into numerical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f12acc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to discretize the variables\n",
    "#input: the dataset and the list of variables' names to discretize\n",
    "def discretize_data(dataset, variables):\n",
    "    for variable in variables:\n",
    "        #get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        \n",
    "        #generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "\n",
    "        #add a new colum with the number representation of the variable\n",
    "        dataset[variable+'_num'] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17ba9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretize the categorical variables\n",
    "variables = ['hand', 'gender', 'ioc']\n",
    "df = discretize_data(df, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2253efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the categorical variables since we don't need them anymore \n",
    "df.drop(columns=['name','hand', 'gender', 'ioc'], axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d940dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2072 entries, 0 to 2071\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   ratio                  2072 non-null   float64\n",
      " 1   num_matches_2016-2019  2072 non-null   float64\n",
      " 2   ratio_2016-2019        2072 non-null   float64\n",
      " 3   num_matches_2020-2021  2072 non-null   float64\n",
      " 4   ratio_2020-2021        2072 non-null   float64\n",
      " 5   birth                  2072 non-null   float64\n",
      " 6   ht                     2072 non-null   float64\n",
      " 7   minutes                2072 non-null   float64\n",
      " 8   perc_ace               2072 non-null   float64\n",
      " 9   serv_won_tot_seve      2072 non-null   float64\n",
      " 10  bpFaced                2072 non-null   float64\n",
      " 11  perc_df                2072 non-null   float64\n",
      " 12  perc_2ndwon            2072 non-null   float64\n",
      " 13  perc_v_ace             2072 non-null   float64\n",
      " 14  perc_v_df              2072 non-null   float64\n",
      " 15  perc_v_1stwon          2072 non-null   float64\n",
      " 16  rank                   2037 non-null   float64\n",
      " 17  hand_num               2072 non-null   int64  \n",
      " 18  gender_num             2072 non-null   int64  \n",
      " 19  ioc_num                2072 non-null   int64  \n",
      "dtypes: float64(17), int64(3)\n",
      "memory usage: 339.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe8db7",
   "metadata": {},
   "source": [
    "### Write to csv before classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5871f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset/players_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15428b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Labels\n",
    "\n",
    "Abbiamo bisogno di capire qual'è il target associato ad ogni insieme per fare il processo di classificazione, un idea potrebbe essere utilizzando un attributo specifico che tiene tratta delle \"performance\" di ogni giocatore, in modo da poter contraddistingure i giocatori più forti da quelli più deboli.\n",
    "\n",
    "Nota: questa non è una metrica efficate perchè il vero label del giocatore viene calcolato in base al relativo ranking ma nel nostro caso avendo molti null risulta difficile stimarlo quindi se non ci sono altre alternative potrebbe essere la soluzione più efficente \n",
    "\n",
    "Quindi possiamo usare i percentili o i quartili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d100a709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio</th>\n",
       "      <th>num_matches_2016-2019</th>\n",
       "      <th>ratio_2016-2019</th>\n",
       "      <th>num_matches_2020-2021</th>\n",
       "      <th>ratio_2020-2021</th>\n",
       "      <th>birth</th>\n",
       "      <th>ht</th>\n",
       "      <th>minutes</th>\n",
       "      <th>perc_ace</th>\n",
       "      <th>serv_won_tot_seve</th>\n",
       "      <th>bpFaced</th>\n",
       "      <th>perc_df</th>\n",
       "      <th>perc_2ndwon</th>\n",
       "      <th>perc_v_ace</th>\n",
       "      <th>perc_v_df</th>\n",
       "      <th>perc_v_1stwon</th>\n",
       "      <th>rank</th>\n",
       "      <th>hand_num</th>\n",
       "      <th>gender_num</th>\n",
       "      <th>ioc_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>0.845161</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.829694</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>118.034749</td>\n",
       "      <td>10.43</td>\n",
       "      <td>0.675834</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>4.92</td>\n",
       "      <td>54.72</td>\n",
       "      <td>11.15</td>\n",
       "      <td>6.01</td>\n",
       "      <td>65.42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0.754579</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.745690</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>88.797710</td>\n",
       "      <td>4.19</td>\n",
       "      <td>0.590683</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>48.38</td>\n",
       "      <td>4.38</td>\n",
       "      <td>7.17</td>\n",
       "      <td>58.06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>0.835616</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.842553</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>122.658811</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.679608</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>3.69</td>\n",
       "      <td>57.72</td>\n",
       "      <td>12.03</td>\n",
       "      <td>5.78</td>\n",
       "      <td>64.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>0.828829</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>112.136728</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.712798</td>\n",
       "      <td>874.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>58.48</td>\n",
       "      <td>10.92</td>\n",
       "      <td>5.65</td>\n",
       "      <td>68.16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.699405</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>97.553718</td>\n",
       "      <td>15.94</td>\n",
       "      <td>0.618893</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>7.84</td>\n",
       "      <td>45.59</td>\n",
       "      <td>7.41</td>\n",
       "      <td>8.34</td>\n",
       "      <td>63.85</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>172.137193</td>\n",
       "      <td>97.307692</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.391993</td>\n",
       "      <td>159.0</td>\n",
       "      <td>9.15</td>\n",
       "      <td>36.12</td>\n",
       "      <td>2.83</td>\n",
       "      <td>5.98</td>\n",
       "      <td>54.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>0.379310</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>177.500000</td>\n",
       "      <td>61.904040</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.409342</td>\n",
       "      <td>305.0</td>\n",
       "      <td>12.49</td>\n",
       "      <td>31.81</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>173.363636</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.130994</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.81</td>\n",
       "      <td>13.16</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.89</td>\n",
       "      <td>11.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>0.380952</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>172.137193</td>\n",
       "      <td>71.658654</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.482784</td>\n",
       "      <td>139.0</td>\n",
       "      <td>10.25</td>\n",
       "      <td>43.84</td>\n",
       "      <td>1.65</td>\n",
       "      <td>8.06</td>\n",
       "      <td>25.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>0.342857</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>60.239130</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.229478</td>\n",
       "      <td>276.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>26.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2072 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ratio  num_matches_2016-2019  ratio_2016-2019  num_matches_2020-2021  \\\n",
       "1493  0.845161                  229.0         0.829694                   81.0   \n",
       "1782  0.754579                  232.0         0.745690                   41.0   \n",
       "1617  0.835616                  235.0         0.842553                   57.0   \n",
       "1672  0.828829                  202.0         0.841584                   20.0   \n",
       "1021  0.699405                  270.0         0.711111                   66.0   \n",
       "...        ...                    ...              ...                    ...   \n",
       "1549  0.133333                   15.0         0.133333                    0.0   \n",
       "1701  0.379310                    8.0         0.375000                   21.0   \n",
       "1833  0.500000                   16.0         0.500000                    0.0   \n",
       "1866  0.380952                   21.0         0.380952                    0.0   \n",
       "1938  0.342857                   16.0         0.250000                   19.0   \n",
       "\n",
       "      ratio_2020-2021   birth          ht     minutes  perc_ace  \\\n",
       "1493         0.888889  1987.0  188.000000  118.034749     10.43   \n",
       "1782         0.804878  1991.0  168.000000   88.797710      4.19   \n",
       "1617         0.807018  1986.0  185.000000  122.658811      7.35   \n",
       "1672         0.700000  1981.0  185.000000  112.136728     17.50   \n",
       "1021         0.651515  1992.0  184.000000   97.553718     15.94   \n",
       "...               ...     ...         ...         ...       ...   \n",
       "1549         0.000000  1999.0  172.137193   97.307692      3.15   \n",
       "1701         0.380952  2002.0  177.500000   61.904040      3.20   \n",
       "1833         0.000000  1994.0  173.363636   59.750000      0.00   \n",
       "1866         0.000000  1994.0  172.137193   71.658654      0.72   \n",
       "1938         0.421053  2000.0  165.000000   60.239130      0.00   \n",
       "\n",
       "      serv_won_tot_seve  bpFaced  perc_df  perc_2ndwon  perc_v_ace  perc_v_df  \\\n",
       "1493           0.675834   1454.0     4.92        54.72       11.15       6.01   \n",
       "1782           0.590683   1808.0     5.50        48.38        4.38       7.17   \n",
       "1617           0.679608   1377.0     3.69        57.72       12.03       5.78   \n",
       "1672           0.712798    874.0     3.41        58.48       10.92       5.65   \n",
       "1021           0.618893   2185.0     7.84        45.59        7.41       8.34   \n",
       "...                 ...      ...      ...          ...         ...        ...   \n",
       "1549           0.391993    159.0     9.15        36.12        2.83       5.98   \n",
       "1701           0.409342    305.0    12.49        31.81        0.08       0.49   \n",
       "1833           0.130994     72.0     5.81        13.16        1.44       2.89   \n",
       "1866           0.482784    139.0    10.25        43.84        1.65       8.06   \n",
       "1938           0.229478    276.0     8.14        26.14        0.07       0.07   \n",
       "\n",
       "      perc_v_1stwon  rank  hand_num  gender_num  ioc_num  \n",
       "1493          65.42   3.0         1           1       78  \n",
       "1782          58.06   3.0         1           0       71  \n",
       "1617          64.74   3.0         0           1       26  \n",
       "1672          68.16   4.0         1           1       80  \n",
       "1021          63.85   7.0         1           0       20  \n",
       "...             ...   ...       ...         ...      ...  \n",
       "1549          54.02   NaN         2           0       49  \n",
       "1701           5.00   NaN         2           0       27  \n",
       "1833          11.19   NaN         2           0       29  \n",
       "1866          25.41   NaN         2           0       52  \n",
       "1938           0.91   NaN         2           0        4  \n",
       "\n",
       "[2072 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31f658d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label tipo1\n",
    "quantile_a = df['rank'].quantile(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3436b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blindtest=df[df['rank'].isna()]\n",
    "del blindtest['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19326c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['rank'].isna()].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21be1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for index, rank in df['rank'].items():\n",
    "    if rank <= quantile_a:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1df4bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['high-level', 'low-level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d41935f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.746686\n",
       "0    0.253314\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = pd.DataFrame()\n",
    "classes['labels'] = labels\n",
    "classes.labels.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97ac76",
   "metadata": {},
   "source": [
    "### Prepare dataset (splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "459c7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "005100a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use stratify because database contain unbalanced label, in this way it's possible to mantain this percentage \n",
    "#of label in train and test set \n",
    "train_set, test_set, train_label, test_label = train_test_split(df, labels, stratify=labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af61c82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e13c0e",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046343f",
   "metadata": {},
   "source": [
    "Abbiamo usato diversi metodi di classificazione in particolare:\n",
    "\n",
    "- Decision Tree\n",
    "- Bayesian classifier\n",
    "- Neural Network\n",
    "- KNN\n",
    "\n",
    "da aggiungere:\n",
    "- Rule based classified \n",
    "- SVM\n",
    "- AdaBoosting\n",
    "- Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b2af6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Classfication with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "transsexual-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library for decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "import pydotplus \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a733cb",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62241b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_max_depth = [2,3,5,6,7,10,12,None]\n",
    "dt_min_samples_split = sp_randint(2, 51)\n",
    "min_samples_leaf = sp_randint(1, 51)\n",
    "criterion = [\"entropy\", \"gini\"]\n",
    "splitter = [\"best\", \"random\"]\n",
    "max_features = [None, 2, 3, 4, 5]\n",
    "\n",
    "dt_param_grid = {\n",
    "    \"max_depth\": dt_max_depth,\n",
    "    \"min_samples_split\": dt_min_samples_split.rvs(5),\n",
    "    \"min_samples_leaf\": min_samples_leaf.rvs(5),\n",
    "    \"criterion\": criterion,\n",
    "    \"splitter\": splitter,\n",
    "    \"max_features\": max_features,\n",
    "    }\n",
    "\n",
    "\n",
    "#define the grid search\n",
    "dt_grid = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=dt_param_grid, \n",
    "                            scoring=make_scorer(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffbb8ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 15, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "best_model = dt_grid.fit(train_set, train_label)\n",
    "print(dt_grid.best_params_)\n",
    "train_pred_dt = dt_grid.predict(train_set)\n",
    "test_pred_dt = dt_grid.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "plain-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_pred_dt = dt_grid.predict(blindtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "greater-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(best_model.best_estimator_, out_file=None, \n",
    "            filled=True, rounded=True, class_names=['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "minor-nickel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [color=\"black\", fontname=\"helvetica\", shape=box, style=\"filled, rounded\"];\n",
      "edge [fontname=\"helvetica\"];\n",
      "0 [fillcolor=\"#7cbeee\", label=\"X[1] <= 108.952\\nentropy = 0.817\\nsamples = 1527\\nvalue = [387, 1140]\\nclass = 1\"];\n",
      "1 [fillcolor=\"#46a3e7\", label=\"X[5] <= 1991.41\\nentropy = 0.333\\nsamples = 879\\nvalue = [54, 825]\\nclass = 1\"];\n",
      "0 -> 1  [headlabel=\"True\", labelangle=45, labeldistance=\"2.5\"];\n",
      "2 [fillcolor=\"#5baee9\", label=\"X[17] <= 0.304\\nentropy = 0.602\\nsamples = 259\\nvalue = [38, 221]\\nclass = 1\"];\n",
      "1 -> 2;\n",
      "3 [fillcolor=\"#9ccef2\", label=\"X[13] <= 4.068\\nentropy = 0.918\\nsamples = 72\\nvalue = [24, 48]\\nclass = 1\"];\n",
      "2 -> 3;\n",
      "4 [fillcolor=\"#5dafea\", label=\"X[15] <= 31.69\\nentropy = 0.615\\nsamples = 46\\nvalue = [7, 39]\\nclass = 1\"];\n",
      "3 -> 4;\n",
      "5 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 14\\nvalue = [0, 14]\\nclass = 1\"];\n",
      "4 -> 5;\n",
      "6 [fillcolor=\"#70b8ec\", label=\"X[5] <= 1987.596\\nentropy = 0.758\\nsamples = 32\\nvalue = [7, 25]\\nclass = 1\"];\n",
      "4 -> 6;\n",
      "7 [fillcolor=\"#deeffb\", label=\"entropy = 0.994\\nsamples = 11\\nvalue = [5, 6]\\nclass = 1\"];\n",
      "6 -> 7;\n",
      "8 [fillcolor=\"#4ea7e8\", label=\"X[8] <= 3.017\\nentropy = 0.454\\nsamples = 21\\nvalue = [2, 19]\\nclass = 1\"];\n",
      "6 -> 8;\n",
      "9 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 9\\nvalue = [0, 9]\\nclass = 1\"];\n",
      "8 -> 9;\n",
      "10 [fillcolor=\"#61b1ea\", label=\"entropy = 0.65\\nsamples = 12\\nvalue = [2, 10]\\nclass = 1\"];\n",
      "8 -> 10;\n",
      "11 [fillcolor=\"#f3c4a2\", label=\"X[10] <= 629.704\\nentropy = 0.931\\nsamples = 26\\nvalue = [17, 9]\\nclass = 0\"];\n",
      "3 -> 11;\n",
      "12 [fillcolor=\"#9ccef2\", label=\"entropy = 0.918\\nsamples = 12\\nvalue = [4, 8]\\nclass = 1\"];\n",
      "11 -> 12;\n",
      "13 [fillcolor=\"#e78b48\", label=\"entropy = 0.371\\nsamples = 14\\nvalue = [13, 1]\\nclass = 0\"];\n",
      "11 -> 13;\n",
      "14 [fillcolor=\"#49a5e7\", label=\"X[5] <= 1981.729\\nentropy = 0.384\\nsamples = 187\\nvalue = [14, 173]\\nclass = 1\"];\n",
      "2 -> 14;\n",
      "15 [fillcolor=\"#deeffb\", label=\"entropy = 0.994\\nsamples = 11\\nvalue = [5, 6]\\nclass = 1\"];\n",
      "14 -> 15;\n",
      "16 [fillcolor=\"#44a2e6\", label=\"X[5] <= 1988.693\\nentropy = 0.291\\nsamples = 176\\nvalue = [9, 167]\\nclass = 1\"];\n",
      "14 -> 16;\n",
      "17 [fillcolor=\"#50a8e8\", label=\"X[12] <= 52.331\\nentropy = 0.477\\nsamples = 78\\nvalue = [8, 70]\\nclass = 1\"];\n",
      "16 -> 17;\n",
      "18 [fillcolor=\"#53aae8\", label=\"X[2] <= 0.414\\nentropy = 0.523\\nsamples = 68\\nvalue = [8, 60]\\nclass = 1\"];\n",
      "17 -> 18;\n",
      "19 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 24\\nvalue = [0, 24]\\nclass = 1\"];\n",
      "18 -> 19;\n",
      "20 [fillcolor=\"#65b3eb\", label=\"entropy = 0.684\\nsamples = 44\\nvalue = [8, 36]\\nclass = 1\"];\n",
      "18 -> 20;\n",
      "21 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 10\\nvalue = [0, 10]\\nclass = 1\"];\n",
      "17 -> 21;\n",
      "22 [fillcolor=\"#3b9ee5\", label=\"X[13] <= 15.976\\nentropy = 0.082\\nsamples = 98\\nvalue = [1, 97]\\nclass = 1\"];\n",
      "16 -> 22;\n",
      "23 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 92\\nvalue = [0, 92]\\nclass = 1\"];\n",
      "22 -> 23;\n",
      "24 [fillcolor=\"#61b1ea\", label=\"entropy = 0.65\\nsamples = 6\\nvalue = [1, 5]\\nclass = 1\"];\n",
      "22 -> 24;\n",
      "25 [fillcolor=\"#3ea0e6\", label=\"X[3] <= 43.069\\nentropy = 0.173\\nsamples = 620\\nvalue = [16, 604]\\nclass = 1\"];\n",
      "1 -> 25;\n",
      "26 [fillcolor=\"#3b9ee5\", label=\"X[1] <= 42.052\\nentropy = 0.077\\nsamples = 528\\nvalue = [5, 523]\\nclass = 1\"];\n",
      "25 -> 26;\n",
      "27 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 336\\nvalue = [0, 336]\\nclass = 1\"];\n",
      "26 -> 27;\n",
      "28 [fillcolor=\"#3ea0e6\", label=\"X[14] <= 7.034\\nentropy = 0.174\\nsamples = 192\\nvalue = [5, 187]\\nclass = 1\"];\n",
      "26 -> 28;\n",
      "29 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 140\\nvalue = [0, 140]\\nclass = 1\"];\n",
      "28 -> 29;\n",
      "30 [fillcolor=\"#4ea7e8\", label=\"X[17] <= 0.253\\nentropy = 0.457\\nsamples = 52\\nvalue = [5, 47]\\nclass = 1\"];\n",
      "28 -> 30;\n",
      "31 [fillcolor=\"#a7d3f3\", label=\"entropy = 0.94\\nsamples = 14\\nvalue = [5, 9]\\nclass = 1\"];\n",
      "30 -> 31;\n",
      "32 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 38\\nvalue = [0, 38]\\nclass = 1\"];\n",
      "30 -> 32;\n",
      "33 [fillcolor=\"#54aae9\", label=\"X[9] <= 0.545\\nentropy = 0.528\\nsamples = 92\\nvalue = [11, 81]\\nclass = 1\"];\n",
      "25 -> 33;\n",
      "34 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 31\\nvalue = [0, 31]\\nclass = 1\"];\n",
      "33 -> 34;\n",
      "35 [fillcolor=\"#65b3eb\", label=\"X[12] <= 54.444\\nentropy = 0.681\\nsamples = 61\\nvalue = [11, 50]\\nclass = 1\"];\n",
      "33 -> 35;\n",
      "36 [fillcolor=\"#6db7ec\", label=\"X[2] <= 0.544\\nentropy = 0.737\\nsamples = 53\\nvalue = [11, 42]\\nclass = 1\"];\n",
      "35 -> 36;\n",
      "37 [fillcolor=\"#47a4e7\", label=\"X[8] <= 6.064\\nentropy = 0.353\\nsamples = 30\\nvalue = [2, 28]\\nclass = 1\"];\n",
      "36 -> 37;\n",
      "38 [fillcolor=\"#6ab6ec\", label=\"entropy = 0.722\\nsamples = 10\\nvalue = [2, 8]\\nclass = 1\"];\n",
      "37 -> 38;\n",
      "39 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 20\\nvalue = [0, 20]\\nclass = 1\"];\n",
      "37 -> 39;\n",
      "40 [fillcolor=\"#b8dcf6\", label=\"X[1] <= 37.327\\nentropy = 0.966\\nsamples = 23\\nvalue = [9, 14]\\nclass = 1\"];\n",
      "36 -> 40;\n",
      "41 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]\\nclass = 1\"];\n",
      "40 -> 41;\n",
      "42 [fillcolor=\"#ffffff\", label=\"entropy = 1.0\\nsamples = 18\\nvalue = [9, 9]\\nclass = 0\"];\n",
      "40 -> 42;\n",
      "43 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 8\\nvalue = [0, 8]\\nclass = 1\"];\n",
      "35 -> 43;\n",
      "44 [fillcolor=\"#fef8f4\", label=\"X[7] <= 75.215\\nentropy = 0.999\\nsamples = 648\\nvalue = [333, 315]\\nclass = 0\"];\n",
      "0 -> 44  [headlabel=\"False\", labelangle=\"-45\", labeldistance=\"2.5\"];\n",
      "45 [fillcolor=\"#5dafea\", label=\"X[7] <= 68.789\\nentropy = 0.615\\nsamples = 276\\nvalue = [42, 234]\\nclass = 1\"];\n",
      "44 -> 45;\n",
      "46 [fillcolor=\"#43a2e6\", label=\"X[9] <= 0.423\\nentropy = 0.281\\nsamples = 226\\nvalue = [11, 215]\\nclass = 1\"];\n",
      "45 -> 46;\n",
      "47 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 54\\nvalue = [0, 54]\\nclass = 1\"];\n",
      "46 -> 47;\n",
      "48 [fillcolor=\"#47a4e7\", label=\"X[7] <= 66.385\\nentropy = 0.343\\nsamples = 172\\nvalue = [11, 161]\\nclass = 1\"];\n",
      "46 -> 48;\n",
      "49 [fillcolor=\"#3c9ee5\", label=\"X[7] <= 62.887\\nentropy = 0.107\\nsamples = 142\\nvalue = [2, 140]\\nclass = 1\"];\n",
      "48 -> 49;\n",
      "50 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 77\\nvalue = [0, 77]\\nclass = 1\"];\n",
      "49 -> 50;\n",
      "51 [fillcolor=\"#3fa0e6\", label=\"X[1] <= 195.365\\nentropy = 0.198\\nsamples = 65\\nvalue = [2, 63]\\nclass = 1\"];\n",
      "49 -> 51;\n",
      "52 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 38\\nvalue = [0, 38]\\nclass = 1\"];\n",
      "51 -> 52;\n",
      "53 [fillcolor=\"#49a5e7\", label=\"entropy = 0.381\\nsamples = 27\\nvalue = [2, 25]\\nclass = 1\"];\n",
      "51 -> 53;\n",
      "54 [fillcolor=\"#8ec7f0\", label=\"X[15] <= 53.151\\nentropy = 0.881\\nsamples = 30\\nvalue = [9, 21]\\nclass = 1\"];\n",
      "48 -> 54;\n",
      "55 [fillcolor=\"#6db7ec\", label=\"X[1] <= 187.903\\nentropy = 0.738\\nsamples = 24\\nvalue = [5, 19]\\nclass = 1\"];\n",
      "54 -> 55;\n",
      "56 [fillcolor=\"#4da7e8\", label=\"entropy = 0.439\\nsamples = 11\\nvalue = [1, 10]\\nclass = 1\"];\n",
      "55 -> 56;\n",
      "57 [fillcolor=\"#91c9f1\", label=\"entropy = 0.89\\nsamples = 13\\nvalue = [4, 9]\\nclass = 1\"];\n",
      "55 -> 57;\n",
      "58 [fillcolor=\"#f2c09c\", label=\"entropy = 0.918\\nsamples = 6\\nvalue = [4, 2]\\nclass = 0\"];\n",
      "54 -> 58;\n",
      "59 [fillcolor=\"#f5ceb2\", label=\"X[1] <= 225.653\\nentropy = 0.958\\nsamples = 50\\nvalue = [31, 19]\\nclass = 0\"];\n",
      "45 -> 59;\n",
      "60 [fillcolor=\"#fbeee4\", label=\"X[15] <= 53.738\\nentropy = 0.996\\nsamples = 41\\nvalue = [22, 19]\\nclass = 0\"];\n",
      "59 -> 60;\n",
      "61 [fillcolor=\"#97cbf1\", label=\"X[2] <= 0.558\\nentropy = 0.906\\nsamples = 28\\nvalue = [9, 19]\\nclass = 1\"];\n",
      "60 -> 61;\n",
      "62 [fillcolor=\"#4ba6e7\", label=\"entropy = 0.414\\nsamples = 12\\nvalue = [1, 11]\\nclass = 1\"];\n",
      "61 -> 62;\n",
      "63 [fillcolor=\"#ffffff\", label=\"X[6] <= 172.783\\nentropy = 1.0\\nsamples = 16\\nvalue = [8, 8]\\nclass = 0\"];\n",
      "61 -> 63;\n",
      "64 [fillcolor=\"#f0b78e\", label=\"entropy = 0.881\\nsamples = 10\\nvalue = [7, 3]\\nclass = 0\"];\n",
      "63 -> 64;\n",
      "65 [fillcolor=\"#61b1ea\", label=\"entropy = 0.65\\nsamples = 6\\nvalue = [1, 5]\\nclass = 1\"];\n",
      "63 -> 65;\n",
      "66 [fillcolor=\"#e58139\", label=\"entropy = 0.0\\nsamples = 13\\nvalue = [13, 0]\\nclass = 0\"];\n",
      "60 -> 66;\n",
      "67 [fillcolor=\"#e58139\", label=\"entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]\\nclass = 0\"];\n",
      "59 -> 67;\n",
      "68 [fillcolor=\"#eca470\", label=\"X[1] <= 147.716\\nentropy = 0.756\\nsamples = 372\\nvalue = [291, 81]\\nclass = 0\"];\n",
      "44 -> 68;\n",
      "69 [fillcolor=\"#c4e2f7\", label=\"X[17] <= 0.621\\nentropy = 0.978\\nsamples = 80\\nvalue = [33, 47]\\nclass = 1\"];\n",
      "68 -> 69;\n",
      "70 [fillcolor=\"#eeab7b\", label=\"X[7] <= 85.703\\nentropy = 0.811\\nsamples = 20\\nvalue = [15, 5]\\nclass = 0\"];\n",
      "69 -> 70;\n",
      "71 [fillcolor=\"#fbeade\", label=\"entropy = 0.994\\nsamples = 11\\nvalue = [6, 5]\\nclass = 0\"];\n",
      "70 -> 71;\n",
      "72 [fillcolor=\"#e58139\", label=\"entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]\\nclass = 0\"];\n",
      "70 -> 72;\n",
      "73 [fillcolor=\"#8ec7f0\", label=\"X[0] <= 0.463\\nentropy = 0.881\\nsamples = 60\\nvalue = [18, 42]\\nclass = 1\"];\n",
      "69 -> 73;\n",
      "74 [fillcolor=\"#55abe9\", label=\"X[15] <= 70.764\\nentropy = 0.544\\nsamples = 16\\nvalue = [2, 14]\\nclass = 1\"];\n",
      "73 -> 74;\n",
      "75 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 11\\nvalue = [0, 11]\\nclass = 1\"];\n",
      "74 -> 75;\n",
      "76 [fillcolor=\"#bddef6\", label=\"entropy = 0.971\\nsamples = 5\\nvalue = [2, 3]\\nclass = 1\"];\n",
      "74 -> 76;\n",
      "77 [fillcolor=\"#aad5f4\", label=\"X[5] <= 1991.659\\nentropy = 0.946\\nsamples = 44\\nvalue = [16, 28]\\nclass = 1\"];\n",
      "73 -> 77;\n",
      "78 [fillcolor=\"#f8e0ce\", label=\"entropy = 0.985\\nsamples = 14\\nvalue = [8, 6]\\nclass = 0\"];\n",
      "77 -> 78;\n",
      "79 [fillcolor=\"#81c1ee\", label=\"X[10] <= 1143.265\\nentropy = 0.837\\nsamples = 30\\nvalue = [8, 22]\\nclass = 1\"];\n",
      "77 -> 79;\n",
      "80 [fillcolor=\"#57ace9\", label=\"entropy = 0.567\\nsamples = 15\\nvalue = [2, 13]\\nclass = 1\"];\n",
      "79 -> 80;\n",
      "81 [fillcolor=\"#bddef6\", label=\"entropy = 0.971\\nsamples = 15\\nvalue = [6, 9]\\nclass = 1\"];\n",
      "79 -> 81;\n",
      "82 [fillcolor=\"#e89253\", label=\"X[2] <= 0.524\\nentropy = 0.519\\nsamples = 292\\nvalue = [258, 34]\\nclass = 0\"];\n",
      "68 -> 82;\n",
      "83 [fillcolor=\"#efb184\", label=\"X[17] <= 0.415\\nentropy = 0.848\\nsamples = 91\\nvalue = [66, 25]\\nclass = 0\"];\n",
      "82 -> 83;\n",
      "84 [fillcolor=\"#e58139\", label=\"entropy = 0.0\\nsamples = 21\\nvalue = [21, 0]\\nclass = 0\"];\n",
      "83 -> 84;\n",
      "85 [fillcolor=\"#f3c7a7\", label=\"X[7] <= 101.901\\nentropy = 0.94\\nsamples = 70\\nvalue = [45, 25]\\nclass = 0\"];\n",
      "83 -> 85;\n",
      "86 [fillcolor=\"#f8dbc6\", label=\"X[0] <= 0.423\\nentropy = 0.98\\nsamples = 60\\nvalue = [35, 25]\\nclass = 0\"];\n",
      "85 -> 86;\n",
      "87 [fillcolor=\"#399de5\", label=\"entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]\\nclass = 1\"];\n",
      "86 -> 87;\n",
      "88 [fillcolor=\"#f4c9aa\", label=\"entropy = 0.946\\nsamples = 55\\nvalue = [35, 20]\\nclass = 0\"];\n",
      "86 -> 88;\n",
      "89 [fillcolor=\"#e58139\", label=\"entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]\\nclass = 0\"];\n",
      "85 -> 89;\n",
      "90 [fillcolor=\"#e68742\", label=\"X[16] <= 0.43\\nentropy = 0.264\\nsamples = 201\\nvalue = [192, 9]\\nclass = 0\"];\n",
      "82 -> 90;\n",
      "91 [fillcolor=\"#e9965a\", label=\"X[5] <= 1988.469\\nentropy = 0.592\\nsamples = 28\\nvalue = [24, 4]\\nclass = 0\"];\n",
      "90 -> 91;\n",
      "92 [fillcolor=\"#e58139\", label=\"entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]\\nclass = 0\"];\n",
      "91 -> 92;\n",
      "93 [fillcolor=\"#ea9c63\", label=\"X[8] <= 10.931\\nentropy = 0.667\\nsamples = 23\\nvalue = [19, 4]\\nclass = 0\"];\n",
      "91 -> 93;\n",
      "94 [fillcolor=\"#eda876\", label=\"entropy = 0.787\\nsamples = 17\\nvalue = [13, 4]\\nclass = 0\"];\n",
      "93 -> 94;\n",
      "95 [fillcolor=\"#e58139\", label=\"entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]\\nclass = 0\"];\n",
      "93 -> 95;\n",
      "96 [fillcolor=\"#e6853f\", label=\"X[17] <= 0.755\\nentropy = 0.189\\nsamples = 173\\nvalue = [168, 5]\\nclass = 0\"];\n",
      "90 -> 96;\n",
      "97 [fillcolor=\"#e58139\", label=\"entropy = 0.0\\nsamples = 69\\nvalue = [69, 0]\\nclass = 0\"];\n",
      "96 -> 97;\n",
      "98 [fillcolor=\"#e68743\", label=\"X[1] <= 180.236\\nentropy = 0.278\\nsamples = 104\\nvalue = [99, 5]\\nclass = 0\"];\n",
      "96 -> 98;\n",
      "99 [fillcolor=\"#e99457\", label=\"entropy = 0.559\\nsamples = 23\\nvalue = [20, 3]\\nclass = 0\"];\n",
      "98 -> 99;\n",
      "100 [fillcolor=\"#e6843e\", label=\"entropy = 0.167\\nsamples = 81\\nvalue = [79, 2]\\nclass = 0\"];\n",
      "98 -> 100;\n",
      "\"\\n\";\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "print(graph.to_string())\n",
    "#Image(graph.create_png()) AGGIUSTARE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473325a",
   "metadata": {},
   "source": [
    "### Evaluation of the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf2b973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  high-level       0.86      0.87      0.86       387\n",
      "   low-level       0.96      0.95      0.95      1140\n",
      "\n",
      "    accuracy                           0.93      1527\n",
      "   macro avg       0.91      0.91      0.91      1527\n",
      "weighted avg       0.93      0.93      0.93      1527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaulate the accuracy on the train set and the test set\n",
    "#metrics also contains precision, recall, f1 and the support\n",
    "### PUò ESSERE UTILE CALCOLARE LA PROBABILITà DI APPARTENZA DI UN RECORD AD UNA CLASSE O ALL'ALTRA (UTILE PER ROC CURVE)\n",
    "print(classification_report(train_label, train_pred_dt, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "oriental-retro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  high-level       0.87      0.83      0.85       129\n",
      "   low-level       0.94      0.96      0.95       381\n",
      "\n",
      "    accuracy                           0.93       510\n",
      "   macro avg       0.91      0.89      0.90       510\n",
      "weighted avg       0.92      0.93      0.92       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, test_pred_dt, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7364e096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_label, test_pred_dt)\n",
    "plot_confusion_matrix(dt_grid, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "square-responsibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'ROC Curves'}, xlabel='False Positive Rate', ylabel='True Positive Rate'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred_proba_dt = dt_grid.predict_proba(test_set)\n",
    "skplt.metrics.plot_roc(test_label, test_pred_proba_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ae78959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ace and minutes\n",
    "plt.scatter(test_set['minutes'], test_set['perc_ace'], c=test_label, s=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e3b9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bayesian classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "furnished-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79696835",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set, train_label)\n",
    "train_pred_gnb = gnb.predict(train_set)\n",
    "#predict on the test set\n",
    "test_pred_gnb = gnb.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "483bbbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  high-level       0.66      0.92      0.77       387\n",
      "   low-level       0.97      0.84      0.90      1140\n",
      "\n",
      "    accuracy                           0.86      1527\n",
      "   macro avg       0.81      0.88      0.83      1527\n",
      "weighted avg       0.89      0.86      0.86      1527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compute the performance of the model\n",
    "print(classification_report(train_label, train_pred_gnb, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68b40da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  high-level       0.72      0.93      0.81       129\n",
      "   low-level       0.97      0.88      0.92       381\n",
      "\n",
      "    accuracy                           0.89       510\n",
      "   macro avg       0.85      0.90      0.87       510\n",
      "weighted avg       0.91      0.89      0.90       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, test_pred_gnb, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acute-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'ROC Curves'}, xlabel='False Positive Rate', ylabel='True Positive Rate'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred_proba_gnb = gnb.predict_proba(test_set)\n",
    "test_pred_proba_gnb\n",
    "skplt.metrics.plot_roc(test_label, test_pred_proba_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-brook",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb06a33",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "068cc0f5-1b14-4447-9f4c-701cead0cd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "respective-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_neurons1, activation1, n_neurons2, activation2, dropout_rate, optimizer, activation_out, loss): \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_neurons1, input_dim=19, activation=activation1)) \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_neurons2, activation=activation2))\n",
    "    model.add(Dropout(dropout_rate)) \n",
    "    model.add(Dense(1, activation=activation_out))\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\", \"MeanSquaredError\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "concerned-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    \"n_neurons1\":[9,20],\n",
    "    \"activation1\":[\"sigmoid\",\"softmax\",\"linea\"],\n",
    "    \"n_neurons2\":[5,15],\n",
    "    \"activation2\":[\"relu\",\"softmax\"],\n",
    "    \"optimizer\": ['SGD'],\n",
    "#     \"activation_out\":[\"softmax\",\"relu\",\"sigmoid\"],\n",
    "    \"dropout_rate\" : [0.2],\n",
    "    \"activation_out\":[\"softmax\"],\n",
    "    \"loss\":[\"binary_crossentropy\", \"mean_squared_error\"]\n",
    "}\n",
    "\n",
    "nn = KerasClassifier(build_fn=create_model, epochs=150, batch_size=32)\n",
    "nn_grid = GridSearchCV(nn, param_grid=grid_param, n_jobs=-1, cv=5, scoring=make_scorer(f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9771803-84c9-412f-a1a7-08d9be7daa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Metal device set to: Apple M1\n",
      "Metal device set to: Apple M1\n",
      "Metal device set to: Apple M1\n",
      "Metal device set to: Apple M1\n",
      "Metal device set to: Apple M1\n",
      "Metal device set to: Apple M1\n",
      "Metal device set to: Apple M1\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:29:10.411022: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-23 19:29:10.411028: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-23 19:29:10.411045: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-23 19:29:10.411022: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-23 19:29:10.411080: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-23 19:29:10.411089: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-23 19:29:10.411110: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-23 19:29:10.411111: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-23 19:29:10.411590: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-23 19:29:10.411599: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-23 19:29:10.411602: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-23 19:29:10.411777: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-23 19:29:10.411790: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-23 19:29:10.411793: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-23 19:29:10.411800: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-23 19:29:10.411810: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-23 19:29:11.202415: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-23 19:29:11.202468: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-23 19:29:11.207684: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-23 19:29:11.214143: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-23 19:29:11.214791: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-23 19:29:11.214830: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-23 19:29:11.214843: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-23 19:29:11.214841: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-23 19:29:11.218319: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-23 19:29:11.220069: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-23 19:29:11.228134: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-23 19:29:11.228385: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-23 19:29:11.240278: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-23 19:29:11.240537: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-23 19:29:11.242190: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-23 19:29:11.242426: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-23 19:29:11.968323: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:29:11.973293: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:29:11.980300: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:29:11.985094: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:29:12.016102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:29:12.017487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:29:12.019147: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:29:12.058607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5874 - accuracy: 0.7227 - mean_squared_error: 0.2773Epoch 1/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.6026 - accuracy: 0.7125 - mean_squared_error: 0.2875Epoch 1/150\n",
      " 1/39 [..............................] - ETA: 2:07 - loss: 0.5434 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 1/150\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5276 - accuracy: 0.7413 - mean_squared_error: 0.2587Epoch 1/150\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.7056 - accuracy: 0.7514 - mean_squared_error: 0.2486Epoch 1/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.6990 - accuracy: 0.7482 - mean_squared_error: 0.2518Epoch 1/150\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.6248 - accuracy: 0.7514 - mean_squared_error: 0.2486Epoch 1/150\n",
      "39/39 [==============================] - 5s 36ms/step - loss: 0.6787 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.6151 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 2/150\n",
      "39/39 [==============================] - 5s 42ms/step - loss: 0.5849 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.6417 - accuracy: 0.7674 - mean_squared_error: 0.2326Epoch 2/150\n",
      "39/39 [==============================] - 5s 38ms/step - loss: 0.6940 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.6592 - accuracy: 0.7473 - mean_squared_error: 0.2527Epoch 2/150\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.6378 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 3/150\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 0.5774 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 3/150\n",
      "39/39 [==============================] - 5s 54ms/step - loss: 0.5221 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5528 - accuracy: 0.7734 - mean_squared_error: 0.2266Epoch 2/150\n",
      "39/39 [==============================] - 6s 41ms/step - loss: 0.6153 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 6s 61ms/step - loss: 0.6970 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5568 - accuracy: 0.7727 - mean_squared_error: 0.2273Epoch 2/150\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5353 - accuracy: 0.7216 - mean_squared_error: 0.2784Epoch 2/150\n",
      "39/39 [==============================] - 6s 58ms/step - loss: 0.8019 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5170 - accuracy: 0.7465 - mean_squared_error: 0.2535Epoch 2/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.6725 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.6500 - accuracy: 0.7637 - mean_squared_error: 0.2363Epoch 3/150\n",
      "39/39 [==============================] - 6s 48ms/step - loss: 0.6573 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5240 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 2/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5964 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5837 - accuracy: 0.7445 - mean_squared_error: 0.2555Epoch 4/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5355 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5813 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.6311 - accuracy: 0.7273 - mean_squared_error: 0.2727Epoch 3/150\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.5658 - accuracy: 0.7875 - mean_squared_error: 0.2125Epoch 4/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5771 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5701 - accuracy: 0.7857 - mean_squared_error: 0.2143Epoch 3/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.6392 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.5500 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 3/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.7764 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.5591 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 3/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.6525 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.8019 - accuracy: 0.7219 - mean_squared_error: 0.2781Epoch 4/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.6015 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.6452 - accuracy: 0.7257 - mean_squared_error: 0.2743Epoch 3/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5681 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5884 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 5/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5732 - accuracy: 0.7546 - mean_squared_error: 0.2454Epoch 5/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5688 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.6396 - accuracy: 0.7426 - mean_squared_error: 0.2574Epoch 4/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5780 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5581 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 4/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.6140 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 4/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.6741 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5757 - accuracy: 0.7435 - mean_squared_error: 0.2565Epoch 4/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.6350 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5761 - accuracy: 0.7525 - mean_squared_error: 0.2475Epoch 5/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5746 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.6414 - accuracy: 0.7031 - mean_squared_error: 0.2969Epoch 4/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5587 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.6246 - accuracy: 0.7438 - mean_squared_error: 0.2563Epoch 6/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5777 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5688 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 6/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5433 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.6005 - accuracy: 0.7480 - mean_squared_error: 0.2520Epoch 5/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5629 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.6252 - accuracy: 0.7432 - mean_squared_error: 0.2568Epoch 5/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5988 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.6294 - accuracy: 0.7288 - mean_squared_error: 0.2712Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5677 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5809 - accuracy: 0.7729 - mean_squared_error: 0.2271Epoch 5/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.6217 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5982 - accuracy: 0.7301 - mean_squared_error: 0.2699Epoch 6/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5754 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5977 - accuracy: 0.7312 - mean_squared_error: 0.2688Epoch 5/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5545 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5922 - accuracy: 0.7425 - mean_squared_error: 0.2575Epoch 6/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5585 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5852 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.6134 - accuracy: 0.7547 - mean_squared_error: 0.2453Epoch 7/150\n",
      "11/39 [=======>......................] - ETA: 1s - loss: 0.5525 - accuracy: 0.7244 - mean_squared_error: 0.2756Epoch 7/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5326 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5690 - accuracy: 0.7631 - mean_squared_error: 0.2369Epoch 6/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5893 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5790 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5907 - accuracy: 0.7135 - mean_squared_error: 0.2865Epoch 6/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5264 - accuracy: 0.7701 - mean_squared_error: 0.2299Epoch 6/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.6154 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5391 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 7/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5414 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5923 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 6/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5596 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5462 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.6018 - accuracy: 0.7280 - mean_squared_error: 0.2720Epoch 8/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5145 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 7/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5152 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5572 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.5931 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 7/150\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.6028 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 8/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5779 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5879 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 7/150\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5577 - accuracy: 0.7330 - mean_squared_error: 0.2670Epoch 7/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.6034 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5311 - accuracy: 0.7574 - mean_squared_error: 0.2426Epoch 8/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5429 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5780 - accuracy: 0.7425 - mean_squared_error: 0.2575Epoch 7/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5169 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5332 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 8/150\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5811 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 8/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5477 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5894 - accuracy: 0.7670 - mean_squared_error: 0.2330Epoch 9/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5660 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5204 - accuracy: 0.7937 - mean_squared_error: 0.2062Epoch 9/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5744 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5810 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5486 - accuracy: 0.7535 - mean_squared_error: 0.2465Epoch 8/150\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5517 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 8/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5982 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5423 - accuracy: 0.7485 - mean_squared_error: 0.2515Epoch 9/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5281 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5751 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 8/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5406 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5359 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5474 - accuracy: 0.7070 - mean_squared_error: 0.2930Epoch 9/150\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5728 - accuracy: 0.7452 - mean_squared_error: 0.2548Epoch 9/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5530 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 10/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5541 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5319 - accuracy: 0.7260 - mean_squared_error: 0.2740Epoch 10/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5697 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5787 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 9/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5659 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5952 - accuracy: 0.7429 - mean_squared_error: 0.2571Epoch 9/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5936 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5320 - accuracy: 0.7400 - mean_squared_error: 0.2600Epoch 10/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5262 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5124 - accuracy: 0.7520 - mean_squared_error: 0.2480Epoch 9/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5257 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5568 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5248 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 10/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5653 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 10/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5494 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5527 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5690 - accuracy: 0.7433 - mean_squared_error: 0.2567Epoch 11/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5766 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4741 - accuracy: 0.7857 - mean_squared_error: 0.2143Epoch 10/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5565 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5887 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 10/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5891 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5703 - accuracy: 0.7555 - mean_squared_error: 0.2445Epoch 11/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5714 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4946 - accuracy: 0.7595 - mean_squared_error: 0.2405Epoch 10/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5680 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5166 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5321 - accuracy: 0.7437 - mean_squared_error: 0.2562Epoch 12/150\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5229 - accuracy: 0.7535 - mean_squared_error: 0.2465Epoch 11/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5285 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5707 - accuracy: 0.7338 - mean_squared_error: 0.2662Epoch 11/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5352 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5330 - accuracy: 0.7569 - mean_squared_error: 0.2431Epoch 12/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5742 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5256 - accuracy: 0.7483 - mean_squared_error: 0.2517Epoch 11/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5856 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5407 - accuracy: 0.7610 - mean_squared_error: 0.2390Epoch 12/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5573 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5690 - accuracy: 0.7578 - mean_squared_error: 0.2422Epoch 11/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5232 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5802 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 11/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5540 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5859 - accuracy: 0.7409 - mean_squared_error: 0.2591Epoch 13/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5135 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5960 - accuracy: 0.7454 - mean_squared_error: 0.2546Epoch 12/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5381 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5434 - accuracy: 0.7510 - mean_squared_error: 0.2490Epoch 13/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5773 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5938 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5853 - accuracy: 0.7426 - mean_squared_error: 0.2574Epoch 12/150\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.6056 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 12/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5829 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5416 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 13/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5441 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.6067 - accuracy: 0.7083 - mean_squared_error: 0.2917Epoch 12/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5134 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5766 - accuracy: 0.7514 - mean_squared_error: 0.2486Epoch 12/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5549 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5458 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 14/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.6205 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5806 - accuracy: 0.7383 - mean_squared_error: 0.2617Epoch 13/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5711 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5821 - accuracy: 0.7445 - mean_squared_error: 0.2555Epoch 13/150\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.5391 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5988 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 14/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4908 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 13/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5810 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.6459 - accuracy: 0.7222 - mean_squared_error: 0.2778Epoch 14/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5432 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "11/39 [=======>......................] - ETA: 1s - loss: 0.6412 - accuracy: 0.7216 - mean_squared_error: 0.2784Epoch 13/150\n",
      "39/39 [==============================] - 2s 38ms/step - loss: 0.5141 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.6117 - accuracy: 0.7408 - mean_squared_error: 0.2592Epoch 13/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5492 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5782 - accuracy: 0.7480 - mean_squared_error: 0.2520Epoch 15/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5729 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5737 - accuracy: 0.7523 - mean_squared_error: 0.2477Epoch 14/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5404 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.6195 - accuracy: 0.7232 - mean_squared_error: 0.2768Epoch 15/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.6070 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5090 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 14/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.6026 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5386 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5778 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5360 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 14/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5711 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 14/150\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5586 - accuracy: 0.7305 - mean_squared_error: 0.2695Epoch 15/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5438 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5795 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 16/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5156 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5984 - accuracy: 0.7515 - mean_squared_error: 0.2485Epoch 14/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5843 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5707 - accuracy: 0.7587 - mean_squared_error: 0.2412Epoch 15/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5773 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5384 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5030 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 16/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5874 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5992 - accuracy: 0.7424 - mean_squared_error: 0.2576Epoch 16/150\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.4938 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 15/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5961 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5308 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 15/150\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5349 - accuracy: 0.7554 - mean_squared_error: 0.2446Epoch 15/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5327 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5702 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 17/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5059 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5781 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.6091 - accuracy: 0.7433 - mean_squared_error: 0.2567Epoch 15/150\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5209 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 16/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5416 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.6012 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5220 - accuracy: 0.7483 - mean_squared_error: 0.2517Epoch 17/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5745 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 16/150\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5045 - accuracy: 0.7524 - mean_squared_error: 0.2476Epoch 17/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5228 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5888 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 16/150\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5589 - accuracy: 0.7708 - mean_squared_error: 0.2292Epoch 16/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5308 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5104 - accuracy: 0.7465 - mean_squared_error: 0.2535Epoch 18/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5130 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5750 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 16/150\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.5351 - accuracy: 0.7688 - mean_squared_error: 0.2313Epoch 17/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5720 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5437 - accuracy: 0.7415 - mean_squared_error: 0.2585Epoch 18/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5302 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5627 - accuracy: 0.7739 - mean_squared_error: 0.2261Epoch 18/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5984 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5854 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5130 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5595 - accuracy: 0.7539 - mean_squared_error: 0.2461Epoch 17/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4838 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 17/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4892 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 17/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5242 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5862 - accuracy: 0.7453 - mean_squared_error: 0.2547Epoch 19/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5788 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5123 - accuracy: 0.7451 - mean_squared_error: 0.2549Epoch 18/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5120 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5736 - accuracy: 0.7417 - mean_squared_error: 0.2583Epoch 17/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5709 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5370 - accuracy: 0.7387 - mean_squared_error: 0.2613Epoch 19/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5337 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5605 - accuracy: 0.7524 - mean_squared_error: 0.2476Epoch 19/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5233 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.6998 - accuracy: 0.6042 - mean_squared_error: 0.3958Epoch 18/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5929 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5851 - accuracy: 0.7281 - mean_squared_error: 0.2719Epoch 18/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5909 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5341 - accuracy: 0.7356 - mean_squared_error: 0.2644Epoch 18/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5222 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5703 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5135 - accuracy: 0.7472 - mean_squared_error: 0.2528Epoch 20/150\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5732 - accuracy: 0.7400 - mean_squared_error: 0.2600Epoch 19/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5162 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5927 - accuracy: 0.7369 - mean_squared_error: 0.2631Epoch 18/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5684 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5794 - accuracy: 0.7563 - mean_squared_error: 0.2438Epoch 20/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5386 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5950 - accuracy: 0.7482 - mean_squared_error: 0.2518Epoch 20/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5840 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5974 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5154 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/39 [..............................] - ETA: 0s - loss: 0.7028 - accuracy: 0.6250 - mean_squared_error: 0.3750Epoch 19/150\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5159 - accuracy: 0.7406 - mean_squared_error: 0.2594Epoch 19/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5269 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5699 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5027 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 21/150\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5658 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 20/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5039 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5238 - accuracy: 0.7642 - mean_squared_error: 0.2358Epoch 19/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5280 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5679 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 21/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5867 - accuracy: 0.7482 - mean_squared_error: 0.2518Epoch 21/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5150 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5881 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5839 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5600 - accuracy: 0.7569 - mean_squared_error: 0.2431Epoch 20/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5232 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 20/150\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5214 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 20/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5763 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5300 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5909 - accuracy: 0.7386 - mean_squared_error: 0.2614Epoch 21/150\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5168 - accuracy: 0.7525 - mean_squared_error: 0.2475Epoch 22/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5692 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5414 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.4757 - accuracy: 0.7926 - mean_squared_error: 0.2074Epoch 22/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5322 - accuracy: 0.7405 - mean_squared_error: 0.2595Epoch 20/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5362 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5136 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5992 - accuracy: 0.7266 - mean_squared_error: 0.2734Epoch 22/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6841 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 21/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5872 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5470 - accuracy: 0.7734 - mean_squared_error: 0.2266Epoch 21/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5817 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5827 - accuracy: 0.7273 - mean_squared_error: 0.2727Epoch 21/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5714 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5958 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 22/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5282 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5850 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 23/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5678 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5503 - accuracy: 0.7323 - mean_squared_error: 0.2677Epoch 23/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5181 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5701 - accuracy: 0.7451 - mean_squared_error: 0.2549Epoch 22/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5705 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5379 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5485 - accuracy: 0.7773 - mean_squared_error: 0.2227Epoch 21/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5852 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 23/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5875 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5862 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.6160 - accuracy: 0.7312 - mean_squared_error: 0.2688Epoch 22/150\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.6385 - accuracy: 0.7232 - mean_squared_error: 0.2768Epoch 22/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5738 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5268 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5812 - accuracy: 0.7408 - mean_squared_error: 0.2592Epoch 24/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.4324 - accuracy: 0.8438 - mean_squared_error: 0.1562Epoch 23/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5676 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5928 - accuracy: 0.7417 - mean_squared_error: 0.2583Epoch 24/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4967 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5813 - accuracy: 0.7522 - mean_squared_error: 0.2478Epoch 23/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5310 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5868 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5848 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 22/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5822 - accuracy: 0.7492 - mean_squared_error: 0.2508Epoch 23/150\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5129 - accuracy: 0.7139 - mean_squared_error: 0.2861Epoch 24/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5859 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 5/39 [==>...........................] - ETA: 2s - loss: 0.4608 - accuracy: 0.8500 - mean_squared_error: 0.1500Epoch 23/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5647 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5642 - accuracy: 0.7476 - mean_squared_error: 0.2524Epoch 24/150\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.5209 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5883 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 41ms/step - loss: 0.5041 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.5671 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5734 - accuracy: 0.7619 - mean_squared_error: 0.2381Epoch 24/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.6859 - accuracy: 0.5938 - mean_squared_error: 0.4062Epoch 25/150\n",
      "39/39 [==============================] - 2s 35ms/step - loss: 0.5294 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5872 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5387 - accuracy: 0.7250 - mean_squared_error: 0.2750Epoch 25/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4939 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 24/150\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.5425 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5249 - accuracy: 0.7298 - mean_squared_error: 0.2702Epoch 23/150\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.5789 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5742 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 24/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5701 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5578 - accuracy: 0.7533 - mean_squared_error: 0.2467Epoch 25/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5217 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5315 - accuracy: 0.7773 - mean_squared_error: 0.2227Epoch 26/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5158 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5904 - accuracy: 0.7405 - mean_squared_error: 0.2595Epoch 25/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5651 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5954 - accuracy: 0.7362 - mean_squared_error: 0.2637Epoch 26/150\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.5845 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.5265 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4859 - accuracy: 0.7619 - mean_squared_error: 0.2381Epoch 26/150\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5826 - accuracy: 0.7419 - mean_squared_error: 0.2581Epoch 25/150\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.5200 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5339 - accuracy: 0.7349 - mean_squared_error: 0.2651Epoch 24/150\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.5766 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5670 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5216 - accuracy: 0.7474 - mean_squared_error: 0.2526Epoch 25/150\n",
      " 1/39 [..............................] - ETA: 2s - loss: 0.5815 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 26/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5155 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5338 - accuracy: 0.7285 - mean_squared_error: 0.2715Epoch 27/150\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.4941 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5804 - accuracy: 0.7383 - mean_squared_error: 0.2617Epoch 26/150\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.5659 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 27/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5788 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5293 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5205 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 26/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5753 - accuracy: 0.7526 - mean_squared_error: 0.2474Epoch 27/150\n",
      "39/39 [==============================] - 1s 39ms/step - loss: 0.5079 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 25/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5659 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5679 - accuracy: 0.7596 - mean_squared_error: 0.2404Epoch 27/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5085 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5008 - accuracy: 0.7708 - mean_squared_error: 0.2292Epoch 28/150\n",
      "39/39 [==============================] - 2s 48ms/step - loss: 0.5794 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 2s - loss: 0.5089 - accuracy: 0.7266 - mean_squared_error: 0.2734Epoch 26/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5069 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5872 - accuracy: 0.7406 - mean_squared_error: 0.2594Epoch 27/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.5668 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.4986 - accuracy: 0.7610 - mean_squared_error: 0.2390Epoch 28/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5872 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5940 - accuracy: 0.7401 - mean_squared_error: 0.2599Epoch 27/150\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5229 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5717 - accuracy: 0.7380 - mean_squared_error: 0.2620Epoch 28/150\n",
      "39/39 [==============================] - 1s 39ms/step - loss: 0.5073 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5678 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5326 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 26/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4542 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 28/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5102 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.6116 - accuracy: 0.7313 - mean_squared_error: 0.2688Epoch 29/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5850 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5987 - accuracy: 0.7361 - mean_squared_error: 0.2639Epoch 27/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4927 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5107 - accuracy: 0.7406 - mean_squared_error: 0.2594Epoch 28/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5657 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5221 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 29/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5898 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5431 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5177 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5737 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 29/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5716 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5130 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5913 - accuracy: 0.7400 - mean_squared_error: 0.2600Epoch 29/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5308 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 27/150\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5177 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5257 - accuracy: 0.7565 - mean_squared_error: 0.2435Epoch 30/150\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.5787 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5381 - accuracy: 0.7517 - mean_squared_error: 0.2483Epoch 28/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5396 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5512 - accuracy: 0.7656 - mean_squared_error: 0.2344Epoch 29/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5657 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 30/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5818 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5226 - accuracy: 0.7379 - mean_squared_error: 0.2621Epoch 29/150\n",
      "39/39 [==============================] - 1s 39ms/step - loss: 0.5221 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4967 - accuracy: 0.7438 - mean_squared_error: 0.2562Epoch 30/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5624 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5216 - accuracy: 0.7517 - mean_squared_error: 0.2483Epoch 30/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5187 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5104 - accuracy: 0.7442 - mean_squared_error: 0.2558Epoch 31/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5093 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5023 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 28/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5843 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4966 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5124 - accuracy: 0.7813 - mean_squared_error: 0.2188Epoch 29/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5647 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 30/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5649 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5320 - accuracy: 0.7693 - mean_squared_error: 0.2307Epoch 31/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5811 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.5446 - accuracy: 0.7679 - mean_squared_error: 0.2321Epoch 30/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5691 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5222 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 31/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5047 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5498 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 31/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5499 - accuracy: 0.7609 - mean_squared_error: 0.2391Epoch 29/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.3702 - accuracy: 0.9062 - mean_squared_error: 0.0938Epoch 32/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4930 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5105 - accuracy: 0.7642 - mean_squared_error: 0.2358Epoch 31/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5825 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5853 - accuracy: 0.7390 - mean_squared_error: 0.2610Epoch 30/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5647 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5789 - accuracy: 0.7478 - mean_squared_error: 0.2522Epoch 32/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5810 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.4875 - accuracy: 0.7574 - mean_squared_error: 0.2426Epoch 31/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5138 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4752 - accuracy: 0.7539 - mean_squared_error: 0.2461Epoch 32/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5655 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5033 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 30/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5097 - accuracy: 0.7549 - mean_squared_error: 0.2451Epoch 32/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5098 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5674 - accuracy: 0.7429 - mean_squared_error: 0.2571Epoch 33/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5756 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5153 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 31/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4761 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5547 - accuracy: 0.7693 - mean_squared_error: 0.2307Epoch 32/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5649 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4842 - accuracy: 0.7738 - mean_squared_error: 0.2262Epoch 33/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5819 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5098 - accuracy: 0.7491 - mean_squared_error: 0.2509Epoch 32/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5115 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5138 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5060 - accuracy: 0.7541 - mean_squared_error: 0.2459Epoch 31/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5057 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 33/150\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5667 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 34/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5655 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5704 - accuracy: 0.7370 - mean_squared_error: 0.2630Epoch 33/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4789 - accuracy: 0.7471 - mean_squared_error: 0.2529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5308 - accuracy: 0.7212 - mean_squared_error: 0.2788Epoch 33/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5851 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.5571 - accuracy: 0.7292 - mean_squared_error: 0.2708Epoch 32/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5626 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4955 - accuracy: 0.7474 - mean_squared_error: 0.2526Epoch 34/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5037 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5490 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4959 - accuracy: 0.7537 - mean_squared_error: 0.2463Epoch 32/150\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5663 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 33/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5074 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5053 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5672 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5167 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 34/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4968 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 35/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5148 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 34/150\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5009 - accuracy: 0.7469 - mean_squared_error: 0.2531Epoch 34/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5883 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.4870 - accuracy: 0.7674 - mean_squared_error: 0.2326Epoch 33/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5652 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5968 - accuracy: 0.7232 - mean_squared_error: 0.2768Epoch 35/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5009 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5369 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 33/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5224 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4926 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5382 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5712 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 35/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4439 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 36/150\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5374 - accuracy: 0.7375 - mean_squared_error: 0.2625Epoch 35/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4886 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5615 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 35/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4079 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 34/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5783 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4934 - accuracy: 0.7478 - mean_squared_error: 0.2522Epoch 34/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5634 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.6277 - accuracy: 0.6797 - mean_squared_error: 0.3203Epoch 36/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5732 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5358 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5166 - accuracy: 0.7530 - mean_squared_error: 0.2470Epoch 36/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.3378 - accuracy: 0.9688 - mean_squared_error: 0.0312Epoch 34/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5007 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4863 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5676 - accuracy: 0.6797 - mean_squared_error: 0.3203Epoch 37/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.3473 - accuracy: 0.9062 - mean_squared_error: 0.0938Epoch 36/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5226 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.3925 - accuracy: 0.8438 - mean_squared_error: 0.1562Epoch 36/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5235 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5619 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 35/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5821 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5250 - accuracy: 0.7370 - mean_squared_error: 0.2630Epoch 35/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5628 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "13/39 [=========>....................] - ETA: 1s - loss: 0.4742 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 37/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5080 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5244 - accuracy: 0.7393 - mean_squared_error: 0.2607Epoch 35/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5154 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5662 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4863 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 37/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5544 - accuracy: 0.7695 - mean_squared_error: 0.2305Epoch 37/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5227 - accuracy: 0.7417 - mean_squared_error: 0.2583Epoch 38/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5183 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5218 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.4964 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 36/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.4314 - accuracy: 0.8750 - mean_squared_error: 0.1250Epoch 37/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5628 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.5631 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 38/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5775 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5014 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 36/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5128 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5099 - accuracy: 0.7438 - mean_squared_error: 0.2563Epoch 38/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5647 - accuracy: 0.7543 - mean_squared_error: 0.2457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/39 [=>............................] - ETA: 1s - loss: 0.4610 - accuracy: 0.7917 - mean_squared_error: 0.2083Epoch 38/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5018 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5027 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5949 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 36/150\n",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.4655 - accuracy: 0.8594 - mean_squared_error: 0.1406Epoch 39/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5069 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5637 - accuracy: 0.7432 - mean_squared_error: 0.2568Epoch 38/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5085 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5619 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5040 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 37/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5809 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 39/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5785 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4803 - accuracy: 0.7697 - mean_squared_error: 0.2303Epoch 37/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4842 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5207 - accuracy: 0.7292 - mean_squared_error: 0.2708Epoch 39/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5684 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5206 - accuracy: 0.7361 - mean_squared_error: 0.2639Epoch 39/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4945 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5180 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5835 - accuracy: 0.7303 - mean_squared_error: 0.2697Epoch 40/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.4994 - accuracy: 0.7413 - mean_squared_error: 0.2587Epoch 39/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5632 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4963 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5172 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 40/150\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5730 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 38/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5790 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5019 - accuracy: 0.7563 - mean_squared_error: 0.2438Epoch 37/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5733 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5380 - accuracy: 0.7708 - mean_squared_error: 0.2292Epoch 38/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4759 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5491 - accuracy: 0.7591 - mean_squared_error: 0.2409Epoch 40/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5619 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.5977 - accuracy: 0.7326 - mean_squared_error: 0.2674Epoch 40/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5137 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4865 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5414 - accuracy: 0.7708 - mean_squared_error: 0.2292Epoch 40/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4871 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 41/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5616 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 41/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4923 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5745 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5094 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 39/150\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.4976 - accuracy: 0.7476 - mean_squared_error: 0.2524Epoch 38/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4790 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.4899 - accuracy: 0.7557 - mean_squared_error: 0.2443Epoch 41/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5769 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5620 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 39/150\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5551 - accuracy: 0.7515 - mean_squared_error: 0.2485Epoch 41/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5165 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4888 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5620 - accuracy: 0.7446 - mean_squared_error: 0.2554Epoch 42/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5521 - accuracy: 0.7679 - mean_squared_error: 0.2321Epoch 41/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5616 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4810 - accuracy: 0.7328 - mean_squared_error: 0.2672Epoch 42/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4936 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5560 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 40/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5725 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4989 - accuracy: 0.7321 - mean_squared_error: 0.2679Epoch 39/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5787 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5720 - accuracy: 0.7542 - mean_squared_error: 0.2458Epoch 40/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5728 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4673 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5031 - accuracy: 0.7331 - mean_squared_error: 0.2669Epoch 42/150\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.4997 - accuracy: 0.7514 - mean_squared_error: 0.2486Epoch 42/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5610 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5106 - accuracy: 0.7473 - mean_squared_error: 0.2527Epoch 43/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4936 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5722 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 42/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4966 - accuracy: 0.7543 - mean_squared_error: 0.2457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/39 [===============>..............] - ETA: 0s - loss: 0.4700 - accuracy: 0.7628 - mean_squared_error: 0.2372Epoch 43/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5053 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5620 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5566 - accuracy: 0.7516 - mean_squared_error: 0.2484Epoch 41/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.4856 - accuracy: 0.7465 - mean_squared_error: 0.2535Epoch 43/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5699 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5737 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5588 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 40/150\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5540 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 41/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4855 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.6192 - accuracy: 0.6979 - mean_squared_error: 0.3021Epoch 43/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5602 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5013 - accuracy: 0.7486 - mean_squared_error: 0.2514Epoch 44/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5205 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.4986 - accuracy: 0.7465 - mean_squared_error: 0.2535Epoch 43/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4921 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5635 - accuracy: 0.7511 - mean_squared_error: 0.2489Epoch 44/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4987 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5630 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 42/150\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4546 - accuracy: 0.7844 - mean_squared_error: 0.2156Epoch 44/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5692 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5166 - accuracy: 0.7969 - mean_squared_error: 0.2031Epoch 41/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5777 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.4218 - accuracy: 0.8021 - mean_squared_error: 0.1979Epoch 42/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5149 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5059 - accuracy: 0.8021 - mean_squared_error: 0.1979Epoch 44/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5609 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5779 - accuracy: 0.7385 - mean_squared_error: 0.2615Epoch 45/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5175 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.4901 - accuracy: 0.7483 - mean_squared_error: 0.2517Epoch 44/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5011 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 45/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5602 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.4883 - accuracy: 0.7656 - mean_squared_error: 0.2344Epoch 45/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5734 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4861 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5707 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 43/150\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5047 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 42/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6600 - accuracy: 0.6562 - mean_squared_error: 0.3438Epoch 43/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4846 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.4216 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 45/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5570 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5001 - accuracy: 0.7585 - mean_squared_error: 0.2415Epoch 46/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5175 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5621 - accuracy: 0.7517 - mean_squared_error: 0.2483Epoch 45/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5601 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5039 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 46/150\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5732 - accuracy: 0.7442 - mean_squared_error: 0.2558Epoch 46/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5711 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.4867 - accuracy: 0.7464 - mean_squared_error: 0.2536Epoch 43/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5071 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5764 - accuracy: 0.7230 - mean_squared_error: 0.2770Epoch 46/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5804 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4878 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5205 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 44/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5206 - accuracy: 0.7484 - mean_squared_error: 0.2516Epoch 44/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5572 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5826 - accuracy: 0.7324 - mean_squared_error: 0.2676Epoch 47/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5680 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4984 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 47/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5159 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5633 - accuracy: 0.7513 - mean_squared_error: 0.2487Epoch 46/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5108 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5096 - accuracy: 0.7578 - mean_squared_error: 0.2422Epoch 47/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5677 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5761 - accuracy: 0.7472 - mean_squared_error: 0.2528Epoch 44/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.4911 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4791 - accuracy: 0.7471 - mean_squared_error: 0.2529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5049 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 47/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5427 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 45/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5781 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5125 - accuracy: 0.7917 - mean_squared_error: 0.2083Epoch 45/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5541 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5616 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5401 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 48/150\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5589 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 48/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5189 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5399 - accuracy: 0.7557 - mean_squared_error: 0.2443Epoch 47/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4967 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5670 - accuracy: 0.7537 - mean_squared_error: 0.2463Epoch 48/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4797 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5507 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 48/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5077 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5450 - accuracy: 0.7546 - mean_squared_error: 0.2454Epoch 46/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5690 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5795 - accuracy: 0.7441 - mean_squared_error: 0.2559Epoch 45/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5771 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.4737 - accuracy: 0.7232 - mean_squared_error: 0.2768Epoch 46/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5515 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5668 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 49/150\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5013 - accuracy: 0.7675 - mean_squared_error: 0.2325Epoch 49/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5064 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5427 - accuracy: 0.7681 - mean_squared_error: 0.2319Epoch 48/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5080 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5877 - accuracy: 0.7353 - mean_squared_error: 0.2647Epoch 49/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4823 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5086 - accuracy: 0.7526 - mean_squared_error: 0.2474Epoch 49/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4890 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5813 - accuracy: 0.7391 - mean_squared_error: 0.2609Epoch 47/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5652 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5768 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5516 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 47/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.4994 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 46/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5644 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4799 - accuracy: 0.7485 - mean_squared_error: 0.2515Epoch 50/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5542 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.4791 - accuracy: 0.7462 - mean_squared_error: 0.2537Epoch 50/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5218 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4837 - accuracy: 0.7471 - mean_squared_error: 0.2529Epoch 49/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4963 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5906 - accuracy: 0.7320 - mean_squared_error: 0.2680Epoch 50/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4881 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4760 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5594 - accuracy: 0.7232 - mean_squared_error: 0.2768Epoch 48/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4750 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 50/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5779 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5358 - accuracy: 0.7023 - mean_squared_error: 0.2977Epoch 48/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5655 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5543 - accuracy: 0.7435 - mean_squared_error: 0.2565Epoch 47/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5649 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5160 - accuracy: 0.7284 - mean_squared_error: 0.2716Epoch 51/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5506 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5485 - accuracy: 0.7674 - mean_squared_error: 0.2326Epoch 51/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5112 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.5688 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 50/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4935 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5219 - accuracy: 0.7688 - mean_squared_error: 0.2313Epoch 51/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4671 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5688 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 51/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4850 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 49/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5728 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5717 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 49/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5674 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5693 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 48/150\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.6227 - accuracy: 0.7541 - mean_squared_error: 0.2459Epoch 52/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5542 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5878 - accuracy: 0.7240 - mean_squared_error: 0.2760Epoch 52/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5337 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5654 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 51/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.6186 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.4878 - accuracy: 0.7474 - mean_squared_error: 0.2526Epoch 52/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4882 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5319 - accuracy: 0.7159 - mean_squared_error: 0.2841Epoch 52/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5105 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5677 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 50/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5705 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.6169 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 50/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5673 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5506 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 53/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5686 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5278 - accuracy: 0.7365 - mean_squared_error: 0.2635Epoch 49/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5499 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5756 - accuracy: 0.7401 - mean_squared_error: 0.2599Epoch 53/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5277 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5744 - accuracy: 0.7428 - mean_squared_error: 0.2572Epoch 52/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5987 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5722 - accuracy: 0.7457 - mean_squared_error: 0.2543Epoch 53/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4738 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5630 - accuracy: 0.7333 - mean_squared_error: 0.2667Epoch 53/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4835 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5203 - accuracy: 0.7413 - mean_squared_error: 0.2587Epoch 51/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5628 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5741 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 51/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5680 - accuracy: 0.7432 - mean_squared_error: 0.2568Epoch 54/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5660 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5116 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 50/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5502 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4791 - accuracy: 0.7547 - mean_squared_error: 0.2453Epoch 54/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5808 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5173 - accuracy: 0.7390 - mean_squared_error: 0.2610Epoch 54/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5164 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4979 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 53/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4734 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4858 - accuracy: 0.7415 - mean_squared_error: 0.2585Epoch 54/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4866 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5254 - accuracy: 0.7625 - mean_squared_error: 0.2375Epoch 52/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5755 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5628 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.5244 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 52/150\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5686 - accuracy: 0.7442 - mean_squared_error: 0.2558Epoch 55/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5679 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5462 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 51/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5470 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4996 - accuracy: 0.7432 - mean_squared_error: 0.2568Epoch 55/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5093 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5714 - accuracy: 0.7386 - mean_squared_error: 0.2614Epoch 54/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5733 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5490 - accuracy: 0.7612 - mean_squared_error: 0.2388Epoch 55/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4752 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5660 - accuracy: 0.7220 - mean_squared_error: 0.2780Epoch 55/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4892 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5785 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5681 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 53/150\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5578 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 53/150\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4988 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 56/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5669 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5452 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 56/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4927 - accuracy: 0.7286 - mean_squared_error: 0.2714Epoch 52/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5091 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5690 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5705 - accuracy: 0.7418 - mean_squared_error: 0.2582Epoch 56/150\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5675 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 55/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4662 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5618 - accuracy: 0.7656 - mean_squared_error: 0.2344Epoch 56/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5616 - accuracy: 0.7543 - mean_squared_error: 0.2457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5615 - accuracy: 0.7656 - mean_squared_error: 0.2344Epoch 57/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5712 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.4446 - accuracy: 0.7773 - mean_squared_error: 0.2227Epoch 54/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4967 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4998 - accuracy: 0.7625 - mean_squared_error: 0.2375Epoch 54/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5416 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.5256 - accuracy: 0.7857 - mean_squared_error: 0.2143Epoch 57/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5679 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5817 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 53/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5726 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5352 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 57/150\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5981 - accuracy: 0.7487 - mean_squared_error: 0.2512Epoch 56/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4709 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5663 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 57/150\n",
      "11/39 [=======>......................] - ETA: 1s - loss: 0.5773 - accuracy: 0.7386 - mean_squared_error: 0.2614Epoch 58/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5715 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.6007 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 55/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5998 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5414 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 55/150\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5392 - accuracy: 0.7771 - mean_squared_error: 0.2229Epoch 58/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5688 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5735 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 54/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5702 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5151 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.7492 - mean_squared_error: 0.2508Epoch 58/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5161 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5824 - accuracy: 0.7354 - mean_squared_error: 0.2646Epoch 57/150\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5444 - accuracy: 0.7488 - mean_squared_error: 0.2512Epoch 58/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5666 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5630 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 59/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5722 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5447 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5628 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5200 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 56/150\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5595 - accuracy: 0.7557 - mean_squared_error: 0.2443Epoch 59/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5948 - accuracy: 0.7254 - mean_squared_error: 0.2746Epoch 56/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5691 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.6014 - accuracy: 0.7224 - mean_squared_error: 0.2776Epoch 55/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5416 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5688 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 58/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5591 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.5495 - accuracy: 0.7674 - mean_squared_error: 0.2326Epoch 59/150\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5794 - accuracy: 0.7414 - mean_squared_error: 0.2586Epoch 60/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5074 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.4777 - accuracy: 0.8281 - mean_squared_error: 0.1719Epoch 59/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5658 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.4910 - accuracy: 0.7321 - mean_squared_error: 0.2679Epoch 57/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5754 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5403 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5216 - accuracy: 0.7885 - mean_squared_error: 0.2115Epoch 57/150\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.4921 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 60/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5697 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5089 - accuracy: 0.7438 - mean_squared_error: 0.2562Epoch 56/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5615 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5526 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 61/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5855 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.4899 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 59/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5685 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5728 - accuracy: 0.7386 - mean_squared_error: 0.2614Epoch 60/150\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5374 - accuracy: 0.7857 - mean_squared_error: 0.2143Epoch 60/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4965 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.4387 - accuracy: 0.7969 - mean_squared_error: 0.2031Epoch 58/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5555 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5694 - accuracy: 0.7432 - mean_squared_error: 0.2568Epoch 61/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5697 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5043 - accuracy: 0.7857 - mean_squared_error: 0.2143Epoch 58/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5667 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5608 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5766 - accuracy: 0.7408 - mean_squared_error: 0.2592Epoch 62/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5653 - accuracy: 0.7528 - mean_squared_error: 0.2472Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 27ms/step - loss: 0.6004 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5652 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5883 - accuracy: 0.7232 - mean_squared_error: 0.2768Epoch 60/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.7475 - mean_squared_error: 0.2525Epoch 61/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4864 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5060 - accuracy: 0.7474 - mean_squared_error: 0.2526Epoch 61/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5048 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.4364 - accuracy: 0.7723 - mean_squared_error: 0.2277Epoch 59/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5352 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.4517 - accuracy: 0.7548 - mean_squared_error: 0.2452Epoch 62/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5720 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5998 - accuracy: 0.7305 - mean_squared_error: 0.2695Epoch 59/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5608 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5552 - accuracy: 0.7616 - mean_squared_error: 0.2384Epoch 63/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5664 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5640 - accuracy: 0.7518 - mean_squared_error: 0.2482Epoch 58/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5866 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.4609 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5755 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 62/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5619 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5436 - accuracy: 0.7684 - mean_squared_error: 0.2316Epoch 61/150\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5239 - accuracy: 0.7865 - mean_squared_error: 0.2135Epoch 62/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5117 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5459 - accuracy: 0.7734 - mean_squared_error: 0.2266Epoch 60/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5410 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5481 - accuracy: 0.7632 - mean_squared_error: 0.2368Epoch 63/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5740 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.5612 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 60/150\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5877 - accuracy: 0.7390 - mean_squared_error: 0.2610Epoch 64/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5657 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4786 - accuracy: 0.7520 - mean_squared_error: 0.2480Epoch 59/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5918 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 62/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5645 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 63/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4780 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5737 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 63/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4853 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5347 - accuracy: 0.7408 - mean_squared_error: 0.2592Epoch 61/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5324 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5621 - accuracy: 0.7521 - mean_squared_error: 0.2479Epoch 64/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5660 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5736 - accuracy: 0.7383 - mean_squared_error: 0.2617Epoch 65/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5706 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5132 - accuracy: 0.7865 - mean_squared_error: 0.2135Epoch 61/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5669 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5906 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5631 - accuracy: 0.7525 - mean_squared_error: 0.2475Epoch 60/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5615 - accuracy: 0.7526 - mean_squared_error: 0.2474Epoch 63/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5615 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5002 - accuracy: 0.7387 - mean_squared_error: 0.2613Epoch 64/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4694 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.4937 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 64/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4932 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5627 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 62/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5339 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5484 - accuracy: 0.7594 - mean_squared_error: 0.2406Epoch 65/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5604 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5022 - accuracy: 0.8021 - mean_squared_error: 0.1979Epoch 66/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5736 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5454 - accuracy: 0.7639 - mean_squared_error: 0.2361Epoch 62/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5672 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5830 - accuracy: 0.7413 - mean_squared_error: 0.2587Epoch 61/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5850 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5669 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.4979 - accuracy: 0.7491 - mean_squared_error: 0.2509Epoch 64/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.4713 - accuracy: 0.7420 - mean_squared_error: 0.2580Epoch 65/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4695 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5382 - accuracy: 0.7453 - mean_squared_error: 0.2547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5309 - accuracy: 0.7969 - mean_squared_error: 0.2031Epoch 66/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5011 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 65/150\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5745 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 63/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5670 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5694 - accuracy: 0.7471 - mean_squared_error: 0.2529Epoch 67/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5720 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5149 - accuracy: 0.7332 - mean_squared_error: 0.2668Epoch 63/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5668 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5640 - accuracy: 0.7613 - mean_squared_error: 0.2387Epoch 62/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5702 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5844 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 66/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5698 - accuracy: 0.7509 - mean_squared_error: 0.2491Epoch 65/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4922 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5408 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5645 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 67/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4578 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5631 - accuracy: 0.7522 - mean_squared_error: 0.2478Epoch 68/150\n",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.5713 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 64/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5768 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 66/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5732 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5677 - accuracy: 0.7273 - mean_squared_error: 0.2727Epoch 64/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5701 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5443 - accuracy: 0.7399 - mean_squared_error: 0.2601Epoch 63/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5692 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5426 - accuracy: 0.7441 - mean_squared_error: 0.2559Epoch 67/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.4798 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5454 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5604 - accuracy: 0.7541 - mean_squared_error: 0.2459Epoch 66/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4507 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 65/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5238 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5602 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 69/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.4818 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 68/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4816 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5530 - accuracy: 0.7594 - mean_squared_error: 0.2406Epoch 67/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5700 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.4811 - accuracy: 0.7535 - mean_squared_error: 0.2465Epoch 65/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5722 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4763 - accuracy: 0.7482 - mean_squared_error: 0.2518Epoch 68/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5324 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5684 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.4846 - accuracy: 0.7441 - mean_squared_error: 0.2559Epoch 64/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6533 - accuracy: 0.6562 - mean_squared_error: 0.3438Epoch 69/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5206 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4853 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.6047 - accuracy: 0.7098 - mean_squared_error: 0.2902Epoch 67/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5605 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4720 - accuracy: 0.7472 - mean_squared_error: 0.2528Epoch 66/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.4550 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 70/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4656 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5458 - accuracy: 0.7708 - mean_squared_error: 0.2292Epoch 68/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5730 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5412 - accuracy: 0.7691 - mean_squared_error: 0.2309Epoch 66/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5705 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5211 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5395 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 69/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5602 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4635 - accuracy: 0.7490 - mean_squared_error: 0.2510Epoch 71/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5415 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4745 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5679 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5638 - accuracy: 0.7515 - mean_squared_error: 0.2485Epoch 70/150\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5409 - accuracy: 0.7734 - mean_squared_error: 0.2266Epoch 67/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.2997 - accuracy: 0.9375 - mean_squared_error: 0.0625Epoch 65/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.7065 - accuracy: 0.6250 - mean_squared_error: 0.3750Epoch 68/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4603 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5824 - accuracy: 0.7156 - mean_squared_error: 0.2844Epoch 69/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5678 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5592 - accuracy: 0.7375 - mean_squared_error: 0.2625Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5644 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5680 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5755 - accuracy: 0.7363 - mean_squared_error: 0.2637Epoch 72/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5435 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4786 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 70/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5739 - accuracy: 0.7385 - mean_squared_error: 0.2615Epoch 69/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5720 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 66/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4802 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.5844 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 68/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5454 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.4941 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 71/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4715 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.4961 - accuracy: 0.7557 - mean_squared_error: 0.2443Epoch 70/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5691 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5495 - accuracy: 0.7286 - mean_squared_error: 0.2714Epoch 68/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5609 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5717 - accuracy: 0.7472 - mean_squared_error: 0.2528Epoch 73/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5472 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5616 - accuracy: 0.7545 - mean_squared_error: 0.2455Epoch 70/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4945 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5676 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5664 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5093 - accuracy: 0.7560 - mean_squared_error: 0.2440Epoch 67/150\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5681 - accuracy: 0.7486 - mean_squared_error: 0.2514Epoch 71/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5320 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 69/150\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.5463 - accuracy: 0.7604 - mean_squared_error: 0.2396Epoch 72/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5073 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5480 - accuracy: 0.7617 - mean_squared_error: 0.2383Epoch 71/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5695 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4750 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 69/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5599 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5188 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 74/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5239 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5565 - accuracy: 0.7627 - mean_squared_error: 0.2373Epoch 71/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4748 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5595 - accuracy: 0.7535 - mean_squared_error: 0.2465Epoch 70/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5343 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4958 - accuracy: 0.7563 - mean_squared_error: 0.2438Epoch 73/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5676 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5687 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.4405 - accuracy: 0.7708 - mean_squared_error: 0.2292Epoch 68/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.7206 - accuracy: 0.5938 - mean_squared_error: 0.4062Epoch 72/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5198 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.5942 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 72/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5727 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5618 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 70/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5605 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5000 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5669 - accuracy: 0.7587 - mean_squared_error: 0.2412Epoch 75/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5951 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 72/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4854 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5736 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5012 - accuracy: 0.7453 - mean_squared_error: 0.2547Epoch 71/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4868 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 73/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5671 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5249 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 69/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5842 - accuracy: 0.7401 - mean_squared_error: 0.2599Epoch 74/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4975 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 3/39 [=>............................] - ETA: 2s - loss: 0.4956 - accuracy: 0.6979 - mean_squared_error: 0.3021Epoch 73/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5713 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5086 - accuracy: 0.7832 - mean_squared_error: 0.2168Epoch 71/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5664 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5355 - accuracy: 0.7373 - mean_squared_error: 0.2627Epoch 76/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5283 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5266 - accuracy: 0.7457 - mean_squared_error: 0.2543Epoch 73/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5661 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4758 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5289 - accuracy: 0.7451 - mean_squared_error: 0.2549Epoch 72/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4766 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5671 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.4821 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 70/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5256 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.4931 - accuracy: 0.7305 - mean_squared_error: 0.2695Epoch 75/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5197 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 74/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5641 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5546 - accuracy: 0.7743 - mean_squared_error: 0.2257Epoch 77/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5705 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5488 - accuracy: 0.7781 - mean_squared_error: 0.2219Epoch 72/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5170 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5834 - accuracy: 0.7354 - mean_squared_error: 0.2646Epoch 74/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4775 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5180 - accuracy: 0.7466 - mean_squared_error: 0.2534Epoch 73/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5716 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5178 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5298 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.4612 - accuracy: 0.7773 - mean_squared_error: 0.2227Epoch 75/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5670 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 75/150\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5730 - accuracy: 0.7444 - mean_squared_error: 0.2556Epoch 76/150\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5222 - accuracy: 0.7463 - mean_squared_error: 0.2537Epoch 71/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5692 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5622 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5074 - accuracy: 0.7585 - mean_squared_error: 0.2415Epoch 73/150\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.4993 - accuracy: 0.7716 - mean_squared_error: 0.2284Epoch 78/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5213 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5656 - accuracy: 0.7566 - mean_squared_error: 0.2434Epoch 75/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4692 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5301 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5770 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 74/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5657 - accuracy: 0.7592 - mean_squared_error: 0.2408Epoch 77/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5180 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5709 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 76/150\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5810 - accuracy: 0.7083 - mean_squared_error: 0.2917Epoch 76/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5684 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5652 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5086 - accuracy: 0.7429 - mean_squared_error: 0.2571Epoch 72/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5708 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 79/150\n",
      " 1/39 [..............................] - ETA: 4s - loss: 0.6191 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 74/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5080 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4864 - accuracy: 0.7426 - mean_squared_error: 0.2574Epoch 76/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4819 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5287 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 75/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.4943 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 78/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4935 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5677 - accuracy: 0.7542 - mean_squared_error: 0.2458Epoch 77/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5677 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5374 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 77/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5679 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5632 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 73/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.4951 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 80/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5723 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5123 - accuracy: 0.7409 - mean_squared_error: 0.2591Epoch 75/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5143 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4867 - accuracy: 0.7415 - mean_squared_error: 0.2585Epoch 77/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4874 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5610 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 76/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5568 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5205 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5395 - accuracy: 0.7449 - mean_squared_error: 0.2551Epoch 81/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.7309 - accuracy: 0.6250 - mean_squared_error: 0.3750Epoch 78/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5386 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5682 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.4753 - accuracy: 0.7585 - mean_squared_error: 0.2415Epoch 78/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4926 - accuracy: 0.7566 - mean_squared_error: 0.2434Epoch 79/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5690 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5668 - accuracy: 0.7083 - mean_squared_error: 0.2917Epoch 74/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5670 - accuracy: 0.7463 - mean_squared_error: 0.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5317 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 76/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5120 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5347 - accuracy: 0.7364 - mean_squared_error: 0.2636Epoch 78/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4706 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.4975 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 77/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5005 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5637 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 79/150\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.4636 - accuracy: 0.7375 - mean_squared_error: 0.2625Epoch 82/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5673 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5278 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5668 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 79/150\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.4968 - accuracy: 0.7309 - mean_squared_error: 0.2691Epoch 80/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5668 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5620 - accuracy: 0.7545 - mean_squared_error: 0.2455Epoch 75/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5718 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4991 - accuracy: 0.7326 - mean_squared_error: 0.2674Epoch 77/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4934 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5684 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 79/150\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.4739 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5090 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 78/150\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.5617 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5231 - accuracy: 0.7452 - mean_squared_error: 0.2548Epoch 80/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5628 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5027 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5100 - accuracy: 0.7049 - mean_squared_error: 0.2951Epoch 83/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5260 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.6077 - accuracy: 0.7063 - mean_squared_error: 0.2938Epoch 81/150\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5111 - accuracy: 0.7372 - mean_squared_error: 0.2628Epoch 80/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5686 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5726 - accuracy: 0.7446 - mean_squared_error: 0.2554Epoch 76/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5709 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4848 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 78/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5055 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5789 - accuracy: 0.7361 - mean_squared_error: 0.2639Epoch 80/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4775 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5771 - accuracy: 0.7378 - mean_squared_error: 0.2622Epoch 79/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5592 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5467 - accuracy: 0.7240 - mean_squared_error: 0.2760Epoch 81/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5615 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.7451 - mean_squared_error: 0.2549Epoch 84/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5336 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5723 - accuracy: 0.7460 - mean_squared_error: 0.2540Epoch 82/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4985 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.5505 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 81/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5686 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.4904 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 77/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5728 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4868 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 79/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4927 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5579 - accuracy: 0.7571 - mean_squared_error: 0.2429Epoch 81/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4757 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5736 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 80/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5627 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4837 - accuracy: 0.7482 - mean_squared_error: 0.2518Epoch 82/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5590 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.4811 - accuracy: 0.7428 - mean_squared_error: 0.2572Epoch 85/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4834 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5792 - accuracy: 0.7323 - mean_squared_error: 0.2677Epoch 82/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5668 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5750 - accuracy: 0.7363 - mean_squared_error: 0.2637Epoch 83/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5739 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.4515 - accuracy: 0.7461 - mean_squared_error: 0.2539Epoch 80/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5658 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5329 - accuracy: 0.7741 - mean_squared_error: 0.2259Epoch 78/150\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.4920 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.4854 - accuracy: 0.7667 - mean_squared_error: 0.2333Epoch 82/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5553 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5500 - accuracy: 0.7604 - mean_squared_error: 0.2396Epoch 86/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4655 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7665 - mean_squared_error: 0.2335Epoch 81/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5664 - accuracy: 0.7543 - mean_squared_error: 0.2457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5521 - accuracy: 0.7614 - mean_squared_error: 0.2386Epoch 83/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4870 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5588 - accuracy: 0.7550 - mean_squared_error: 0.2450Epoch 83/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5388 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4771 - accuracy: 0.7281 - mean_squared_error: 0.2719Epoch 84/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5710 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5690 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 81/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5398 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 79/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5086 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.4899 - accuracy: 0.7475 - mean_squared_error: 0.2525Epoch 83/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5615 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.4820 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 87/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5581 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.4824 - accuracy: 0.7543 - mean_squared_error: 0.2457Epoch 84/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4742 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4883 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.6037 - accuracy: 0.7031 - mean_squared_error: 0.2969Epoch 84/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5330 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 85/150\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5529 - accuracy: 0.7572 - mean_squared_error: 0.2428Epoch 82/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5675 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5684 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5426 - accuracy: 0.7699 - mean_squared_error: 0.2301Epoch 82/150\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5302 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 80/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4882 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.5488 - accuracy: 0.7688 - mean_squared_error: 0.2313Epoch 84/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5605 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4925 - accuracy: 0.7419 - mean_squared_error: 0.2581Epoch 88/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4891 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4813 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 85/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5662 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5327 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5716 - accuracy: 0.7446 - mean_squared_error: 0.2554Epoch 83/150\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5623 - accuracy: 0.7511 - mean_squared_error: 0.2489Epoch 85/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.4623 - accuracy: 0.8438 - mean_squared_error: 0.1562Epoch 86/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5676 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.4666 - accuracy: 0.7734 - mean_squared_error: 0.2266Epoch 83/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5701 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5630 - accuracy: 0.7539 - mean_squared_error: 0.2461Epoch 81/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5030 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.4768 - accuracy: 0.7416 - mean_squared_error: 0.2584Epoch 85/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5616 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5587 - accuracy: 0.7565 - mean_squared_error: 0.2435Epoch 89/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.4832 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5621 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5734 - accuracy: 0.7405 - mean_squared_error: 0.2595Epoch 86/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6767 - accuracy: 0.6562 - mean_squared_error: 0.3438Epoch 84/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.4897 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.4318 - accuracy: 0.7969 - mean_squared_error: 0.2031Epoch 86/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.5301 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.4401 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 87/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5698 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 1s - loss: 0.4704 - accuracy: 0.7526 - mean_squared_error: 0.2474Epoch 84/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.5668 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.4688 - accuracy: 0.7574 - mean_squared_error: 0.2426Epoch 82/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5072 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5613 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.6054 - accuracy: 0.7210 - mean_squared_error: 0.2790Epoch 86/150\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4799 - accuracy: 0.7454 - mean_squared_error: 0.2546Epoch 90/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.4855 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4784 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5425 - accuracy: 0.7429 - mean_squared_error: 0.2571Epoch 85/150\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5670 - accuracy: 0.7473 - mean_squared_error: 0.2527Epoch 87/150\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5604 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5417 - accuracy: 0.7449 - mean_squared_error: 0.2551Epoch 87/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5399 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5618 - accuracy: 0.7512 - mean_squared_error: 0.2488Epoch 88/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5749 - accuracy: 0.7463 - mean_squared_error: 0.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5686 - accuracy: 0.7450 - mean_squared_error: 0.2550Epoch 85/150\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5677 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5607 - accuracy: 0.7528 - mean_squared_error: 0.2472Epoch 83/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5586 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4992 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4990 - accuracy: 0.7269 - mean_squared_error: 0.2731Epoch 91/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5479 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 87/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4835 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5718 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 86/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5610 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5195 - accuracy: 0.7451 - mean_squared_error: 0.2549Epoch 88/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.4738 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5194 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.4124 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 89/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5657 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5659 - accuracy: 0.7604 - mean_squared_error: 0.2396Epoch 88/150\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4693 - accuracy: 0.7530 - mean_squared_error: 0.2470Epoch 86/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5706 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5044 - accuracy: 0.7366 - mean_squared_error: 0.2634Epoch 84/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5606 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.4860 - accuracy: 0.7387 - mean_squared_error: 0.2613Epoch 92/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4858 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.4606 - accuracy: 0.7636 - mean_squared_error: 0.2364Epoch 88/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5627 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5647 - accuracy: 0.7491 - mean_squared_error: 0.2509Epoch 89/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.4794 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5569 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5676 - accuracy: 0.7475 - mean_squared_error: 0.2525Epoch 87/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5583 - accuracy: 0.7539 - mean_squared_error: 0.2461Epoch 90/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5692 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.5551 - accuracy: 0.7625 - mean_squared_error: 0.2375Epoch 87/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.4990 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5008 - accuracy: 0.7415 - mean_squared_error: 0.2585Epoch 89/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5609 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5523 - accuracy: 0.7637 - mean_squared_error: 0.2363Epoch 93/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5685 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5549 - accuracy: 0.7604 - mean_squared_error: 0.2396Epoch 85/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.5032 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5715 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 89/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5642 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 90/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5630 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5706 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5119 - accuracy: 0.7475 - mean_squared_error: 0.2525Epoch 91/150\n",
      " 1/39 [..............................] - ETA: 2s - loss: 0.5102 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 88/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4764 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5134 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5758 - accuracy: 0.7292 - mean_squared_error: 0.2708Epoch 90/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5632 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5397 - accuracy: 0.7734 - mean_squared_error: 0.2266Epoch 94/150\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5710 - accuracy: 0.7433 - mean_squared_error: 0.2567Epoch 88/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5687 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5572 - accuracy: 0.7578 - mean_squared_error: 0.2422Epoch 86/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4912 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4804 - accuracy: 0.7615 - mean_squared_error: 0.2385Epoch 90/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5611 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5333 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 91/150\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.4800 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 92/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5696 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.4837 - accuracy: 0.7527 - mean_squared_error: 0.2473Epoch 89/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4991 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5588 - accuracy: 0.7561 - mean_squared_error: 0.2439Epoch 91/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4853 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5617 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 95/150\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5679 - accuracy: 0.7464 - mean_squared_error: 0.2536Epoch 89/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5699 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4764 - accuracy: 0.7566 - mean_squared_error: 0.2434Epoch 87/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.4918 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5053 - accuracy: 0.7527 - mean_squared_error: 0.2473Epoch 91/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5656 - accuracy: 0.7543 - mean_squared_error: 0.2457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/39 [======================>.......] - ETA: 0s - loss: 0.4824 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 92/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5680 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4980 - accuracy: 0.7469 - mean_squared_error: 0.2531Epoch 90/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4817 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5589 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 92/150\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5872 - accuracy: 0.7274 - mean_squared_error: 0.2726Epoch 96/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5407 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.6110 - accuracy: 0.7063 - mean_squared_error: 0.2938Epoch 93/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5011 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4788 - accuracy: 0.7469 - mean_squared_error: 0.2531Epoch 90/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5668 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4900 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5334 - accuracy: 0.7377 - mean_squared_error: 0.2623Epoch 88/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5887 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 92/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5699 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.4822 - accuracy: 0.7418 - mean_squared_error: 0.2582Epoch 93/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5651 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5276 - accuracy: 0.7441 - mean_squared_error: 0.2559Epoch 91/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5262 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5337 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 94/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5605 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5635 - accuracy: 0.7518 - mean_squared_error: 0.2482Epoch 97/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4844 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4970 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 93/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4752 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.4410 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 91/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4968 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5682 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5215 - accuracy: 0.7452 - mean_squared_error: 0.2548Epoch 93/150\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5814 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 89/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5656 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5539 - accuracy: 0.7321 - mean_squared_error: 0.2679Epoch 94/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5583 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5267 - accuracy: 0.7424 - mean_squared_error: 0.2576Epoch 98/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5725 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5366 - accuracy: 0.7734 - mean_squared_error: 0.2266Epoch 92/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5239 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4721 - accuracy: 0.7519 - mean_squared_error: 0.2481Epoch 95/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4779 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5433 - accuracy: 0.7266 - mean_squared_error: 0.2734Epoch 92/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4842 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5962 - accuracy: 0.7227 - mean_squared_error: 0.2773Epoch 94/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4919 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5684 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 94/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4519 - accuracy: 0.7648 - mean_squared_error: 0.2352Epoch 90/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5580 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 99/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5671 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.4811 - accuracy: 0.7403 - mean_squared_error: 0.2597Epoch 95/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5721 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5210 - accuracy: 0.7869 - mean_squared_error: 0.2131Epoch 93/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5187 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5740 - accuracy: 0.7361 - mean_squared_error: 0.2639Epoch 96/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4758 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 2/39 [>.............................] - ETA: 1s - loss: 0.5291 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 93/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4700 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4988 - accuracy: 0.7545 - mean_squared_error: 0.2455Epoch 95/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5683 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5055 - accuracy: 0.7527 - mean_squared_error: 0.2473Epoch 91/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5639 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5084 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4601 - accuracy: 0.7750 - mean_squared_error: 0.2250Epoch 100/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6373 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 95/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5148 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5703 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.4870 - accuracy: 0.7465 - mean_squared_error: 0.2535Epoch 97/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5814 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 94/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5652 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5614 - accuracy: 0.7530 - mean_squared_error: 0.2470Epoch 96/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4857 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4872 - accuracy: 0.7566 - mean_squared_error: 0.2434Epoch 94/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4817 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5920 - accuracy: 0.7305 - mean_squared_error: 0.2695Epoch 96/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5591 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.4780 - accuracy: 0.7378 - mean_squared_error: 0.2622Epoch 101/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4989 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5668 - accuracy: 0.7466 - mean_squared_error: 0.2534Epoch 96/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5687 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5299 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 92/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5647 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.4852 - accuracy: 0.7250 - mean_squared_error: 0.2750Epoch 97/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5165 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4784 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5696 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5579 - accuracy: 0.7526 - mean_squared_error: 0.2474Epoch 98/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4947 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 95/150\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.4815 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 95/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5606 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4863 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5017 - accuracy: 0.7393 - mean_squared_error: 0.2607Epoch 102/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5972 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 97/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4986 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5658 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4730 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 97/150\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4799 - accuracy: 0.7523 - mean_squared_error: 0.2477Epoch 93/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5225 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5570 - accuracy: 0.7533 - mean_squared_error: 0.2467Epoch 99/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5656 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4882 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5788 - accuracy: 0.7330 - mean_squared_error: 0.2670Epoch 98/150\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.4763 - accuracy: 0.7417 - mean_squared_error: 0.2583Epoch 96/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5684 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.4949 - accuracy: 0.7865 - mean_squared_error: 0.2135Epoch 96/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5567 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5271 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 103/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4838 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.4922 - accuracy: 0.7390 - mean_squared_error: 0.2610Epoch 98/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4914 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5609 - accuracy: 0.7585 - mean_squared_error: 0.2415Epoch 98/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5675 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.4653 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 94/150\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.5624 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "12/39 [========>.....................] - ETA: 1s - loss: 0.4511 - accuracy: 0.7760 - mean_squared_error: 0.2240Epoch 99/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4713 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5864 - accuracy: 0.7305 - mean_squared_error: 0.2695Epoch 97/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5204 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5663 - accuracy: 0.7509 - mean_squared_error: 0.2491Epoch 100/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5623 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.7451 - mean_squared_error: 0.2549Epoch 104/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5689 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5485 - accuracy: 0.7646 - mean_squared_error: 0.2354Epoch 97/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4802 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5567 - accuracy: 0.7533 - mean_squared_error: 0.2467Epoch 99/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4930 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4998 - accuracy: 0.7331 - mean_squared_error: 0.2669Epoch 99/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5671 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4903 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 95/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5612 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5604 - accuracy: 0.7558 - mean_squared_error: 0.2442Epoch 100/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5621 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4849 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 105/150\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5615 - accuracy: 0.7517 - mean_squared_error: 0.2483Epoch 98/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5647 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5298 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 2/39 [>.............................] - ETA: 3s - loss: 0.5009 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 101/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5228 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 98/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4962 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5663 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 100/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5679 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4727 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5648 - accuracy: 0.7568 - mean_squared_error: 0.2432Epoch 100/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5601 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 96/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5675 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.6013 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5618 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5685 - accuracy: 0.7446 - mean_squared_error: 0.2554Epoch 106/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4770 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5016 - accuracy: 0.7146 - mean_squared_error: 0.2854Epoch 99/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5247 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5681 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.4875 - accuracy: 0.7625 - mean_squared_error: 0.2375Epoch 102/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5244 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 99/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4847 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5597 - accuracy: 0.7526 - mean_squared_error: 0.2474Epoch 101/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5674 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4793 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 97/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5587 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4968 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 101/150\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5523 - accuracy: 0.7611 - mean_squared_error: 0.2389Epoch 102/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5587 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4891 - accuracy: 0.7426 - mean_squared_error: 0.2574Epoch 107/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4833 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.4697 - accuracy: 0.7555 - mean_squared_error: 0.2445Epoch 100/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5211 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5786 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 103/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5736 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5725 - accuracy: 0.7450 - mean_squared_error: 0.2550Epoch 100/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4682 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5672 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4989 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5597 - accuracy: 0.7549 - mean_squared_error: 0.2451Epoch 102/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4924 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 98/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5604 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 102/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4758 - accuracy: 0.7399 - mean_squared_error: 0.2601Epoch 103/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5594 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.4748 - accuracy: 0.7545 - mean_squared_error: 0.2455Epoch 108/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4769 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5220 - accuracy: 0.7428 - mean_squared_error: 0.2572Epoch 101/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5220 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5785 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 104/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5661 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5758 - accuracy: 0.7377 - mean_squared_error: 0.2623Epoch 101/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4796 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4909 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5715 - accuracy: 0.7509 - mean_squared_error: 0.2491Epoch 103/150\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4684 - accuracy: 0.7546 - mean_squared_error: 0.2454Epoch 103/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5580 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5224 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 109/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5671 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5675 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.4551 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 99/150\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.4791 - accuracy: 0.7450 - mean_squared_error: 0.2550Epoch 104/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4803 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.6158 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 102/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5204 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5817 - accuracy: 0.7440 - mean_squared_error: 0.2560Epoch 105/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5706 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5627 - accuracy: 0.7557 - mean_squared_error: 0.2443Epoch 102/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4994 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4848 - accuracy: 0.7491 - mean_squared_error: 0.2509Epoch 104/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5629 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5679 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5820 - accuracy: 0.7431 - mean_squared_error: 0.2569Epoch 110/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5629 - accuracy: 0.7528 - mean_squared_error: 0.2472Epoch 100/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4901 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.4677 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 104/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5616 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 105/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4916 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5655 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 103/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5083 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5731 - accuracy: 0.7449 - mean_squared_error: 0.2551Epoch 106/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5715 - accuracy: 0.7463 - mean_squared_error: 0.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5330 - accuracy: 0.7625 - mean_squared_error: 0.2375Epoch 103/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4915 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5765 - accuracy: 0.7438 - mean_squared_error: 0.2562Epoch 105/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4931 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5719 - accuracy: 0.7491 - mean_squared_error: 0.2509Epoch 105/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5661 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "11/39 [=======>......................] - ETA: 1s - loss: 0.4998 - accuracy: 0.7472 - mean_squared_error: 0.2528Epoch 111/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5690 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.4902 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 101/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5606 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 106/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5513 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5874 - accuracy: 0.7297 - mean_squared_error: 0.2703Epoch 104/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5174 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5556 - accuracy: 0.7575 - mean_squared_error: 0.2425Epoch 107/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5714 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5581 - accuracy: 0.7582 - mean_squared_error: 0.2418Epoch 104/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5279 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5590 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.5513 - accuracy: 0.7465 - mean_squared_error: 0.2535Epoch 106/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5060 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 4/39 [==>...........................] - ETA: 2s - loss: 0.5844 - accuracy: 0.7266 - mean_squared_error: 0.2734Epoch 112/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5677 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 106/150\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5356 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 102/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4884 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5619 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5296 - accuracy: 0.7391 - mean_squared_error: 0.2609Epoch 107/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5321 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 105/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5353 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5759 - accuracy: 0.7375 - mean_squared_error: 0.2625Epoch 108/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5686 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5116 - accuracy: 0.7393 - mean_squared_error: 0.2607Epoch 105/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5111 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5611 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5364 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 113/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6089 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 107/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5669 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5532 - accuracy: 0.7308 - mean_squared_error: 0.2692Epoch 107/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5106 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 103/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5600 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5257 - accuracy: 0.7321 - mean_squared_error: 0.2679Epoch 108/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4824 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5192 - accuracy: 0.7535 - mean_squared_error: 0.2465Epoch 106/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5234 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5719 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 109/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5599 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5689 - accuracy: 0.7427 - mean_squared_error: 0.2573Epoch 114/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5057 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5714 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 108/150\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5704 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 106/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4898 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5865 - accuracy: 0.7292 - mean_squared_error: 0.2708Epoch 108/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5674 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5900 - accuracy: 0.7250 - mean_squared_error: 0.2750Epoch 104/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4697 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5614 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4682 - accuracy: 0.7522 - mean_squared_error: 0.2478Epoch 109/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4207 - accuracy: 0.8750 - mean_squared_error: 0.1250Epoch 107/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5097 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5574 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 110/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4629 - accuracy: 0.7559 - mean_squared_error: 0.2441Epoch 115/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4982 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4665 - accuracy: 0.7518 - mean_squared_error: 0.2482Epoch 109/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4774 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5537 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 109/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5685 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5717 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5422 - accuracy: 0.7740 - mean_squared_error: 0.2260Epoch 105/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5537 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5608 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5197 - accuracy: 0.7372 - mean_squared_error: 0.2628Epoch 110/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5050 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5156 - accuracy: 0.7370 - mean_squared_error: 0.2630Epoch 108/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5616 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.4421 - accuracy: 0.7617 - mean_squared_error: 0.2383Epoch 116/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4864 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5138 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.4842 - accuracy: 0.7431 - mean_squared_error: 0.2569Epoch 110/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5676 - accuracy: 0.7441 - mean_squared_error: 0.2559Epoch 111/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4860 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5663 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5676 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 110/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4913 - accuracy: 0.7487 - mean_squared_error: 0.2513Epoch 106/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.4978 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 108/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5588 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.5583 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.4942 - accuracy: 0.7320 - mean_squared_error: 0.2680Epoch 111/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5089 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 117/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5008 - accuracy: 0.7630 - mean_squared_error: 0.2370Epoch 109/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4923 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5177 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 111/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5068 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5166 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5790 - accuracy: 0.7420 - mean_squared_error: 0.2580Epoch 111/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5733 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 112/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5737 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.3870 - accuracy: 0.8047 - mean_squared_error: 0.1953Epoch 109/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5672 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 107/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5597 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4987 - accuracy: 0.7312 - mean_squared_error: 0.2688Epoch 118/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5647 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5030 - accuracy: 0.7301 - mean_squared_error: 0.2699Epoch 112/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5397 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5620 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 110/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4901 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5403 - accuracy: 0.7714 - mean_squared_error: 0.2286Epoch 112/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4822 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5242 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.4296 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 112/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5348 - accuracy: 0.6562 - mean_squared_error: 0.3438Epoch 113/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5663 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5677 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5610 - accuracy: 0.7511 - mean_squared_error: 0.2489Epoch 110/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5466 - accuracy: 0.7526 - mean_squared_error: 0.2474Epoch 108/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5569 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5575 - accuracy: 0.7585 - mean_squared_error: 0.2415Epoch 119/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5625 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5477 - accuracy: 0.7674 - mean_squared_error: 0.2326Epoch 113/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5681 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 111/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.4936 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 113/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4917 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5490 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 113/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5693 - accuracy: 0.7483 - mean_squared_error: 0.2517Epoch 114/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5694 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5725 - accuracy: 0.7424 - mean_squared_error: 0.2576Epoch 109/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5678 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5616 - accuracy: 0.7581 - mean_squared_error: 0.2419Epoch 111/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5632 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5675 - accuracy: 0.7528 - mean_squared_error: 0.2472Epoch 120/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5650 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5737 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 114/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5546 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5681 - accuracy: 0.7426 - mean_squared_error: 0.2574Epoch 112/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5057 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4930 - accuracy: 0.7415 - mean_squared_error: 0.2585Epoch 114/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4873 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5605 - accuracy: 0.7549 - mean_squared_error: 0.2451Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5666 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.4987 - accuracy: 0.7625 - mean_squared_error: 0.2375Epoch 110/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5588 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5612 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.4923 - accuracy: 0.7667 - mean_squared_error: 0.2333Epoch 115/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5120 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 121/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5697 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 112/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.4858 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5061 - accuracy: 0.7528 - mean_squared_error: 0.2472Epoch 113/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5628 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5138 - accuracy: 0.7433 - mean_squared_error: 0.2567Epoch 115/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5010 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5097 - accuracy: 0.7490 - mean_squared_error: 0.2510Epoch 115/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4969 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5027 - accuracy: 0.7531 - mean_squared_error: 0.2469Epoch 115/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5663 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5590 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5632 - accuracy: 0.7517 - mean_squared_error: 0.2483Epoch 122/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5690 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4833 - accuracy: 0.7465 - mean_squared_error: 0.2535Epoch 111/150\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.4585 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 113/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5126 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.4926 - accuracy: 0.7583 - mean_squared_error: 0.2417Epoch 116/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4834 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5784 - accuracy: 0.7361 - mean_squared_error: 0.2639Epoch 114/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5625 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5667 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 116/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5012 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5694 - accuracy: 0.7444 - mean_squared_error: 0.2556Epoch 116/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4942 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5578 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.4822 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 116/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5688 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 123/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5693 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5687 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.4824 - accuracy: 0.7524 - mean_squared_error: 0.2476Epoch 114/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5187 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 112/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5206 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.6174 - accuracy: 0.6953 - mean_squared_error: 0.3047Epoch 117/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4894 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4786 - accuracy: 0.7566 - mean_squared_error: 0.2434Epoch 115/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5602 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5060 - accuracy: 0.7118 - mean_squared_error: 0.2882Epoch 117/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4912 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5630 - accuracy: 0.7535 - mean_squared_error: 0.2465Epoch 117/150\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5616 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.4689 - accuracy: 0.7563 - mean_squared_error: 0.2438Epoch 124/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4922 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5674 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5708 - accuracy: 0.7424 - mean_squared_error: 0.2576Epoch 117/150\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.4945 - accuracy: 0.7464 - mean_squared_error: 0.2536Epoch 115/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5677 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.4926 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 113/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5078 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5621 - accuracy: 0.7566 - mean_squared_error: 0.2434Epoch 118/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4860 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5038 - accuracy: 0.7285 - mean_squared_error: 0.2715Epoch 116/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5614 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4861 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5580 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.4925 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 125/150\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5667 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 118/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4893 - accuracy: 0.7513 - mean_squared_error: 0.2487Epoch 118/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4708 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.4324 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 118/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5685 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.6284 - accuracy: 0.6979 - mean_squared_error: 0.3021Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5033 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5680 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.5866 - accuracy: 0.7219 - mean_squared_error: 0.2781Epoch 114/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4806 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 117/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.7148 - accuracy: 0.6562 - mean_squared_error: 0.3438Epoch 119/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5623 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5015 - accuracy: 0.7348 - mean_squared_error: 0.2652Epoch 126/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4978 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5618 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 119/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4858 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 119/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4723 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5196 - accuracy: 0.7031 - mean_squared_error: 0.2969Epoch 119/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5658 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5614 - accuracy: 0.7509 - mean_squared_error: 0.2491Epoch 117/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5676 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5067 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5208 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 120/150\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5034 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 115/150\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.4892 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 118/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5599 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5687 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 127/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4947 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5605 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 120/150\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5505 - accuracy: 0.7612 - mean_squared_error: 0.2388Epoch 120/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4929 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5655 - accuracy: 0.7469 - mean_squared_error: 0.2531Epoch 120/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5687 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4795 - accuracy: 0.7471 - mean_squared_error: 0.2529Epoch 118/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5673 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.6801 - accuracy: 0.6354 - mean_squared_error: 0.3646Epoch 116/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5017 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.6593 - accuracy: 0.6562 - mean_squared_error: 0.3438Epoch 121/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4818 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.5673 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 119/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5595 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5580 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 128/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5602 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.4925 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5204 - accuracy: 0.7386 - mean_squared_error: 0.2614Epoch 121/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4676 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5560 - accuracy: 0.7569 - mean_squared_error: 0.2431Epoch 121/150\n",
      " 1/39 [..............................] - ETA: 3s - loss: 0.6069 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 121/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5652 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5948 - accuracy: 0.7284 - mean_squared_error: 0.2716Epoch 119/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5685 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5837 - accuracy: 0.7378 - mean_squared_error: 0.2622Epoch 117/150\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5104 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.4801 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5836 - accuracy: 0.7358 - mean_squared_error: 0.2642Epoch 120/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5571 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4539 - accuracy: 0.7533 - mean_squared_error: 0.2467Epoch 129/150\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4786 - accuracy: 0.7465 - mean_squared_error: 0.2535Epoch 122/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4965 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5602 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 122/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5626 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.4568 - accuracy: 0.7539 - mean_squared_error: 0.2461Epoch 122/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.4623 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5665 - accuracy: 0.7483 - mean_squared_error: 0.2517Epoch 122/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5690 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.5214 - accuracy: 0.7917 - mean_squared_error: 0.2083Epoch 120/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5689 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5459 - accuracy: 0.7668 - mean_squared_error: 0.2332Epoch 118/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5173 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.4773 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.4971 - accuracy: 0.7425 - mean_squared_error: 0.2575Epoch 123/150\n",
      " 1/39 [..............................] - ETA: 6s - loss: 0.5119 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 121/150\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.5602 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.4959 - accuracy: 0.7414 - mean_squared_error: 0.2586Epoch 130/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 42ms/step - loss: 0.4983 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5587 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.4842 - accuracy: 0.7383 - mean_squared_error: 0.2617Epoch 123/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4952 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 123/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5707 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.5707 - accuracy: 0.7438 - mean_squared_error: 0.2562Epoch 121/150\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.5160 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5710 - accuracy: 0.7432 - mean_squared_error: 0.2568Epoch 123/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5690 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5386 - accuracy: 0.7472 - mean_squared_error: 0.2528Epoch 119/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5402 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5591 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.4806 - accuracy: 0.7476 - mean_squared_error: 0.2524Epoch 124/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.4777 - accuracy: 0.7483 - mean_squared_error: 0.2517Epoch 131/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4791 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.6137 - accuracy: 0.7098 - mean_squared_error: 0.2902Epoch 122/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4954 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5817 - accuracy: 0.7310 - mean_squared_error: 0.2690Epoch 124/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5687 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5609 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 122/150\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.4647 - accuracy: 0.7457 - mean_squared_error: 0.2543Epoch 124/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4867 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5678 - accuracy: 0.7442 - mean_squared_error: 0.2558Epoch 124/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5667 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.4263 - accuracy: 0.7656 - mean_squared_error: 0.2344Epoch 120/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5615 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.4538 - accuracy: 0.7598 - mean_squared_error: 0.2402Epoch 132/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5207 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 125/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4812 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5552 - accuracy: 0.7587 - mean_squared_error: 0.2413Epoch 123/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4909 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5431 - accuracy: 0.7677 - mean_squared_error: 0.2323Epoch 125/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5603 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5513 - accuracy: 0.7640 - mean_squared_error: 0.2360Epoch 125/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5670 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5597 - accuracy: 0.7568 - mean_squared_error: 0.2432Epoch 123/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4754 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5617 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5760 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 133/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5117 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4964 - accuracy: 0.7363 - mean_squared_error: 0.2637Epoch 125/150\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.4707 - accuracy: 0.7441 - mean_squared_error: 0.2559Epoch 126/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5659 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.4817 - accuracy: 0.7326 - mean_squared_error: 0.2674Epoch 121/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.4888 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5561 - accuracy: 0.7545 - mean_squared_error: 0.2455Epoch 124/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5607 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.4848 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5608 - accuracy: 0.7546 - mean_squared_error: 0.2454Epoch 126/150\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5300 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 126/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4670 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5726 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5219 - accuracy: 0.7454 - mean_squared_error: 0.2546Epoch 126/150\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5283 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 124/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5596 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5667 - accuracy: 0.7460 - mean_squared_error: 0.2540Epoch 134/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5212 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 127/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4761 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.5676 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 125/150\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5690 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 122/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4959 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5167 - accuracy: 0.7443 - mean_squared_error: 0.2557Epoch 127/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5601 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5732 - accuracy: 0.7418 - mean_squared_error: 0.2582Epoch 127/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4719 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5111 - accuracy: 0.7450 - mean_squared_error: 0.2550Epoch 127/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5575 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5681 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5141 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 135/150\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.5583 - accuracy: 0.7531 - mean_squared_error: 0.2469Epoch 125/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 41ms/step - loss: 0.5151 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5678 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5703 - accuracy: 0.7463 - mean_squared_error: 0.2537Epoch 128/150\n",
      "39/39 [==============================] - 2s 38ms/step - loss: 0.4731 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5588 - accuracy: 0.7566 - mean_squared_error: 0.2434Epoch 126/150\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5133 - accuracy: 0.7250 - mean_squared_error: 0.2750Epoch 123/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.4933 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.4934 - accuracy: 0.7684 - mean_squared_error: 0.2316Epoch 128/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5598 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.4834 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 128/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4730 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5688 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5683 - accuracy: 0.7452 - mean_squared_error: 0.2548Epoch 128/150\n",
      " 1/39 [..............................] - ETA: 2s - loss: 0.6210 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 126/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5606 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5639 - accuracy: 0.7490 - mean_squared_error: 0.2510Epoch 136/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5167 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5578 - accuracy: 0.7587 - mean_squared_error: 0.2413Epoch 129/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5672 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5525 - accuracy: 0.7617 - mean_squared_error: 0.2383Epoch 124/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4660 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5927 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 127/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4942 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5501 - accuracy: 0.7627 - mean_squared_error: 0.2373Epoch 129/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5607 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5339 - accuracy: 0.7378 - mean_squared_error: 0.2622Epoch 129/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4777 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4719 - accuracy: 0.7512 - mean_squared_error: 0.2488Epoch 129/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5587 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5667 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.4953 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 137/150\n",
      "13/39 [=========>....................] - ETA: 1s - loss: 0.5348 - accuracy: 0.7260 - mean_squared_error: 0.2740Epoch 127/150\n",
      "39/39 [==============================] - 3s 69ms/step - loss: 0.5302 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 3s 68ms/step - loss: 0.5663 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5196 - accuracy: 0.7299 - mean_squared_error: 0.2701Epoch 130/150\n",
      "39/39 [==============================] - 3s 68ms/step - loss: 0.4731 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 125/150\n",
      "18/39 [============>.................] - ETA: 2s - loss: 0.5052 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 128/150\n",
      "39/39 [==============================] - 3s 77ms/step - loss: 0.4968 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "28/39 [====================>.........] - ETA: 1s - loss: 0.4749 - accuracy: 0.7467 - mean_squared_error: 0.2533Epoch 130/150\n",
      "39/39 [==============================] - 4s 94ms/step - loss: 0.5596 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "18/39 [============>.................] - ETA: 2s - loss: 0.5498 - accuracy: 0.7309 - mean_squared_error: 0.2691Epoch 130/150\n",
      "39/39 [==============================] - 4s 94ms/step - loss: 0.5608 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "13/39 [=========>....................] - ETA: 2s - loss: 0.5006 - accuracy: 0.7308 - mean_squared_error: 0.2692Epoch 138/150\n",
      "39/39 [==============================] - 4s 97ms/step - loss: 0.4746 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "15/39 [==========>...................] - ETA: 2s - loss: 0.5081 - accuracy: 0.7229 - mean_squared_error: 0.2771Epoch 130/150\n",
      "39/39 [==============================] - 4s 99ms/step - loss: 0.5682 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "16/39 [===========>..................] - ETA: 1s - loss: 0.5082 - accuracy: 0.7305 - mean_squared_error: 0.2695Epoch 128/150\n",
      "39/39 [==============================] - 2s 64ms/step - loss: 0.5678 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 2s 62ms/step - loss: 0.4717 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5621 - accuracy: 0.7559 - mean_squared_error: 0.2441Epoch 129/150\n",
      "39/39 [==============================] - 3s 67ms/step - loss: 0.5362 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5420 - accuracy: 0.7716 - mean_squared_error: 0.2284Epoch 131/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6007 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 126/150\n",
      "39/39 [==============================] - 2s 53ms/step - loss: 0.4976 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 131/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5555 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.4746 - accuracy: 0.7528 - mean_squared_error: 0.2472Epoch 131/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4779 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.7475 - mean_squared_error: 0.2525Epoch 131/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5689 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.7541 - mean_squared_error: 0.2459Epoch 129/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.5598 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4723 - accuracy: 0.7491 - mean_squared_error: 0.2509Epoch 139/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5673 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4787 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5810 - accuracy: 0.7383 - mean_squared_error: 0.2617Epoch 127/150\n",
      " 1/39 [..............................] - ETA: 2s - loss: 0.6351 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 130/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5252 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4730 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 132/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5005 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5595 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 132/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5605 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5666 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 132/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5608 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 5/39 [==>...........................] - ETA: 2s - loss: 0.6432 - accuracy: 0.6813 - mean_squared_error: 0.3187Epoch 140/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5698 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5058 - accuracy: 0.7363 - mean_squared_error: 0.2637Epoch 130/150\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.4707 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5236 - accuracy: 0.7349 - mean_squared_error: 0.2651Epoch 132/150\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5675 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.4716 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 128/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5202 - accuracy: 0.7402 - mean_squared_error: 0.2598Epoch 131/150\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 0.5162 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 7/39 [====>.........................] - ETA: 2s - loss: 0.4464 - accuracy: 0.7634 - mean_squared_error: 0.2366Epoch 133/150\n",
      "39/39 [==============================] - 2s 48ms/step - loss: 0.4929 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "18/39 [============>.................] - ETA: 1s - loss: 0.5539 - accuracy: 0.7587 - mean_squared_error: 0.2413Epoch 133/150\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 0.5645 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5583 - accuracy: 0.7561 - mean_squared_error: 0.2439Epoch 133/150\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 0.5601 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 141/150\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 0.4790 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 2s 51ms/step - loss: 0.5670 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 133/150\n",
      " 7/39 [====>.........................] - ETA: 2s - loss: 0.5322 - accuracy: 0.7813 - mean_squared_error: 0.2188Epoch 131/150\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 0.5687 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 0.4785 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "14/39 [=========>....................] - ETA: 1s - loss: 0.5311 - accuracy: 0.7790 - mean_squared_error: 0.2210Epoch 132/150\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.4813 - accuracy: 0.7031 - mean_squared_error: 0.2969Epoch 129/150\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 0.5179 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5566 - accuracy: 0.7548 - mean_squared_error: 0.2452Epoch 134/150\n",
      "39/39 [==============================] - 2s 48ms/step - loss: 0.4919 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5780 - accuracy: 0.7359 - mean_squared_error: 0.2641Epoch 134/150\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 0.5618 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4785 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 134/150\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.5600 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.4737 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5718 - accuracy: 0.7417 - mean_squared_error: 0.2583Epoch 142/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5682 - accuracy: 0.7441 - mean_squared_error: 0.2559Epoch 134/150\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.5652 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5070 - accuracy: 0.7546 - mean_squared_error: 0.2454Epoch 132/150\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5672 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.5710 - accuracy: 0.7438 - mean_squared_error: 0.2562Epoch 130/150\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.4743 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5901 - accuracy: 0.7240 - mean_squared_error: 0.2760Epoch 133/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.5073 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4986 - accuracy: 0.7348 - mean_squared_error: 0.2652Epoch 135/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4933 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5548 - accuracy: 0.7582 - mean_squared_error: 0.2418Epoch 135/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5605 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5611 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.4779 - accuracy: 0.7466 - mean_squared_error: 0.2534Epoch 143/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4720 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.4797 - accuracy: 0.7431 - mean_squared_error: 0.2569Epoch 135/150\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.4663 - accuracy: 0.7457 - mean_squared_error: 0.2543Epoch 135/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5663 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 133/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5672 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4727 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 131/150\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7688 - mean_squared_error: 0.2313Epoch 134/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5244 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5490 - accuracy: 0.7649 - mean_squared_error: 0.2351Epoch 136/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4794 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.4762 - accuracy: 0.7510 - mean_squared_error: 0.2490Epoch 136/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5614 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5772 - accuracy: 0.7392 - mean_squared_error: 0.2608Epoch 144/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5626 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4880 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5203 - accuracy: 0.7604 - mean_squared_error: 0.2396Epoch 136/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5646 - accuracy: 0.7483 - mean_squared_error: 0.2517Epoch 136/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5674 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5701 - accuracy: 0.7463 - mean_squared_error: 0.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/150\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.4839 - accuracy: 0.7277 - mean_squared_error: 0.2723Epoch 134/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4727 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 135/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5257 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.4859 - accuracy: 0.7359 - mean_squared_error: 0.2641Epoch 137/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4860 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5586 - accuracy: 0.7558 - mean_squared_error: 0.2442Epoch 137/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5601 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5089 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 145/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5600 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5594 - accuracy: 0.7557 - mean_squared_error: 0.2443Epoch 137/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5698 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.4711 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 135/150\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.6908 - accuracy: 0.6354 - mean_squared_error: 0.3646Epoch 137/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5674 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4781 - accuracy: 0.7463 - mean_squared_error: 0.2537Epoch 133/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4781 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.6171 - accuracy: 0.7009 - mean_squared_error: 0.2991Epoch 136/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5275 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5752 - accuracy: 0.7388 - mean_squared_error: 0.2612Epoch 138/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5032 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5607 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5663 - accuracy: 0.7450 - mean_squared_error: 0.2550Epoch 146/150\n",
      "12/39 [========>.....................] - ETA: 1s - loss: 0.5340 - accuracy: 0.7318 - mean_squared_error: 0.2682Epoch 138/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5661 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.4714 - accuracy: 0.7420 - mean_squared_error: 0.2580Epoch 136/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5594 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4712 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.4662 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 138/150\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.4808 - accuracy: 0.7361 - mean_squared_error: 0.2639Epoch 138/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5691 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4504 - accuracy: 0.7438 - mean_squared_error: 0.2562Epoch 134/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.4810 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5705 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 137/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5191 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4932 - accuracy: 0.7488 - mean_squared_error: 0.2512Epoch 139/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5601 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5684 - accuracy: 0.7480 - mean_squared_error: 0.2520Epoch 147/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4893 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.5801 - accuracy: 0.7321 - mean_squared_error: 0.2679Epoch 139/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5704 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.5272 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 137/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5584 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5135 - accuracy: 0.7031 - mean_squared_error: 0.2969Epoch 139/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4717 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.4612 - accuracy: 0.7623 - mean_squared_error: 0.2377Epoch 139/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5687 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4752 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4390 - accuracy: 0.7875 - mean_squared_error: 0.2125Epoch 135/150\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5061 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 138/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5245 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5054 - accuracy: 0.7284 - mean_squared_error: 0.2716Epoch 140/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5582 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 148/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5671 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.4757 - accuracy: 0.7361 - mean_squared_error: 0.2639Epoch 138/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4878 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4662 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.5747 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 140/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5119 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 140/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5596 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.4697 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 140/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5685 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5388 - accuracy: 0.7277 - mean_squared_error: 0.2723Epoch 136/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4740 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5618 - accuracy: 0.7555 - mean_squared_error: 0.2445Epoch 139/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5183 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5615 - accuracy: 0.7535 - mean_squared_error: 0.2465Epoch 141/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5606 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.4419 - accuracy: 0.7688 - mean_squared_error: 0.2313Epoch 149/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4646 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5620 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5631 - accuracy: 0.7477 - mean_squared_error: 0.2523Epoch 141/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5703 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.4996 - accuracy: 0.7384 - mean_squared_error: 0.2616Epoch 141/150\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5481 - accuracy: 0.7596 - mean_squared_error: 0.2404Epoch 139/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4944 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.4472 - accuracy: 0.7656 - mean_squared_error: 0.2344Epoch 141/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5664 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5894 - accuracy: 0.7266 - mean_squared_error: 0.2734Epoch 137/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4728 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5444 - accuracy: 0.7656 - mean_squared_error: 0.2344Epoch 140/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5154 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5659 - accuracy: 0.7475 - mean_squared_error: 0.2525Epoch 142/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5558 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5647 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 150/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5591 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4864 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5757 - accuracy: 0.7387 - mean_squared_error: 0.2612Epoch 142/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5697 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5002 - accuracy: 0.7393 - mean_squared_error: 0.2607Epoch 140/150\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.4472 - accuracy: 0.8542 - mean_squared_error: 0.1458Epoch 142/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5011 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.5432 - accuracy: 0.7708 - mean_squared_error: 0.2292Epoch 142/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5679 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5805 - accuracy: 0.7358 - mean_squared_error: 0.2642Epoch 138/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4637 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5668 - accuracy: 0.7477 - mean_squared_error: 0.2523Epoch 141/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5157 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5021 - accuracy: 0.7109 - mean_squared_error: 0.2891Epoch 143/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5590 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5482 - accuracy: 0.7644 - mean_squared_error: 0.2356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5615 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.4788 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5736 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 143/150\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5615 - accuracy: 0.7520 - mean_squared_error: 0.2480Epoch 143/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4913 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5688 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5657 - accuracy: 0.7482 - mean_squared_error: 0.2518Epoch 143/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.4283 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 141/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5683 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.4860 - accuracy: 0.7318 - mean_squared_error: 0.2682Epoch 139/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4764 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5112 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 142/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5796 - accuracy: 0.7366 - mean_squared_error: 0.2634Epoch 144/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4440 - accuracy: 0.7656 - mean_squared_error: 0.2344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:08.034454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5604 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4833 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.4736 - accuracy: 0.7386 - mean_squared_error: 0.2614Epoch 144/150\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.4754 - accuracy: 0.7359 - mean_squared_error: 0.2641Epoch 144/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5690 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4815 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5637 - accuracy: 0.7517 - mean_squared_error: 0.2483Epoch 142/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4869 - accuracy: 0.8125 - mean_squared_error: 0.1875Epoch 144/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5700 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.4901 - accuracy: 0.8177 - mean_squared_error: 0.1823Epoch 140/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4787 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5111 - accuracy: 0.7031 - mean_squared_error: 0.2969Epoch 143/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5235 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5363 - accuracy: 0.7750 - mean_squared_error: 0.2250Epoch 145/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.4765 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5636 - accuracy: 0.7491 - mean_squared_error: 0.2509Epoch 145/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5606 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.4847 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 145/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5666 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5635 - accuracy: 0.7481 - mean_squared_error: 0.2519Epoch 143/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.4919 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5668 - accuracy: 0.7457 - mean_squared_error: 0.2543Epoch 145/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5676 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5849 - accuracy: 0.7257 - mean_squared_error: 0.2743Epoch 141/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5029 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.4819 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 146/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4755 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.4803 - accuracy: 0.7380 - mean_squared_error: 0.2620Epoch 144/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4782 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4864 - accuracy: 0.7433 - mean_squared_error: 0.2567Epoch 146/150\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.4869 - accuracy: 0.7411 - mean_squared_error: 0.2589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:10.930979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5576 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5672 - accuracy: 0.7455 - mean_squared_error: 0.2545Epoch 146/150\n",
      " 1/39 [..............................] - ETA: 1s - loss: 0.5573 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 1/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5671 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4780 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5064 - accuracy: 0.7548 - mean_squared_error: 0.2452Epoch 144/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5674 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 146/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5671 - accuracy: 0.7478 - mean_squared_error: 0.2522Epoch 142/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5108 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4747 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 147/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5059 - accuracy: 0.7545 - mean_squared_error: 0.2455Epoch 145/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4749 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5818 - accuracy: 0.7349 - mean_squared_error: 0.2651Epoch 147/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5592 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.4833 - accuracy: 0.7512 - mean_squared_error: 0.2488Epoch 147/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5681 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5671 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 145/150\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.4711 - accuracy: 0.7630 - mean_squared_error: 0.2370Epoch 143/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4927 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.4848 - accuracy: 0.7409 - mean_squared_error: 0.2591Epoch 147/150\n",
      "39/39 [==============================] - 3s 46ms/step - loss: 0.6309 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5154 - accuracy: 0.7432 - mean_squared_error: 0.2568Epoch 2/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5145 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4784 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 148/150\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5677 - accuracy: 0.7452 - mean_squared_error: 0.2548Epoch 146/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4873 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.4832 - accuracy: 0.7625 - mean_squared_error: 0.2375Epoch 148/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5583 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "11/39 [=======>......................] - ETA: 1s - loss: 0.4919 - accuracy: 0.7557 - mean_squared_error: 0.2443Epoch 148/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5663 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5025 - accuracy: 0.7435 - mean_squared_error: 0.2565Epoch 146/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5683 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5019 - accuracy: 0.7393 - mean_squared_error: 0.2607Epoch 144/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.6004 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5629 - accuracy: 0.7526 - mean_squared_error: 0.2474Epoch 3/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4927 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4712 - accuracy: 0.7529 - mean_squared_error: 0.2471Epoch 148/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5291 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4795 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 149/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4774 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 147/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4828 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5660 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 149/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5679 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.4938 - accuracy: 0.7362 - mean_squared_error: 0.2637Epoch 147/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5590 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5659 - accuracy: 0.7459 - mean_squared_error: 0.2541Epoch 149/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5666 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5165 - accuracy: 0.7207 - mean_squared_error: 0.2793Epoch 145/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5963 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4900 - accuracy: 0.7415 - mean_squared_error: 0.2585Epoch 4/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4969 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 9/39 [=====>........................] - ETA: 1s - loss: 0.5544 - accuracy: 0.7674 - mean_squared_error: 0.2326Epoch 149/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5185 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.4970 - accuracy: 0.7143 - mean_squared_error: 0.2857Epoch 150/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4799 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 148/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.4674 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 150/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5685 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.6045 - accuracy: 0.7454 - mean_squared_error: 0.2546Epoch 148/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5672 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.6035 - accuracy: 0.7449 - mean_squared_error: 0.2551Epoch 146/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5631 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5423 - accuracy: 0.7708 - mean_squared_error: 0.2292Epoch 150/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.6011 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.4859 - accuracy: 0.7438 - mean_squared_error: 0.2563Epoch 5/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5174 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4914 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.6245 - accuracy: 0.7312 - mean_squared_error: 0.2688Epoch 150/150\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5619 - accuracy: 0.7500 - mean_squared_error: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.4850 - accuracy: 0.7511 - mean_squared_error: 0.2489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.6147 - accuracy: 0.7356 - mean_squared_error: 0.2644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.4728 - accuracy: 0.7353 - mean_squared_error: 0.2647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5792 - accuracy: 0.7391 - mean_squared_error: 0.2609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5672 - accuracy: 0.7453 - mean_squared_error: 0.2547\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.4713 - accuracy: 0.7375 - mean_squared_error: 0.2625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.4860 - accuracy: 0.7510 - mean_squared_error: 0.2490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.6015 - accuracy: 0.7458 - mean_squared_error: 0.2542\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5803 - accuracy: 0.7372 - mean_squared_error: 0.2628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5672 - accuracy: 0.7451 - mean_squared_error: 0.2549\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.4725 - accuracy: 0.7383 - mean_squared_error: 0.2617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.4725 - accuracy: 0.7375 - mean_squared_error: 0.2625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.4880 - accuracy: 0.7471 - mean_squared_error: 0.2529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.5632 - accuracy: 0.7484 - mean_squared_error: 0.2516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5711 - accuracy: 0.7461 - mean_squared_error: 0.2539\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5661 - accuracy: 0.7457 - mean_squared_error: 0.2543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.4876 - accuracy: 0.7481 - mean_squared_error: 0.2519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.4689 - accuracy: 0.7405 - mean_squared_error: 0.2595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:17.083077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.6024 - accuracy: 0.7461 - mean_squared_error: 0.2539\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.4595 - accuracy: 0.7465 - mean_squared_error: 0.2535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5569 - accuracy: 0.7543 - mean_squared_error: 0.2457\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5677 - accuracy: 0.7500 - mean_squared_error: 0.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5774 - accuracy: 0.7357 - mean_squared_error: 0.2643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.4815 - accuracy: 0.7482 - mean_squared_error: 0.2518\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.4659 - accuracy: 0.7449 - mean_squared_error: 0.2551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "19/39 [=============>................] - ETA: 0s - loss: 0.6174 - accuracy: 0.7336 - mean_squared_error: 0.2664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.4696 - accuracy: 0.7526 - mean_squared_error: 0.2474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5551 - accuracy: 0.7575 - mean_squared_error: 0.2425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5665 - accuracy: 0.7500 - mean_squared_error: 0.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5713 - accuracy: 0.7419 - mean_squared_error: 0.2581\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/39 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.7475 - mean_squared_error: 0.2525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.4754 - accuracy: 0.7455 - mean_squared_error: 0.2545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.6111 - accuracy: 0.7381 - mean_squared_error: 0.2619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.7463 - mean_squared_error: 0.2537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.4665 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5554 - accuracy: 0.7578 - mean_squared_error: 0.2422Epoch 149/150\n",
      "\r",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6973 - accuracy: 0.6562 - mean_squared_error: 0.3438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5632 - accuracy: 0.7490 - mean_squared_error: 0.2510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.7471 - mean_squared_error: 0.2529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4838 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "24/39 [=================>............] - ETA: 0s - loss: 0.6216 - accuracy: 0.7279 - mean_squared_error: 0.2721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.4676 - accuracy: 0.7500 - mean_squared_error: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5670 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5540 - accuracy: 0.7589 - mean_squared_error: 0.2411Epoch 147/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5706 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.6074 - accuracy: 0.7409 - mean_squared_error: 0.2591Epoch 149/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5592 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4916 - accuracy: 0.7351 - mean_squared_error: 0.2649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "2021-12-23 19:32:17.876228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5961 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5980 - accuracy: 0.7227 - mean_squared_error: 0.2773Epoch 6/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.4891 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5605 - accuracy: 0.7542 - mean_squared_error: 0.2458"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "2021-12-23 19:32:18.104305: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4698 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "Epoch 150/150\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.6009 - accuracy: 0.7375 - mean_squared_error: 0.2625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:18.542696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5651 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5706 - accuracy: 0.7426 - mean_squared_error: 0.2574Epoch 148/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5659 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5890 - accuracy: 0.7437 - mean_squared_error: 0.2562Epoch 150/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5844 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "16/39 [===========>..................] - ETA: 1s - loss: 0.4634 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 7/150\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5851 - accuracy: 0.7305 - mean_squared_error: 0.2695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:19.133380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 29ms/step - loss: 0.4624 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.5463 - accuracy: 0.7667 - mean_squared_error: 0.2333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5676 - accuracy: 0.7459 - mean_squared_error: 0.2541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5663 - accuracy: 0.7608 - mean_squared_error: 0.2392\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5517 - accuracy: 0.7615 - mean_squared_error: 0.2385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5683 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 149/150\n",
      "\r",
      " 1/39 [..............................] - ETA: 1s - loss: 0.6304 - accuracy: 0.6875 - mean_squared_error: 0.3125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5734 - accuracy: 0.7549 - mean_squared_error: 0.2451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5617 - accuracy: 0.7520 - mean_squared_error: 0.2480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.6117 - accuracy: 0.7031 - mean_squared_error: 0.2969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5696 - accuracy: 0.7454 - mean_squared_error: 0.2546\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5740 - accuracy: 0.7546 - mean_squared_error: 0.2454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.6012 - accuracy: 0.7109 - mean_squared_error: 0.2891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:19.780332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5665 - accuracy: 0.7483 - mean_squared_error: 0.2517\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5817 - accuracy: 0.7517 - mean_squared_error: 0.2483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5688 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5868 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.5695 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 8/150\n",
      "\r",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5198 - accuracy: 0.7812 - mean_squared_error: 0.2188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5841 - accuracy: 0.7281 - mean_squared_error: 0.2719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3/39 [=>............................] - ETA: 1s - loss: 0.4998 - accuracy: 0.8229 - mean_squared_error: 0.1771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5859 - accuracy: 0.7284 - mean_squared_error: 0.2716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5551 - accuracy: 0.7812 - mean_squared_error: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "2021-12-23 19:32:20.030657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:32:20.157329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5835 - accuracy: 0.7305 - mean_squared_error: 0.2695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.5514 - accuracy: 0.7857 - mean_squared_error: 0.2143\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5696 - accuracy: 0.7431 - mean_squared_error: 0.2569\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5826 - accuracy: 0.7594 - mean_squared_error: 0.2406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5643 - accuracy: 0.7485 - mean_squared_error: 0.2515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5881 - accuracy: 0.7526 - mean_squared_error: 0.2474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5683 - accuracy: 0.7448 - mean_squared_error: 0.2552\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.5822 - accuracy: 0.7559 - mean_squared_error: 0.2441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:20.316307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-23 19:32:20.324987: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/39 [============>.................] - ETA: 0s - loss: 0.5762 - accuracy: 0.7569 - mean_squared_error: 0.2431Epoch 1/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5674 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.7162 - accuracy: 0.7359 - mean_squared_error: 0.2641Epoch 150/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5867 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.7109 - accuracy: 0.7338 - mean_squared_error: 0.2662Epoch 9/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5750 - accuracy: 0.7516 - mean_squared_error: 0.2484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:21.242938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 22ms/step - loss: 0.5669 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5783 - accuracy: 0.7528 - mean_squared_error: 0.2472Epoch 1/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5792 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 1/150\n",
      " 1/39 [..............................] - ETA: 1:38 - loss: 0.6411 - accuracy: 0.7500 - mean_squared_error: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenico/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "2021-12-23 19:32:21.671085: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.7416 - accuracy: 0.6938 - mean_squared_error: 0.3063\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/39 [>.............................] - ETA: 2s - loss: 0.6583 - accuracy: 0.6875 - mean_squared_error: 0.3125  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5785 - accuracy: 0.7508 - mean_squared_error: 0.2492Epoch 1/150\n",
      "\r",
      " 1/39 [..............................] - ETA: 1:30 - loss: 0.6606 - accuracy: 0.7188 - mean_squared_error: 0.2812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.7388 - accuracy: 0.7009 - mean_squared_error: 0.2991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.6414 - accuracy: 0.6953 - mean_squared_error: 0.3047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - ETA: 0s - loss: 0.5826 - accuracy: 0.7471 - mean_squared_error: 0.2529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.5826 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "Epoch 10/150\n",
      "\r",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4908 - accuracy: 0.8438 - mean_squared_error: 0.1562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.7538 - accuracy: 0.7312 - mean_squared_error: 0.2688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5694 - accuracy: 0.7578 - mean_squared_error: 0.2422  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.6471 - accuracy: 0.7143 - mean_squared_error: 0.2857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.7560 - accuracy: 0.7478 - mean_squared_error: 0.2522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.6333 - accuracy: 0.7321 - mean_squared_error: 0.2679\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.5320 - accuracy: 0.7875 - mean_squared_error: 0.2125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:21.866499: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 4s 46ms/step - loss: 0.7036 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 2/150\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.6660 - accuracy: 0.7614 - mean_squared_error: 0.2386Epoch 1/150\n",
      "39/39 [==============================] - 4s 27ms/step - loss: 0.5975 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.5818 - accuracy: 0.7482 - mean_squared_error: 0.2518Epoch 2/150\n",
      "39/39 [==============================] - 3s 28ms/step - loss: 0.5646 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.6667 - accuracy: 0.7489 - mean_squared_error: 0.2511Epoch 2/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5841 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5555 - accuracy: 0.7594 - mean_squared_error: 0.2406Epoch 11/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.6656 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.5529 - accuracy: 0.7370 - mean_squared_error: 0.2630Epoch 3/150\n",
      "39/39 [==============================] - 4s 48ms/step - loss: 0.7253 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.5512 - accuracy: 0.7362 - mean_squared_error: 0.2637Epoch 2/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6961 - accuracy: 0.6250 - mean_squared_error: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 19:32:23.455374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 3s 23ms/step - loss: 0.6451 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.6778 - accuracy: 0.7750 - mean_squared_error: 0.2250Epoch 1/150\n",
      " 1/39 [..............................] - ETA: 1:32 - loss: 0.7832 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 2/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5456 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "12/39 [========>.....................] - ETA: 0s - loss: 0.7773 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 3/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5364 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.7537 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 3/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5900 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5277 - accuracy: 0.7461 - mean_squared_error: 0.2539Epoch 12/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.6689 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.6348 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 3/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5240 - accuracy: 0.7401 - mean_squared_error: 0.2599Epoch 4/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5714 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.6236 - accuracy: 0.7404 - mean_squared_error: 0.2596Epoch 3/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5465 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.6188 - accuracy: 0.7441 - mean_squared_error: 0.2559Epoch 4/150\n",
      "39/39 [==============================] - 4s 39ms/step - loss: 0.7198 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5992 - accuracy: 0.7411 - mean_squared_error: 0.2589Epoch 2/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5188 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5995 - accuracy: 0.7361 - mean_squared_error: 0.2639Epoch 4/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5793 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.4906 - accuracy: 0.7841 - mean_squared_error: 0.2159Epoch 13/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.6362 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.5685 - accuracy: 0.7422 - mean_squared_error: 0.2578Epoch 4/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.6206 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 0.5915 - accuracy: 0.7415 - mean_squared_error: 0.2585Epoch 5/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5329 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5076 - accuracy: 0.7519 - mean_squared_error: 0.2481Epoch 4/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5456 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 3/39 [=>............................] - ETA: 0s - loss: 0.5412 - accuracy: 0.6771 - mean_squared_error: 0.3229Epoch 5/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5121 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5039 - accuracy: 0.7688 - mean_squared_error: 0.2313Epoch 5/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.6347 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.6130 - accuracy: 0.7366 - mean_squared_error: 0.2634Epoch 3/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.6136 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5841 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.6099 - accuracy: 0.7389 - mean_squared_error: 0.2611Epoch 14/150\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.6056 - accuracy: 0.7121 - mean_squared_error: 0.2879Epoch 5/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.6092 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5049 - accuracy: 0.7597 - mean_squared_error: 0.2403Epoch 6/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5171 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5211 - accuracy: 0.7303 - mean_squared_error: 0.2697Epoch 5/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5111 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5722 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.5970 - accuracy: 0.7572 - mean_squared_error: 0.2428Epoch 6/150\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5933 - accuracy: 0.7381 - mean_squared_error: 0.2619Epoch 4/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5094 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.5891 - accuracy: 0.7417 - mean_squared_error: 0.2583Epoch 6/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5990 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 6/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5820 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5201 - accuracy: 0.7368 - mean_squared_error: 0.2632Epoch 15/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.6022 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5178 - accuracy: 0.7432 - mean_squared_error: 0.2568Epoch 7/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5182 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5063 - accuracy: 0.7425 - mean_squared_error: 0.2575Epoch 6/150\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5588 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.5182 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 5/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5187 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.4910 - accuracy: 0.8063 - mean_squared_error: 0.1938Epoch 7/150\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.5118 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.6095 - accuracy: 0.7171 - mean_squared_error: 0.2829Epoch 7/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5850 - accuracy: 0.7445 - mean_squared_error: 0.2555Epoch 1/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5828 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5855 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.6043 - accuracy: 0.7292 - mean_squared_error: 0.2708Epoch 16/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6516 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 7/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5969 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4950 - accuracy: 0.7530 - mean_squared_error: 0.2470Epoch 8/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5438 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.6012 - accuracy: 0.7232 - mean_squared_error: 0.2768Epoch 6/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5341 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.6035 - accuracy: 0.7458 - mean_squared_error: 0.2542Epoch 7/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5119 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5323 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 8/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4985 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.5950 - accuracy: 0.7366 - mean_squared_error: 0.2634Epoch 8/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5790 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.5104 - accuracy: 0.7454 - mean_squared_error: 0.2546Epoch 17/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5655 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 5/39 [==>...........................] - ETA: 0s - loss: 0.5563 - accuracy: 0.7625 - mean_squared_error: 0.2375Epoch 8/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5919 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.7471 - mean_squared_error: 0.2529Epoch 9/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5070 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.5019 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.5463 - accuracy: 0.7385 - mean_squared_error: 0.2615Epoch 9/150\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5903 - accuracy: 0.7375 - mean_squared_error: 0.2625Epoch 8/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5454 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.5053 - accuracy: 0.7392 - mean_squared_error: 0.2608Epoch 7/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5009 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5187 - accuracy: 0.7535 - mean_squared_error: 0.2465Epoch 9/150\n",
      "39/39 [==============================] - 9s 63ms/step - loss: 0.5981 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5362 - accuracy: 0.7483 - mean_squared_error: 0.2517Epoch 2/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5802 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.5054 - accuracy: 0.7596 - mean_squared_error: 0.2404Epoch 18/150\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.5513 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5882 - accuracy: 0.7429 - mean_squared_error: 0.2571Epoch 9/150\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.5137 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 5/39 [==>...........................] - ETA: 1s - loss: 0.5651 - accuracy: 0.7250 - mean_squared_error: 0.2750Epoch 10/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5091 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5671 - accuracy: 0.7604 - mean_squared_error: 0.2396Epoch 9/150\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5443 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.5285 - accuracy: 0.7292 - mean_squared_error: 0.2708Epoch 8/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5891 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.5958 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 10/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5144 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5777 - accuracy: 0.7451 - mean_squared_error: 0.2549Epoch 10/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5702 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 3/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5760 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.5491 - accuracy: 0.7383 - mean_squared_error: 0.2617Epoch 19/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5443 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 8/39 [=====>........................] - ETA: 1s - loss: 0.5818 - accuracy: 0.7383 - mean_squared_error: 0.2617Epoch 10/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5150 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5956 - accuracy: 0.7277 - mean_squared_error: 0.2723Epoch 11/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5787 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5767 - accuracy: 0.7222 - mean_squared_error: 0.2778Epoch 11/150\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.4998 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5414 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 10/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.5099 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 9/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5749 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 4/150\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.5041 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.4989 - accuracy: 0.7500 - mean_squared_error: 0.2500Epoch 11/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5706 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 9/39 [=====>........................] - ETA: 0s - loss: 0.5038 - accuracy: 0.7396 - mean_squared_error: 0.2604Epoch 20/150\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5502 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.4968 - accuracy: 0.7568 - mean_squared_error: 0.2432Epoch 11/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5007 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 12/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5816 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5089 - accuracy: 0.7946 - mean_squared_error: 0.2054Epoch 12/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5015 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5262 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 11/150\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 0.5201 - accuracy: 0.7372 - mean_squared_error: 0.2628Epoch 10/150\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5172 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.5466 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5439 - accuracy: 0.7473 - mean_squared_error: 0.2527Epoch 5/150\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.4833 - accuracy: 0.7812 - mean_squared_error: 0.2188Epoch 12/150\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5768 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5582 - accuracy: 0.7240 - mean_squared_error: 0.2760Epoch 21/150\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.5442 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      " 4/39 [==>...........................] - ETA: 1s - loss: 0.6274 - accuracy: 0.6797 - mean_squared_error: 0.3203Epoch 12/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 30ms/step - loss: 0.5770 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.5373 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "Epoch 11/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.4941 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "Epoch 13/150\n",
      " 4/39 [==>...........................] - ETA: 0s - loss: 0.5414 - accuracy: 0.7266 - mean_squared_error: 0.2734Epoch 13/150\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4893 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "23/39 [================>.............] - ETA: 0s - loss: 0.5521 - accuracy: 0.7283 - mean_squared_error: 0.2717Epoch 12/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5421 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "Epoch 6/150\n",
      "39/39 [==============================] - 1s 39ms/step - loss: 0.5345 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5449 - accuracy: 0.7339 - mean_squared_error: 0.2661Epoch 13/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5771 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5382 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5266 - accuracy: 0.7063 - mean_squared_error: 0.2938Epoch 22/150\n",
      " 1/39 [..............................] - ETA: 2s - loss: 0.6178 - accuracy: 0.6875 - mean_squared_error: 0.3125Epoch 13/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5341 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.5745 - accuracy: 0.7426 - mean_squared_error: 0.2574Epoch 12/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.4963 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5096 - accuracy: 0.7279 - mean_squared_error: 0.2721Epoch 14/150\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.5756 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "19/39 [=============>................] - ETA: 0s - loss: 0.5614 - accuracy: 0.7549 - mean_squared_error: 0.2451Epoch 14/150\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.4797 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5282 - accuracy: 0.7552 - mean_squared_error: 0.2448Epoch 13/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5414 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 0.4906 - accuracy: 0.7604 - mean_squared_error: 0.2396Epoch 7/150\n",
      "39/39 [==============================] - 1s 39ms/step - loss: 0.4959 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      " 6/39 [===>..........................] - ETA: 1s - loss: 0.5095 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 14/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5729 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5324 - accuracy: 0.7319 - mean_squared_error: 0.2681Epoch 23/150\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5282 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "24/39 [=================>............] - ETA: 0s - loss: 0.5723 - accuracy: 0.7344 - mean_squared_error: 0.2656Epoch 14/150\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.5289 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "39/39 [==============================] - 1s 32ms/step - loss: 0.4973 - accuracy: 0.7543 - mean_squared_error: 0.2457\n",
      " 7/39 [====>.........................] - ETA: 1s - loss: 0.5911 - accuracy: 0.7188 - mean_squared_error: 0.2812Epoch 13/150\n",
      "10/39 [======>.......................] - ETA: 1s - loss: 0.4983 - accuracy: 0.7656 - mean_squared_error: 0.2344Epoch 15/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4795 - accuracy: 0.7471 - mean_squared_error: 0.2529\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.5675 - accuracy: 0.7398 - mean_squared_error: 0.2602\n",
      "15/39 [==========>...................] - ETA: 0s - loss: 0.5173 - accuracy: 0.7583 - mean_squared_error: 0.2417Epoch 14/150\n",
      " 6/39 [===>..........................] - ETA: 0s - loss: 0.4908 - accuracy: 0.7448 - mean_squared_error: 0.2552Epoch 15/150\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.5387 - accuracy: 0.7453 - mean_squared_error: 0.2547\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5687 - accuracy: 0.7510 - mean_squared_error: 0.2490Epoch 8/150\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5092 - accuracy: 0.7463 - mean_squared_error: 0.2537\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.5249 - accuracy: 0.7440 - mean_squared_error: 0.2560Epoch 15/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.5219 - accuracy: 0.7491 - mean_squared_error: 0.2509"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/ipykernel_9777/3298554003.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_pred_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_pred_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "best_model = nn_grid.fit(train_set, train_label)\n",
    "print(nn_grid.best_params_)\n",
    "train_pred_nn = nn_grid.predict(train_set)\n",
    "test_pred_nn = nn_grid.predict(test_set)\n",
    "print('Time taken for fit: {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa75007-22fb-4670-9425-a0b93c9f9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_label, train_pred_nn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447433a4-f77b-4d01-a4f2-f0c7884505ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_label, test_pred_nn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75187e28",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8709f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nn=best_model.best_estimator_\n",
    "history=best_nn.fit(train_set.values, train_label,\n",
    "                    epochs=120,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121cc83",
   "metadata": {},
   "source": [
    "### Print accuracy of best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69879f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training Accuracy', c='r')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy', c='b')\n",
    "plt.title('Training and validation Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf38e2a",
   "metadata": {},
   "source": [
    "### Print accuracy of best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss', c='r')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss', c='b')\n",
    "plt.title('Training and validation Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-sterling",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_no_cat = train_set.loc[:,~train_set.columns.str.contains('_num', case=False)] \n",
    "test_set_no_cat = test_set.loc[:,~test_set.columns.str.contains('_num', case=False)] \n",
    "\n",
    "k = math.sqrt(len(train_set))\n",
    "k = round(k, 0)\n",
    "k = int(k)\n",
    "k = k - 2\n",
    "k_range = []\n",
    "for i in range(0,5):\n",
    "    k_range.append(k)\n",
    "    k = k + 1\n",
    "k_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': k_range,\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "            }\n",
    "\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5, scoring=make_scorer(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.fit(train_set_no_cat, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_knn = knn_grid.predict(train_set_no_cat)\n",
    "test_pred_knn = knn_grid.predict(test_set_no_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_label, train_pred_knn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_label, test_pred_knn, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
