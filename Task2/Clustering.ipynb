{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3e0730-ffab-4604-a85f-b041d338fed7",
   "metadata": {},
   "source": [
    "# Install dependecny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a6262c-ae4e-4bf3-82c5-994327a03f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yellowbrick\n",
      "  Using cached yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from yellowbrick) (1.0.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from yellowbrick) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from yellowbrick) (1.7.3)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from yellowbrick) (0.11.0)\n",
      "Collecting numpy<1.20,>=1.16.0\n",
      "  Using cached numpy-1.19.5.zip (7.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/domenico/miniforge3/bin/python3.8 /Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py prepare_metadata_for_build_wheel /var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/tmpcw5v4m4r\n",
      "       cwd: /private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f866d9382ed449fa87863b5d358a6f13\n",
      "  Complete output (87 lines):\n",
      "  Processing numpy/random/_bounded_integers.pxd.in\n",
      "  Processing numpy/random/_philox.pyx\n",
      "  Processing numpy/random/_bounded_integers.pyx.in\n",
      "  Processing numpy/random/_sfc64.pyx\n",
      "  Processing numpy/random/_mt19937.pyx\n",
      "  Processing numpy/random/bit_generator.pyx\n",
      "  Processing numpy/random/mtrand.pyx\n",
      "  Processing numpy/random/_generator.pyx\n",
      "  Processing numpy/random/_pcg64.pyx\n",
      "  Processing numpy/random/_common.pyx\n",
      "  Cythonizing sources\n",
      "  non-existing path in 'numpy/distutils': 'site.cfg'\n",
      "  running dist_info\n",
      "  running build_src\n",
      "  creating build\n",
      "  creating build/src.macosx-11.0-arm64-3.8\n",
      "  creating build/src.macosx-11.0-arm64-3.8/numpy\n",
      "  creating build/src.macosx-11.0-arm64-3.8/numpy/distutils\n",
      "  Could not locate executable gfortran\n",
      "  Could not locate executable f95\n",
      "  Could not locate executable f90\n",
      "  Could not locate executable f77\n",
      "  Could not locate executable xlf90\n",
      "  Could not locate executable xlf\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifc\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable g95\n",
      "  Could not locate executable pgfortran\n",
      "  don't know how to compile Fortran code on platform 'posix'\n",
      "  ld: warning: ignoring file _configtest.o, building for macOS-x86_64 but attempting to link with file built for unknown-arm64\n",
      "  Undefined symbols for architecture x86_64:\n",
      "    \"_main\", referenced from:\n",
      "       implicit entry/start for main executable\n",
      "  ld: symbol(s) not found for architecture x86_64\n",
      "  clang: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "  Running from numpy source directory.\n",
      "  setup.py:480: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "    run_build = parse_setuppy_commands()\n",
      "  /private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
      "    warnings.warn(msg)\n",
      "  Traceback (most recent call last):\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 363, in <module>\n",
      "      main()\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 345, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 164, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 157, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 248, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 142, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 508, in <module>\n",
      "      setup_package()\n",
      "    File \"setup.py\", line 500, in setup_package\n",
      "      setup(**metadata)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f866d9382ed449fa87863b5d358a6f13/numpy/distutils/core.py\", line 169, in setup\n",
      "      return old_setup(**new_attr)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/__init__.py\", line 165, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 148, in setup\n",
      "      dist.run_commands()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/command/dist_info.py\", line 31, in run\n",
      "      egg_info.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f866d9382ed449fa87863b5d358a6f13/numpy/distutils/command/egg_info.py\", line 24, in run\n",
      "      self.run_command(\"build_src\")\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-kn7bsw3l/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f866d9382ed449fa87863b5d358a6f13/numpy/distutils/command/build_src.py\", line 144, in run\n",
      "      self.build_sources()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f866d9382ed449fa87863b5d358a6f13/numpy/distutils/command/build_src.py\", line 155, in build_sources\n",
      "      self.build_library_sources(*libname_info)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f866d9382ed449fa87863b5d358a6f13/numpy/distutils/command/build_src.py\", line 288, in build_library_sources\n",
      "      sources = self.generate_sources(sources, (lib_name, build_info))\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f866d9382ed449fa87863b5d358a6f13/numpy/distutils/command/build_src.py\", line 378, in generate_sources\n",
      "      source = func(extension, build_dir)\n",
      "    File \"numpy/core/setup.py\", line 663, in get_mathlib_info\n",
      "      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")\n",
      "  RuntimeError: Broken toolchain: cannot link a simple C program\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/51/60/3f0fe5b7675a461d96b9d6729beecd3532565743278a9c3fe6dd09697fa7/numpy-1.19.5.zip#sha256=a76f502430dd98d7546e1ea2250a7360c065a5fdea52b2dffe8ae7180909b6f4 (from https://pypi.org/simple/numpy/) (requires-python:>=3.6). Command errored out with exit status 1: /Users/domenico/miniforge3/bin/python3.8 /Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py prepare_metadata_for_build_wheel /var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/tmpcw5v4m4r Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached numpy-1.19.4.zip (7.3 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/domenico/miniforge3/bin/python3.8 /Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py prepare_metadata_for_build_wheel /var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/tmpksgf36vb\n",
      "       cwd: /private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f051acaa900b4c9b9201d232eab5dc60\n",
      "  Complete output (87 lines):\n",
      "  Processing numpy/random/_bounded_integers.pxd.in\n",
      "  Processing numpy/random/_philox.pyx\n",
      "  Processing numpy/random/_bounded_integers.pyx.in\n",
      "  Processing numpy/random/_sfc64.pyx\n",
      "  Processing numpy/random/_mt19937.pyx\n",
      "  Processing numpy/random/bit_generator.pyx\n",
      "  Processing numpy/random/mtrand.pyx\n",
      "  Processing numpy/random/_generator.pyx\n",
      "  Processing numpy/random/_pcg64.pyx\n",
      "  Processing numpy/random/_common.pyx\n",
      "  Cythonizing sources\n",
      "  non-existing path in 'numpy/distutils': 'site.cfg'\n",
      "  running dist_info\n",
      "  running build_src\n",
      "  creating build\n",
      "  creating build/src.macosx-11.0-arm64-3.8\n",
      "  creating build/src.macosx-11.0-arm64-3.8/numpy\n",
      "  creating build/src.macosx-11.0-arm64-3.8/numpy/distutils\n",
      "  Could not locate executable gfortran\n",
      "  Could not locate executable f95\n",
      "  Could not locate executable f90\n",
      "  Could not locate executable f77\n",
      "  Could not locate executable xlf90\n",
      "  Could not locate executable xlf\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifc\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable g95\n",
      "  Could not locate executable pgfortran\n",
      "  don't know how to compile Fortran code on platform 'posix'\n",
      "  ld: warning: ignoring file _configtest.o, building for macOS-x86_64 but attempting to link with file built for unknown-arm64\n",
      "  Undefined symbols for architecture x86_64:\n",
      "    \"_main\", referenced from:\n",
      "       implicit entry/start for main executable\n",
      "  ld: symbol(s) not found for architecture x86_64\n",
      "  clang: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "  Running from numpy source directory.\n",
      "  setup.py:480: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "    run_build = parse_setuppy_commands()\n",
      "  /private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
      "    warnings.warn(msg)\n",
      "  Traceback (most recent call last):\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 363, in <module>\n",
      "      main()\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 345, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 164, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 157, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 248, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 142, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 508, in <module>\n",
      "      setup_package()\n",
      "    File \"setup.py\", line 500, in setup_package\n",
      "      setup(**metadata)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f051acaa900b4c9b9201d232eab5dc60/numpy/distutils/core.py\", line 169, in setup\n",
      "      return old_setup(**new_attr)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/__init__.py\", line 165, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 148, in setup\n",
      "      dist.run_commands()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/command/dist_info.py\", line 31, in run\n",
      "      egg_info.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f051acaa900b4c9b9201d232eab5dc60/numpy/distutils/command/egg_info.py\", line 24, in run\n",
      "      self.run_command(\"build_src\")\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lwa5e1hg/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f051acaa900b4c9b9201d232eab5dc60/numpy/distutils/command/build_src.py\", line 144, in run\n",
      "      self.build_sources()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f051acaa900b4c9b9201d232eab5dc60/numpy/distutils/command/build_src.py\", line 155, in build_sources\n",
      "      self.build_library_sources(*libname_info)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f051acaa900b4c9b9201d232eab5dc60/numpy/distutils/command/build_src.py\", line 288, in build_library_sources\n",
      "      sources = self.generate_sources(sources, (lib_name, build_info))\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_f051acaa900b4c9b9201d232eab5dc60/numpy/distutils/command/build_src.py\", line 378, in generate_sources\n",
      "      source = func(extension, build_dir)\n",
      "    File \"numpy/core/setup.py\", line 663, in get_mathlib_info\n",
      "      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")\n",
      "  RuntimeError: Broken toolchain: cannot link a simple C program\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/c5/63/a48648ebc57711348420670bb074998f79828291f68aebfff1642be212ec/numpy-1.19.4.zip#sha256=141ec3a3300ab89c7f2b0775289954d193cc8edb621ea05f99db9cb181530512 (from https://pypi.org/simple/numpy/) (requires-python:>=3.6). Command errored out with exit status 1: /Users/domenico/miniforge3/bin/python3.8 /Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py prepare_metadata_for_build_wheel /var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/tmpksgf36vb Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading numpy-1.19.3.zip (7.3 MB)\n",
      "     |████████████████████████████████| 7.3 MB 1.5 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/domenico/miniforge3/bin/python3.8 /Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py prepare_metadata_for_build_wheel /var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/tmpf7n8zvph\n",
      "       cwd: /private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_2cfe198030be44d784d99e3259e05fc7\n",
      "  Complete output (87 lines):\n",
      "  Processing numpy/random/_bounded_integers.pxd.in\n",
      "  Processing numpy/random/_philox.pyx\n",
      "  Processing numpy/random/_bounded_integers.pyx.in\n",
      "  Processing numpy/random/_sfc64.pyx\n",
      "  Processing numpy/random/_mt19937.pyx\n",
      "  Processing numpy/random/bit_generator.pyx\n",
      "  Processing numpy/random/mtrand.pyx\n",
      "  Processing numpy/random/_generator.pyx\n",
      "  Processing numpy/random/_pcg64.pyx\n",
      "  Processing numpy/random/_common.pyx\n",
      "  Cythonizing sources\n",
      "  non-existing path in 'numpy/distutils': 'site.cfg'\n",
      "  running dist_info\n",
      "  running build_src\n",
      "  creating build\n",
      "  creating build/src.macosx-11.0-arm64-3.8\n",
      "  creating build/src.macosx-11.0-arm64-3.8/numpy\n",
      "  creating build/src.macosx-11.0-arm64-3.8/numpy/distutils\n",
      "  Could not locate executable gfortran\n",
      "  Could not locate executable f95\n",
      "  Could not locate executable f90\n",
      "  Could not locate executable f77\n",
      "  Could not locate executable xlf90\n",
      "  Could not locate executable xlf\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifc\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable g95\n",
      "  Could not locate executable pgfortran\n",
      "  don't know how to compile Fortran code on platform 'posix'\n",
      "  ld: warning: ignoring file _configtest.o, building for macOS-x86_64 but attempting to link with file built for unknown-arm64\n",
      "  Undefined symbols for architecture x86_64:\n",
      "    \"_main\", referenced from:\n",
      "       implicit entry/start for main executable\n",
      "  ld: symbol(s) not found for architecture x86_64\n",
      "  clang: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "  Running from numpy source directory.\n",
      "  setup.py:480: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "    run_build = parse_setuppy_commands()\n",
      "  /private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
      "    warnings.warn(msg)\n",
      "  Traceback (most recent call last):\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 363, in <module>\n",
      "      main()\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 345, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"/Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 164, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 157, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 248, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 142, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 508, in <module>\n",
      "      setup_package()\n",
      "    File \"setup.py\", line 500, in setup_package\n",
      "      setup(**metadata)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_2cfe198030be44d784d99e3259e05fc7/numpy/distutils/core.py\", line 169, in setup\n",
      "      return old_setup(**new_attr)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/__init__.py\", line 165, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 148, in setup\n",
      "      dist.run_commands()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/command/dist_info.py\", line 31, in run\n",
      "      egg_info.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_2cfe198030be44d784d99e3259e05fc7/numpy/distutils/command/egg_info.py\", line 24, in run\n",
      "      self.run_command(\"build_src\")\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-build-env-lsrbrkbp/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_2cfe198030be44d784d99e3259e05fc7/numpy/distutils/command/build_src.py\", line 144, in run\n",
      "      self.build_sources()\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_2cfe198030be44d784d99e3259e05fc7/numpy/distutils/command/build_src.py\", line 155, in build_sources\n",
      "      self.build_library_sources(*libname_info)\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_2cfe198030be44d784d99e3259e05fc7/numpy/distutils/command/build_src.py\", line 288, in build_library_sources\n",
      "      sources = self.generate_sources(sources, (lib_name, build_info))\n",
      "    File \"/private/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/pip-install-mfit9p_o/numpy_2cfe198030be44d784d99e3259e05fc7/numpy/distutils/command/build_src.py\", line 378, in generate_sources\n",
      "      source = func(extension, build_dir)\n",
      "    File \"numpy/core/setup.py\", line 663, in get_mathlib_info\n",
      "      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")\n",
      "  RuntimeError: Broken toolchain: cannot link a simple C program\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/cb/c0/7b3d69e6ee68bc54c97ba51f8c3c3e43ff1dbc7bd97347cc19a1f944e60a/numpy-1.19.3.zip#sha256=35bf5316af8dc7c7db1ad45bec603e5fb28671beb98ebd1d65e8059efcfd3b72 (from https://pypi.org/simple/numpy/) (requires-python:>=3.6). Command errored out with exit status 1: /Users/domenico/miniforge3/bin/python3.8 /Users/domenico/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py prepare_metadata_for_build_wheel /var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/tmpf7n8zvph Check the logs for full command output.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Downloading numpy-1.19.2.zip (7.3 MB)\n",
      "     |████████████████████████████████| 7.3 MB 10.2 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "^C\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Collecting pyclustering\n",
      "  Using cached pyclustering-0.10.1.2.tar.gz (2.6 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from pyclustering) (1.7.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from pyclustering) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.15.2 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from pyclustering) (1.21.5)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from pyclustering) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from matplotlib>=3.0.0->pyclustering) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from matplotlib>=3.0.0->pyclustering) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from matplotlib>=3.0.0->pyclustering) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from matplotlib>=3.0.0->pyclustering) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from matplotlib>=3.0.0->pyclustering) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from matplotlib>=3.0.0->pyclustering) (4.28.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/domenico/miniforge3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->pyclustering) (1.16.0)\n",
      "Building wheels for collected packages: pyclustering\n",
      "  Building wheel for pyclustering (setup.py) ... \u001b[?25l\\^C\n",
      "Exception ignored in: <function Popen.__del__ at 0x105415af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/domenico/miniforge3/lib/python3.8/subprocess.py\", line 939, in __del__\n",
      "    def __del__(self, _maxsize=sys.maxsize, _warn=warnings.warn):\n",
      "KeyboardInterrupt: \n",
      "\u001b[?25h  Created wheel for pyclustering: filename=pyclustering-0.10.1.2-py3-none-any.whl size=2395122 sha256=f97824c0e477452cccdf40939ff28e513e67be0023d7ccb731141e9352cb1c3e\n",
      "  Stored in directory: /Users/domenico/Library/Caches/pip/wheels/dc/25/8b/072b221a5cff4f04e7999d39ca1b6cb5dad702cc3e1da951d4\n",
      "Successfully built pyclustering\n",
      "Installing collected packages: pyclustering\n"
     ]
    }
   ],
   "source": [
    "!pip install yellowbrick\n",
    "!pip install pyclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74914091-944b-4f2b-bb07-9f401abf8f33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyclustering'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q3/n1kzrjss3rlcf4h0671f29640000gn/T/ipykernel_30704/2714086164.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmeans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster_visualizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_visualizer_multidim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter_initializer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkmeans_plusplus_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyclustering'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler # normalization\n",
    "from sklearn.cluster import KMeans,DBSCAN,AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from pyclustering.cluster.xmeans import xmeans\n",
    "from pyclustering.cluster import cluster_visualizer, cluster_visualizer_multidim\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster.silhouette import silhouette\n",
    "from pyclustering.cluster.encoder import type_encoding, cluster_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79a9d4-3cfa-45d4-9685-630448a47a88",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2aade-7439-4498-b774-75e01b9c241d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/tennis_players.csv\", skipinitialspace=True, sep=',', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9f98c3-75b3-489c-a08d-38099181fbd0",
   "metadata": {},
   "source": [
    "### Drop categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b46720-90ca-4011-9cce-ac5fbfadf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['name']\n",
    "del df['hand']\n",
    "del df['gender']\n",
    "del df['ioc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08460cce-918f-4fc9-b9b1-1d2421079627",
   "metadata": {},
   "source": [
    "### Drop most correlated attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643ba5d-306c-4fe2-9fbd-90ea336ffb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_threshold = 0.9\n",
    "print(\"Att. A\\tAtt. B\\tCorr(A,B)\")\n",
    "for i in range(0, len(df.columns)):\n",
    "    for j in range(i+1, len(df.columns)):\n",
    "        corr = df[df.columns[i]].corr(df[df.columns[j]])\n",
    "        if  corr > corr_threshold:\n",
    "            print(df.columns[i] + \"\\t\" + df.columns[j] + \"\\t\" + '{:.4f}'.format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e399cf-421e-45b7-a55c-5b18d15b4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['num_matches_2016-2019'] \n",
    "del df['bpFaced']\n",
    "del df['serv_won_tot_seve']\n",
    "del df['perc_2ndwon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8610f-0204-4b52-9084-efdbab241597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ebc5e-b6ae-47f6-80a6-03639979388e",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409259a-494c-4e71-ada7-13317db33b79",
   "metadata": {},
   "source": [
    "### MinMax Normalization before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c4de6-9c13-431b-a65b-359a05dd0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_norm_minmax = scaler.fit_transform(df.values)\n",
    "#print(df_norm_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420ae7e-9a1d-42cb-9769-60f1fd5c595d",
   "metadata": {},
   "source": [
    "### ZScore Normalization before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25aae3-a7df-4ff0-9c93-591d4ca8ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_norm_zscore = scaler.fit_transform(df.values) \n",
    "#print(df_norm_zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c48fb-fde4-40da-af72-60e83aac6a4a",
   "metadata": {},
   "source": [
    "# Partitional and center-based clustering: K-Means\n",
    "\n",
    "**Objective:** Clusters the data into $k$ groups.\n",
    "* **Init step:** Select k points at random as cluster centers.\n",
    "* **Assignment step:** Assign each instance to the cluster with the closest mean according to the distance function.\n",
    "* **Update step**: Calculate the new means to be the centroids of the instances in the new clusters.\n",
    "* ***Repeat*** steps 2 and 3 until the assignment no longer change.\n",
    "\n",
    "There is no guarantee that the optimum is found using this algorithm.\n",
    "\n",
    "## Problems\n",
    "\n",
    "* Initial Centroids\n",
    "* Number of clusters\n",
    "\n",
    "### Number of clusters decision: Elbow Method on the clusters Inertia\n",
    "In cluster analysis, the elbow method is a heuristic used in determining the optimal number of clusters in a data set. \n",
    "<br>It consists of plotting the SSE as a function of the number of clusters, and **picking the elbow** of the curve as the *k* to use.\n",
    "\n",
    "We start from an initial value of 2 and we keep computing the clusterization until we reach the value of 30, our choice for the maximum value of *k*. \n",
    "<br>Considering ranges of k differing in size may lead to slightly different elbows, so we also plot the curves of the intervals [2,10] and [2,20].\n",
    "\n",
    "\n",
    "## Scoring parameter metrics\n",
    "https://www.scikit-yb.org/en/latest/api/cluster/elbow.html\n",
    "\n",
    "* **Distortion:** Is the default method, it computes the mean Sum of Squared distances from each point to its assigned center.\n",
    "\n",
    "* **Average Silhouette:** It is an indicator of both separation and cohesion among clusters. We look for the clusterization with the highest average value among those computed by K-means. It computes the mean ratio of intra-cluster and nearest cluster distance.\n",
    "\n",
    "* **Calinski Harabasz:** It computes the ratio of dispersion between and within clusters.\n",
    "\n",
    "\n",
    "The elbow_locate=True means that it automatically finds the 'elbow' or 'knee' which likely corresponds to the optimal value of k using the 'knee point detection algorithm'. This algorithm finds the point of maximum curvature, which in a well-behaved clustering problem also represents the pivot of the elbow curve.\n",
    "\n",
    "NOTE: the 'elbow' method does not work well if the data is not very clustered, in this case there is a smooth curve and the optimal value of k will be unclear. Then other scoring methods such as BIC or SSE, also can be used to explore if clustering is a correct choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612f9ba-7c38-4889-93ab-185f10df888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_norm_minmax # can try both the normalized forms without obtaining differences\n",
    "#df_norm = df_norm_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238e763-97f1-4411-8568-3156dbc22ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_norm_minmax # can try both the normalized forms without obtaining differences\n",
    "#df_norm = df_norm_zscore\n",
    "\n",
    "k_start = [2]\n",
    "k_max = [10, 20, 30]\n",
    "Ks = []\n",
    "model = KMeans()\n",
    "\n",
    "print(\"The blue line is the function output.\")\n",
    "print(\"The vertical dashed line signs the optimal k value.\")\n",
    "print(\"The green line signs the time needed for each clustering of different k.\")\n",
    "print(\"If there is a strong elbow (point of inflection on the curve) there is the optimal k.\")\n",
    "f, axs = plt.subplots(nrows=1, ncols=len(k_max), figsize=(30,5)) # print the elbow plots\n",
    "for i in range(len(k_max)):\n",
    "    vis = KElbowVisualizer(model, k=(k_start[0],k_max[i]), metric='distortion', timings=True, ax=axs[i])\n",
    "    vis.fit(df_norm) #fit the data to the visualizer \n",
    "    axs[i].set_title('Distortion Score Elbow for K-Means Clustering (K = ' + str(k_start[0]) + ', ' + str(k_max[i]) + ')' )\n",
    "    axs[i].set_ylabel('distortion score')\n",
    "    axs[i].set_xlabel('k')\n",
    "    axs[i].legend(['distortion score for k','elbow at k = ' + str(vis.elbow_value_) + ', score = ' + '{:.2f}'.format(vis.elbow_score_)])\n",
    "    if (vis.elbow_value_ not in Ks) and (vis.elbow_value_ != None):\n",
    "        Ks.append(vis.elbow_value_)\n",
    "plt.show() #finalize and render the figure\n",
    "plt.close()\n",
    "print(\"The arm is up going.\")\n",
    "\n",
    "f, axs = plt.subplots(nrows=1, ncols=len(k_max), figsize=(30,5))\n",
    "for i in range(len(k_max)):\n",
    "    vis = KElbowVisualizer(model, k=(k_start[0],k_max[i]), metric='silhouette', timings=True, ax=axs[i])\n",
    "    #vis = KElbowVisualizer(model, k=(k_start[0],k_max[i]), metric='silhouette', timings=True, ax=axs[i], locate_elbow=False)\n",
    "    vis.fit(df_norm)  \n",
    "    axs[i].set_title('Silhouette Score Elbow for K-Means Clustering (K = ' + str(k_start[0]) + ', ' + str(k_max[i]) + ')' )\n",
    "    axs[i].set_ylabel('silhouette score')\n",
    "    axs[i].set_xlabel('k')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"It highlights a global maxima for k equals to 2 and a local maxima for k equals to 3 or 4\")\n",
    "print(\"We consider these values to the list of candidates for the optimal value of k.\")\n",
    "\n",
    "\n",
    "f, axs = plt.subplots(nrows=1, ncols=len(k_max), figsize=(30,5))\n",
    "for i in range(len(k_max)):\n",
    "    vis = KElbowVisualizer(model, k=(k_start[0],k_max[i]), metric='calinski_harabasz', timings=True, ax=axs[i])\n",
    "    #vis = KElbowVisualizer(model, k=(k_start[0],k_max[i]), metric='calinski_harabasz', timings=True, ax=axs[i], locate_elbow=False)\n",
    "    vis.fit(df_norm)  \n",
    "    axs[i].set_title('Calinski_Harabasz Score Elbow for K-Means Clustering (K = ' + str(k_start[0]) + ', ' + str(k_max[i]) + ')' )\n",
    "    axs[i].set_ylabel('calinski_harabasz score')\n",
    "    axs[i].set_xlabel('k')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"The arm is down going.\")\n",
    "\n",
    "print(\"The line chart (both for Distortion and Calinski) looks like an arm then the elbow point is the best value of k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311054c-1860-49c0-af21-633b372f16cf",
   "metadata": {},
   "source": [
    "### Number of clusters decision: Intercluster Distance Maps\n",
    "It displays an embedding of the cluster centers in 2D with the distance to other centers preserved.\n",
    "i.e. the closer to centers are in the visualization, the closer they are in the original feature space\n",
    "Each cluster is sized according to a scoring metric. By default, they are sized by membership, i.e. the number of instances that belong to each center. This gives a sense of the relative importance of clusters.\n",
    "\n",
    "NOTE: because 2 clusters overlap in the 2D space, it does not imply that they overlap in the original feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7332a5c2-8d48-4198-bd7d-571961c5590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(nrows=1, ncols=1, figsize=(30,5))\n",
    "vis = InterclusterDistance(model)\n",
    "vis.fit(df_norm)  \n",
    "vis.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a496a17-eb78-4d29-ba38-ad04304d738c",
   "metadata": {},
   "source": [
    "## Visualization of the clusters in 2 dimensions\n",
    "\n",
    "Parameters:\n",
    "* **n_clusters**: The number of clusters\n",
    "* **n_init**: Number of time k-means will be run with different initial centroids. The final results will be the best output in terms of inertia.\n",
    "* **max_iter**: Maximum number of iterations of the k-means algorithm for a single run.\n",
    "\n",
    "Output:\n",
    "* **labels_**: Labels of each point\n",
    "* **cluster\\_centers_**: Coordinates of cluster centers\n",
    "* **inertia_**: Sum of squared distances of samples to their closest cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d165e0a-272f-4457-9101-cb1a76cdb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,5):\n",
    "    if i==1:\n",
    "        kmeans = KMeans(n_clusters=8, n_init=10, max_iter=300) #default parameters\n",
    "    else:\n",
    "        kmeans = KMeans(n_clusters=i, n_init=10, max_iter=100) #global max k=2, local max k=3,4 from the Silhouette score analyisis\n",
    "\n",
    "    print(kmeans.fit(df_norm)) \n",
    "    #print( kmeans.labels_[:5] ) #labels\n",
    "    #print( np.unique(kmeans.labels_, return_counts=True) ) # observing the size of each cluster\n",
    "    hist, bins = np.histogram(kmeans.labels_, bins=range(0, len(set(kmeans.labels_)) + 1))\n",
    "    print( dict(zip(bins, hist)) )\n",
    "        \n",
    "    f, axs = plt.subplots(ncols=6, figsize=(30,5))\n",
    "    for j in range(0,6):\n",
    "        if j==0:\n",
    "            df1,df2 = df['ratio'],df['ratio_2016-2019']\n",
    "        elif j==1:\n",
    "            df1,df2 = df['ratio'],df['ratio_2020-2021']\n",
    "        elif j==2:\n",
    "            df1,df2 = df['minutes'],df['perc_ace']\n",
    "        elif j==3:\n",
    "            df1,df2 = df['minutes'],df['perc_df']\n",
    "        elif j==4:\n",
    "            df1,df2 = df['perc_ace'],df['perc_v_ace']\n",
    "        elif j==5:\n",
    "            df1,df2 = df['perc_df'],df['perc_v_df']\n",
    "\n",
    "        axs[j].scatter(df1, df2, s=20, c=kmeans.labels_) # i colori vengono presi qua\n",
    "        axs[j].tick_params(axis='both', which='major', labelsize=22)\n",
    "        axs[j].set_title(df1.name+\" with \"+df2.name)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4bec15-610d-4429-8dbf-17e371db4fe3",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55060542-82f4-4473-91c4-8edd9936f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(nrows=1, ncols=1, figsize=(30,5))\n",
    "vis = InterclusterDistance(model)\n",
    "vis.fit(df_norm)  \n",
    "vis.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc14fabd-6205-47db-b5e1-96ad13ca38d2",
   "metadata": {},
   "source": [
    "# DBSCAN\n",
    "Parameters:\n",
    "* **eps**: The maximum distance between two samples for them to be considered as in the same neighborhood.\n",
    "* **min_samples**: The number of samples in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "\n",
    "\n",
    "To try different configurations of parameters, we set 3 vectors:\n",
    "* **eps_values**: Vector of eps\n",
    "* **min_samples_values**: Vector of min_samples\n",
    "* **metrics**: Vector of metrics\n",
    "\n",
    "\n",
    "\n",
    "In total, we try 1008 different configuration, however, how the reader can see below, we can't exploit a good clustering of our data using dbscan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336db5c-87a2-4c21-9fb1-0cb6546687bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled=df_norm_minmax\n",
    "num_features=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5bb40-ce74-41db-8afb-6a05ea9cde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_values = [0.005, 0.01, 0.05, 0.08, 0.1, 0.15, 0.20, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55]\n",
    "min_samples_values = [3, 5, 6, 7, 8, 9, 10, 15, 16, 17, 18, 20]\n",
    "metrics = ['euclidean'] #'cityblock', 'cosine', 'l1', 'l2', 'manhattan']\n",
    "dbscan = []\n",
    "dbscan_pair = []\n",
    "k = 0\n",
    "for metric in metrics:\n",
    "    for i in range(len(eps_values)):\n",
    "        for j in range(len(min_samples_values)):\n",
    "            d = DBSCAN(eps=eps_values[i], min_samples=min_samples_values[j]) # algorithmic parameters\n",
    "            dbscan.append(d.fit(scaled))\n",
    "            if (len(np.unique((dbscan[k].labels_))) > 1):\n",
    "                s = silhouette_score(scaled, dbscan[k].labels_)\n",
    "                pair = (dbscan[k], s)\n",
    "                dbscan_pair.append(pair)\n",
    "            k = 1 + k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a50b13-98c2-4945-8394-9589deca3f1f",
   "metadata": {},
   "source": [
    "## Cluster Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972abf1-4d12-4ef1-b1fc-4efc1445f78d",
   "metadata": {},
   "source": [
    "To evaluete our cluster, sort by second component of dbscan_pair (that contain the pairs <dbscan, silhouette>) and take the last ten elements, these are the clusters with the greater silhouette. Then, visualize the coefficient, the number of clusters and their cardinality. From the results below, can be notice that best dbscans are composed by an eps = 0.45 and different values of min_sample, however silhouette values are small, the max value found are around 0.2. Also, best dbscans obtain only one big cluster and a very small cluster formed by outliers. So, from these results, it's possible to deduce that DBSCAN is not very well to clustering our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00beb6cd-83bc-4285-a6ac-fe0fc6ed5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_best_k = sorted(dbscan_pair, key=lambda x: x[1])\n",
    "db_best_k = db_best_k[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b989c5-904e-4d16-9b7b-cb1b81d0ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(db_best_k)):\n",
    "    print(db_best_k[i][0], np.unique(db_best_k[i][0].labels_, return_counts=True))\n",
    "    print('Silhouette ', db_best_k[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320ef12-942e-48f6-b56f-823d23f1c7d5",
   "metadata": {},
   "source": [
    "To completness, it's showed also the best results in case dbscan identify more then two clusters (at least one cluster apart custer -1 and 0). Obviously the silhouette it's worste then before and also in this case we have a very big cluster and other smallest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e131021b-1bb2-4e14-b5b9-c69673ad0e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_two = []\n",
    "for i in range(len(dbscan_pair)):\n",
    "    if len(np.unique(dbscan_pair[i][0].labels_)) > 2:\n",
    "        db_two.append(dbscan_pair[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca4183-9c87-4427-8620-a7fa74e1f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_two = sorted(db_two, key=lambda x: x[1])\n",
    "db_two = db_two[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fcc9cd-ef63-4196-92c9-b72d764b65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(db_two)):\n",
    "    print(np.unique(db_two[i][0].labels_, return_counts=True), 'sil', db_two[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280e1ca-23e4-4799-81b0-28c04cb5db18",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Below is showed scatter plot of the best dbscan formed by eps = 0.45 and min_sample = 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be57a37-40f9-4bcf-a9c2-9dd24daeffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_subplots(cell, x, y, x_label, y_label, db):\n",
    "    cell.scatter(x, y, c=db.labels_, s=25)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    #cell.set_title('Corr(' + x_label + ',' + y_label +'): ' + str(x.corr(y)))\n",
    "    cell.set_xlabel(x_label)\n",
    "    cell.set_ylabel(y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dccd155-c418-42ac-9239-abf0aa2d98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(nrows = 2, ncols = 3, figsize=(30,15))\n",
    "best_db = db_best_k[-1][0]\n",
    "scatter_subplots(axs[0][0], num_features.perc_ace, num_features.perc_v_ace, 'perc_ace', 'perc_v_ace', best_db)\n",
    "#scatter_subplots(axs[0][1], num_features.ratio, num_features.serv_won_tot_seve, 'ratio', 'serv_won_tot_seve', best_db)\n",
    "scatter_subplots(axs[0][1], num_features.ht, num_features.perc_df, 'ht', 'perc_df', best_db)\n",
    "scatter_subplots(axs[0][2], num_features.perc_v_1stwon, num_features.perc_v_ace, 'perc_v_1stwon', 'perc_v_ace', best_db)\n",
    "\n",
    "#scatter_subplots(axs[1][0], num_features.minutes, num_features.serv_won_tot_seve, 'minutes', 'serv_won_tot_seve', best_db)\n",
    "#scatter_subplots(axs[1][0], df.minutes, num_features.bpFaced, 'minutes', 'bpFaced', best_db)\n",
    "scatter_subplots(axs[1][0], num_features.ratio, num_features.perc_v_df, 'ratio', 'perc_v_df', best_db)\n",
    "scatter_subplots(axs[1][1], num_features.ratio, num_features.perc_df, 'ratio', 'perc_df', best_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27508087-d14e-4185-9c26-0ef032063303",
   "metadata": {},
   "source": [
    "# Hierarchical clustering \n",
    "\n",
    "There are 2 kinds of hierarchical clustering: \n",
    "\n",
    "- Agglomerative: Start with the points as individual clusters, at each step, merge the closest pair of clusters until only one cluster (or k clusters) left\n",
    "\n",
    "- Divisive: Start with one, all inclusive cluster, at each step, split a cluster until each cluster contains an individual point (or there are k clusters)\n",
    "\n",
    "Using the scipy library, let's explore the linking function and then plot the dendrogram. In our case the analysis was made taking into consideration the Agglomerative cluster, where in particular we will have four types of methods:\n",
    "\n",
    "- Single (Min): Proximity of two clusters is based on the two closest points in the different clusters (Determined by one pair of points, i.e., by one link in the proximity graph)\n",
    "- Complete: Proximity of two clusters is based on the two most distant points in the different clusters (Determined by all pairs of points in the two clusters)\n",
    "- Average: Proximity of two clusters is the average of pairwise proximity between points in the two clusters (Need to use average connectivity for scalability since total proximity favors large clusters)\n",
    "- Ward: Similarity of two clusters is based on the increase in squared error when two clusters are merged (Similar to group average if distance between points is distance squared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb894ef-3798-4036-affb-9f3aeebb3c51",
   "metadata": {},
   "source": [
    "Initially, we set type of parameters to be used, in particular the chosen dataset can be taken from the normalization of the minmax or the z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd394e36-3fc9-4a79-a541-103293621b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data for MinMax\n",
    "data=df_norm_minmax\n",
    "steps = [0.001, 0.01, 0.01, 0.1]\n",
    "\n",
    "#set data for Z-Score\n",
    "#data=df_norm_zscore\n",
    "#steps = [0.01, 0.1, 0.1, 3]\n",
    "\n",
    "methods = ['single', 'complete', 'average', 'ward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7acda-2982-4c68-a14b-c9fcc268fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the linkage matrix and plot dendrogram for relative model type\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "\n",
    "    n_sample = np.zeros(model.children_.shape[0])\n",
    "    samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < samples:\n",
    "                current_count += 1 \n",
    "            else:\n",
    "                current_count += n_sample[child_idx - samples]\n",
    "        n_sample[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_, n_sample]).astype(float)\n",
    "\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "\n",
    "def plot_graph(axs,i,c_thresholds):\n",
    "    axs[i].set_title('Hierarchical Clustering from ' + methods[i] + ' \\n Color Threshold: ' + '{:2.4f}'.format(c_thresholds))\n",
    "    axs[i].set_xlabel('PlayerID or (Cluster Size)')\n",
    "    axs[i].set_ylabel('Distance')\n",
    "    axs[i].axhline(c_thresholds, ls='--', color='r')\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3141a7-be53-4c04-880a-e160e504726c",
   "metadata": {},
   "source": [
    "For each method we go to calculate the agglomerative cluster and then print on the screen the various dendrograms associated with the respective default treshold (initialy set 4/5 of the size of each linkage matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270f66d-8a7c-4b5f-b226-ef6ef4b2ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_thresholds = []\n",
    "\n",
    "f, axs = plt.subplots(ncols=4, figsize=(31,8))\n",
    "\n",
    "for i in range(len(methods)):\n",
    "    model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, affinity='euclidean', linkage=methods[i]).fit(data) \n",
    "    plot_dendrogram(model, truncate_mode='lastp', p=30, leaf_rotation=60, leaf_font_size = 8, show_contracted=True, ax=axs[i])\n",
    "    link_matrix = linkage(data, methods[i])\n",
    "    #take the threshold of 4/5\n",
    "    c_threshold=0.8*max(link_matrix[:,2]) \n",
    "    axs=plot_graph(axs,i,c_threshold)\n",
    "\n",
    "plt.suptitle(('Comparison among the different linkages'), fontsize=18, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c8002-f0f4-46fe-ae33-601068322bbf",
   "metadata": {},
   "source": [
    "### Find best clusters\n",
    "\n",
    "To find the best cluster (able to guarantee a correct separation) we used a function that fixed certain steps chosen by us based on the distance between the various clusters of each method previously seen, selects the number of clusters that best separates the data (with maximum distance). Although this choice can be made graphically, we have decided to automate it also for future uses of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0de4c-dbdf-4304-ba91-cda3edc2b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_cut(linkage, step, norm_data):\n",
    "    clusters_number = []\n",
    "    distances = []\n",
    "    n_clusters = 0\n",
    "    i = 0\n",
    "\n",
    "    while n_clusters != 1:\n",
    "        threshold = i*step\n",
    "        model = AgglomerativeClustering(distance_threshold=threshold, n_clusters=None, affinity='euclidean', linkage=linkage).fit(norm_data)\n",
    "        i = i + 1\n",
    "\n",
    "        n_clusters = model.n_clusters_\n",
    "        distances.append(threshold)\n",
    "        clusters_number.append(n_clusters)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['distance'] = distances\n",
    "    df['n_clusters'] = clusters_number\n",
    "    \n",
    "    n_for_opt_cut = df.groupby('n_clusters').size().agg(['idxmax'])[0]\n",
    "    distance = df[df.n_clusters == n_for_opt_cut].distance.min()\n",
    "    \n",
    "    print('Analysis for ' + linkage + ' reached n_clusters = 1 in ' + str(i) + ' steps')\n",
    "   \n",
    "    return n_for_opt_cut, distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30bf94-8f58-44d2-983e-9eb69f023dd9",
   "metadata": {},
   "source": [
    "We'll search for the best cut for each methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ed7eb-d0c9-456c-9365-cbedb6e3876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clusters = []\n",
    "heights = []\n",
    "\n",
    "for i in range(len(methods)):\n",
    "    n_for_opt_cut, height = get_best_cut(methods[i], steps[i], data)\n",
    "    best_clusters.append(n_for_opt_cut)\n",
    "    heights.append(height)\n",
    "    \n",
    "hierarchical_distances = pd.DataFrame()\n",
    "hierarchical_distances['method'] = methods\n",
    "hierarchical_distances['clusters_best_cut'] = best_clusters\n",
    "hierarchical_distances['distance'] = heights\n",
    "hierarchical_distances.set_index(['method'], inplace=True)\n",
    "\n",
    "print(hierarchical_distances)\n",
    "\n",
    "# We compute and store the labels associated with each cut.\n",
    "clusters_labels = pd.DataFrame()\n",
    "\n",
    "for i in range(len(methods)):\n",
    "    opt_n_clusters = int(hierarchical_distances.loc[methods[i]].clusters_best_cut)\n",
    "    temp = AgglomerativeClustering(n_clusters=opt_n_clusters, affinity='euclidean', linkage=methods[i])\n",
    "    labels=temp.fit_predict(data)\n",
    "    clusters_labels[methods[i]] = labels\n",
    "\n",
    "clusters_labels[['single', 'complete', 'average', 'ward']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28de213-b35a-4c5f-9c08-b7247fcefda3",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We compare the four clusterings by visualizing the distribution of the points among their clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6973b59c-f2bc-42bc-b602-e79652e8f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dendrograms\n",
    "\n",
    "f, axs = plt.subplots(ncols=4, figsize=(32,7))\n",
    "\n",
    "for i in range(len(methods)):\n",
    "    color_threshold = hierarchical_distances.loc[methods[i]].distance\n",
    "    model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, affinity='euclidean', linkage=methods[i]).fit(data) \n",
    "    plot_dendrogram(model, truncate_mode='lastp', p=30, leaf_rotation=60, leaf_font_size = 8, show_contracted=True, ax=axs[i], color_threshold=color_threshold)\n",
    "  \n",
    "    axs=plot_graph(axs,i,color_threshold + steps[i]*2)\n",
    "\n",
    "plt.suptitle(('Comparison among different linkages'),\n",
    "             fontsize=18, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cf176-b0bd-4a93-8de7-1bcfbe08d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(a,b):\n",
    "    f, axs = plt.subplots(nrows=1, ncols=4, figsize=(32,12))\n",
    "    for i in range(len(methods)):\n",
    "        labels = clusters_labels[methods[i]]\n",
    "        opt_n_clusters = int(hierarchical_distances.loc[methods[i]].clusters_best_cut)\n",
    "        scatter = axs[i].scatter(df[a], df[b], c=labels, s=20, cmap='cividis')\n",
    "        axs[i].set_title('Scatter('+a+', '+b+') \\n Method: ' + methods[i] + ', \\n Number clusters: ' + str(opt_n_clusters), fontdict={'fontsize': 'large'})\n",
    "        axs[i].set_xlabel(a, fontdict={'fontsize': 'large'})\n",
    "        axs[i].set_ylabel(b, fontdict={'fontsize': 'large'})\n",
    "\n",
    "        # produce a legend with the unique colors from the scatter\n",
    "        dbs_population = np.unique(labels, return_counts=True)\n",
    "\n",
    "        legend1 = axs[i].legend(*scatter.legend_elements(), #legend_elements creates legend handles and labels for a PathCollection.\n",
    "                            loc=\"lower center\", title=\"Labels\")\n",
    "\n",
    "        axs[i].add_artist(legend1)\n",
    "\n",
    "        # produce a legend \n",
    "        secondlegend = []\n",
    "        classes = np.unique(labels).shape[0]\n",
    "\n",
    "        for j in range(classes):\n",
    "            secondlegend.append(\"{} has {} points\".format(j, dbs_population[1][j]))\n",
    "        handles = scatter.legend_elements()[0]\n",
    "        labels_2 = secondlegend\n",
    "        legend2 = axs[i].legend(handles, labels_2, loc=\"lower right\", title=\"Distribution\")\n",
    "\n",
    "    plt.suptitle(('Comparison of clusterings from different algorithms'),\n",
    "                 fontsize=24, fontweight='bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0670f8-b1fd-4c9e-a921-cc7939ec7de3",
   "metadata": {},
   "source": [
    "### perc_v_ace-perc_v_1stwon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3a582-157d-4ed9-914a-63e3b75715f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 'perc_v_ace', 'perc_v_1stwon'\n",
    "comparison(a,b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb6955-0953-4c73-a052-e6bda3b5d635",
   "metadata": {},
   "source": [
    "### perc_v_ace-perc_v_1stwon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9056b9e-0f84-4589-b2c0-9fbf1e67e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 'ratio', 'ratio_2016-2019'\n",
    "comparison(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510de50a-5ef8-4500-95ba-6b87052cc964",
   "metadata": {},
   "source": [
    "### num_matches_2020-2021 - ratio_2020-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e523621-f41c-41b9-8a43-54920eb71ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 'perc_ace', 'perc_v_ace'\n",
    "comparison(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f04518-7eae-4915-b1a9-aa9efa085153",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We used two types of measures for cluster assessment.\n",
    "- Internal evaluation:\n",
    "    - Separation: The sum of the weights between nodes in the cluster and nodes outside the cluster.\n",
    "    - Silhouette: Combines ideas of both cohesion and separation, but for individual points, as well as clusters and clusterings \n",
    "    \n",
    "- External evaluation:\n",
    "    - Cophenetic correlation: Measure of how faithfully a dendrogram preserves the pairwise distances between the original unmodeled data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a252e-d56e-443b-9780-e001d6f79071",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=pd.DataFrame() \n",
    "    \n",
    "sep=[]\n",
    "sil=[]\n",
    "\n",
    "cophenetic_coefficients = []\n",
    "\n",
    "for method in methods:\n",
    "    sep.append(davies_bouldin_score(data, clusters_labels[method]))\n",
    "    sil.append(silhouette_score(data, clusters_labels[method]))\n",
    "    Z = linkage(data, method)\n",
    "    cophenetic_coefficients = np.append(cophenetic_coefficients, np.corrcoef(pdist(data), cophenet(Z))[0][1])\n",
    "    \n",
    "#internal metric\n",
    "metrics['Methods'] = methods\n",
    "metrics['Separation'] = sep\n",
    "metrics['Silhouette'] = sil\n",
    "\n",
    "#esternal metric\n",
    "metrics['cophenetic_corr'] = cophenetic_coefficients\n",
    "\n",
    "#set index to methods\n",
    "metrics.set_index(['Methods'], inplace=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d913dd-b84d-4544-b424-4433d8448ac7",
   "metadata": {},
   "source": [
    "# X-MEANS (extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9e739-f54c-42a0-b5f0-1bbcd9977290",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.asmatrix(data).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f0340-d134-47bd-863b-bdb8a0aee390",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = np.array(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d00e1-d41a-4c9a-83b2-f64f47ca0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_initial_centers = 2\n",
    "initial_centers = kmeans_plusplus_initializer(mat, amount_initial_centers).initialize()\n",
    "# Create instance of X-Means algorithm. The algorithm will start analysis from 2 clusters, the maximum\n",
    "# number of clusters that can be allocated is 10.\n",
    "xmeans_instance = xmeans(mat, initial_centers, 6, ccore=False)\n",
    "xmeans_instance.process()\n",
    "\n",
    "\n",
    "# Extract clustering results: clusters and their centers\n",
    "clusters = xmeans_instance.get_clusters()\n",
    "centers = xmeans_instance.get_centers()\n",
    "# Visualize clustering results\n",
    "\n",
    "# by default k-means returns representation CLUSTER_INDEX_LIST_SEPARATION\n",
    "type_repr = xmeans_instance.get_cluster_encoding();\n",
    "encoder = cluster_encoder(type_repr, clusters, mat);\n",
    "# change representation from index list to label list\n",
    "encoder.set_encoding(type_encoding.CLUSTER_INDEX_LABELING);\n",
    "\n",
    "#print(\"Index Labeling:\", encoder.get_clusters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa1a18-6023-41e9-a4f1-7a52fdea647a",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9987756-9ab0-460f-a86a-0aed83ff932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Number of clusters: \",encoder.get_clusters())\n",
    "from pyclustering.cluster.silhouette import silhouette \n",
    "score = silhouette(mat, clusters).process().get_score()\n",
    "res = sum(score)/len(score)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368fece-6a05-415d-ae06-8268754ae3e5",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73091786-725e-4555-af47-941afe0c3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['perc_v_ace'], df['perc_v_1stwon'], c=encoder.get_clusters(), s=20)\n",
    "plt.tick_params(labelsize=18)\n",
    "plt.xlabel(\"perc_v_ace\",fontsize=18)\n",
    "plt.ylabel(\"perc_v_1stwon\",fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d20bb0-19f7-46bb-84b8-6aac0fe7cc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
